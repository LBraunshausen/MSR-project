{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac5e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy \n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.transform import jitter\n",
    "from bokeh.io import curdoc\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# configuration\n",
    "n_tag_posts = 500\n",
    "n_answer_posts = 42636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bb811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded csv data\n"
     ]
    }
   ],
   "source": [
    "# Load csv data\n",
    "filepath = os.path.join(os.getcwd(), 'QueryResults_sample_42636_14_05_21.csv')\n",
    "stack_posts = pd.read_csv(filepath, sep = \",\")\n",
    "\n",
    "print(\"loaded csv data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3193e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionUserId</th>\n",
       "      <th>QuestionUserReputation</th>\n",
       "      <th>QuestionUserDN</th>\n",
       "      <th>Tags</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionScore</th>\n",
       "      <th>title</th>\n",
       "      <th>QuestionBody</th>\n",
       "      <th>QuestionDate</th>\n",
       "      <th>AcceptedAnswer</th>\n",
       "      <th>AnswerUserId</th>\n",
       "      <th>AnswerUserReputation</th>\n",
       "      <th>AnswerUserDN</th>\n",
       "      <th>AnswerScore</th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>AnswerBody</th>\n",
       "      <th>AnswerDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3625340</td>\n",
       "      <td>33</td>\n",
       "      <td>user3625340</td>\n",
       "      <td>&lt;image-processing&gt;&lt;machine-learning&gt;&lt;svm&gt;&lt;feat...</td>\n",
       "      <td>27729199</td>\n",
       "      <td>0</td>\n",
       "      <td>How to find Relevent Features for Comparing Di...</td>\n",
       "      <td>&lt;p&gt;Currently we are doing a project on diagram...</td>\n",
       "      <td>2015-01-01 08:03:13</td>\n",
       "      <td>27733517.0</td>\n",
       "      <td>1056563</td>\n",
       "      <td>45925</td>\n",
       "      <td>StephenBoesch</td>\n",
       "      <td>0</td>\n",
       "      <td>27733517</td>\n",
       "      <td>&lt;p&gt;In regard solely to the difference in scale...</td>\n",
       "      <td>2015-01-01 18:39:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4409773</td>\n",
       "      <td>788</td>\n",
       "      <td>Avis</td>\n",
       "      <td>&lt;java&gt;&lt;machine-learning&gt;&lt;svm&gt;&lt;encog&gt;</td>\n",
       "      <td>27729238</td>\n",
       "      <td>1</td>\n",
       "      <td>SVM using Encog in Java for beginners</td>\n",
       "      <td>&lt;p&gt;I am beginner in SVM. Could someone please ...</td>\n",
       "      <td>2015-01-01 08:10:29</td>\n",
       "      <td>27808712.0</td>\n",
       "      <td>173355</td>\n",
       "      <td>3162</td>\n",
       "      <td>JeffHeaton</td>\n",
       "      <td>1</td>\n",
       "      <td>27808712</td>\n",
       "      <td>&lt;p&gt;In Encog SVM is just a classification or re...</td>\n",
       "      <td>2015-01-06 22:58:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4408281</td>\n",
       "      <td>715</td>\n",
       "      <td>datavinci</td>\n",
       "      <td>&lt;python-2.7&gt;&lt;machine-learning&gt;</td>\n",
       "      <td>27730775</td>\n",
       "      <td>1</td>\n",
       "      <td>Why does not the following code snippet run su...</td>\n",
       "      <td>&lt;p&gt;I was reading Programming Collective Intell...</td>\n",
       "      <td>2015-01-01 12:22:49</td>\n",
       "      <td>27730829.0</td>\n",
       "      <td>367273</td>\n",
       "      <td>436785</td>\n",
       "      <td>NPE</td>\n",
       "      <td>1</td>\n",
       "      <td>27730829</td>\n",
       "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;NameError: global name 'lin...</td>\n",
       "      <td>2015-01-01 12:32:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3512217</td>\n",
       "      <td>119</td>\n",
       "      <td>Shlomi</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;svm&gt;</td>\n",
       "      <td>27730870</td>\n",
       "      <td>-1</td>\n",
       "      <td>division of two proper kernels</td>\n",
       "      <td>&lt;p&gt;Let &lt;img src=\"https://i.stack.imgur.com/Z1G...</td>\n",
       "      <td>2015-01-01 12:37:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060350</td>\n",
       "      <td>70610</td>\n",
       "      <td>Has QUIT--Anony-Mousse</td>\n",
       "      <td>0</td>\n",
       "      <td>27742921</td>\n",
       "      <td>&lt;p&gt;K2(x,z) can be 0.&lt;/p&gt;\\n\\n&lt;p&gt;Then this value...</td>\n",
       "      <td>2015-01-02 13:22:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4405757</td>\n",
       "      <td>14440</td>\n",
       "      <td>user7</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;classification&gt;&lt;weka&gt;&lt;libsv...</td>\n",
       "      <td>27732503</td>\n",
       "      <td>0</td>\n",
       "      <td>One class SVM to detect outliers</td>\n",
       "      <td>&lt;p&gt;My problem is&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n  &lt;p&gt;I w...</td>\n",
       "      <td>2015-01-01 16:26:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060350</td>\n",
       "      <td>70610</td>\n",
       "      <td>Has QUIT--Anony-Mousse</td>\n",
       "      <td>5</td>\n",
       "      <td>27739848</td>\n",
       "      <td>&lt;p&gt;Your data is not formatted appropriately fo...</td>\n",
       "      <td>2015-01-02 09:20:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42631</th>\n",
       "      <td>14926602</td>\n",
       "      <td>21</td>\n",
       "      <td>Waqar Kaleem Khan</td>\n",
       "      <td>&lt;tensorflow&gt;&lt;machine-learning&gt;&lt;keras&gt;&lt;deep-lea...</td>\n",
       "      <td>67441958</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM input layer shape in Keras using function...</td>\n",
       "      <td>&lt;p&gt;I am trying to implement LSTMs on drug data...</td>\n",
       "      <td>2021-05-07 21:38:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5927701</td>\n",
       "      <td>2972</td>\n",
       "      <td>data_person</td>\n",
       "      <td>1</td>\n",
       "      <td>67442769</td>\n",
       "      <td>&lt;p&gt;Try adding an &lt;code&gt;Embedding Layer&lt;/code&gt; ...</td>\n",
       "      <td>2021-05-07 23:36:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42632</th>\n",
       "      <td>3973175</td>\n",
       "      <td>4261</td>\n",
       "      <td>con</td>\n",
       "      <td>&lt;python&gt;&lt;python-3.x&gt;&lt;machine-learning&gt;&lt;shap&gt;</td>\n",
       "      <td>67443411</td>\n",
       "      <td>2</td>\n",
       "      <td>How to get feature names of shap_values from T...</td>\n",
       "      <td>&lt;p&gt;I am doing a shap tutorial, and attempting ...</td>\n",
       "      <td>2021-05-08 01:56:51</td>\n",
       "      <td>67444552.0</td>\n",
       "      <td>3954379</td>\n",
       "      <td>5202</td>\n",
       "      <td>Lucas</td>\n",
       "      <td>2</td>\n",
       "      <td>67444552</td>\n",
       "      <td>&lt;p&gt;The features are indeed in the same order, ...</td>\n",
       "      <td>2021-05-08 06:02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42633</th>\n",
       "      <td>15847767</td>\n",
       "      <td>1</td>\n",
       "      <td>Pearl</td>\n",
       "      <td>&lt;python&gt;&lt;machine-learning&gt;&lt;keras&gt;&lt;neural-network&gt;</td>\n",
       "      <td>67443744</td>\n",
       "      <td>-1</td>\n",
       "      <td>What does hidden_layer = layers.Dense(100, act...</td>\n",
       "      <td>&lt;p&gt;I saw the following in &lt;a href=\"https://www...</td>\n",
       "      <td>2021-05-08 03:14:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15166370</td>\n",
       "      <td>45</td>\n",
       "      <td>Vibhav Surve</td>\n",
       "      <td>0</td>\n",
       "      <td>67443785</td>\n",
       "      <td>&lt;p&gt;See input layer is nothing but how many neu...</td>\n",
       "      <td>2021-05-08 03:22:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42634</th>\n",
       "      <td>14551464</td>\n",
       "      <td>61</td>\n",
       "      <td>Onkar Chougule</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;pytorch&gt;&lt;con...</td>\n",
       "      <td>67449276</td>\n",
       "      <td>0</td>\n",
       "      <td>Initalize using previous .pth and train for fu...</td>\n",
       "      <td>&lt;p&gt;How do I initialize a UNet model from its p...</td>\n",
       "      <td>2021-05-08 15:36:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14551464</td>\n",
       "      <td>61</td>\n",
       "      <td>Onkar Chougule</td>\n",
       "      <td>0</td>\n",
       "      <td>67451326</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;state= torch.load(&amp;quot;/content/mo...</td>\n",
       "      <td>2021-05-08 19:21:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42635</th>\n",
       "      <td>15409153</td>\n",
       "      <td>7</td>\n",
       "      <td>maritsae</td>\n",
       "      <td>&lt;python&gt;&lt;machine-learning&gt;&lt;prediction&gt;</td>\n",
       "      <td>67449334</td>\n",
       "      <td>-2</td>\n",
       "      <td>How to get probabilities of each predicted val...</td>\n",
       "      <td>&lt;p&gt;I am currently working on disease predictio...</td>\n",
       "      <td>2021-05-08 15:40:50</td>\n",
       "      <td>67449543.0</td>\n",
       "      <td>1458722</td>\n",
       "      <td>884</td>\n",
       "      <td>Hrishikesh</td>\n",
       "      <td>0</td>\n",
       "      <td>67449543</td>\n",
       "      <td>&lt;p&gt;If you're using scikit-learn, you can use &lt;...</td>\n",
       "      <td>2021-05-08 16:01:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42636 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QuestionUserId  QuestionUserReputation     QuestionUserDN  \\\n",
       "0             3625340                      33        user3625340   \n",
       "1             4409773                     788               Avis   \n",
       "2             4408281                     715          datavinci   \n",
       "3             3512217                     119             Shlomi   \n",
       "4             4405757                   14440              user7   \n",
       "...               ...                     ...                ...   \n",
       "42631        14926602                      21  Waqar Kaleem Khan   \n",
       "42632         3973175                    4261                con   \n",
       "42633        15847767                       1              Pearl   \n",
       "42634        14551464                      61     Onkar Chougule   \n",
       "42635        15409153                       7           maritsae   \n",
       "\n",
       "                                                    Tags  QuestionId  \\\n",
       "0      <image-processing><machine-learning><svm><feat...    27729199   \n",
       "1                   <java><machine-learning><svm><encog>    27729238   \n",
       "2                         <python-2.7><machine-learning>    27730775   \n",
       "3                                <machine-learning><svm>    27730870   \n",
       "4      <machine-learning><classification><weka><libsv...    27732503   \n",
       "...                                                  ...         ...   \n",
       "42631  <tensorflow><machine-learning><keras><deep-lea...    67441958   \n",
       "42632       <python><python-3.x><machine-learning><shap>    67443411   \n",
       "42633  <python><machine-learning><keras><neural-network>    67443744   \n",
       "42634  <machine-learning><deep-learning><pytorch><con...    67449276   \n",
       "42635             <python><machine-learning><prediction>    67449334   \n",
       "\n",
       "       QuestionScore                                              title  \\\n",
       "0                  0  How to find Relevent Features for Comparing Di...   \n",
       "1                  1              SVM using Encog in Java for beginners   \n",
       "2                  1  Why does not the following code snippet run su...   \n",
       "3                 -1                     division of two proper kernels   \n",
       "4                  0                   One class SVM to detect outliers   \n",
       "...              ...                                                ...   \n",
       "42631              0  LSTM input layer shape in Keras using function...   \n",
       "42632              2  How to get feature names of shap_values from T...   \n",
       "42633             -1  What does hidden_layer = layers.Dense(100, act...   \n",
       "42634              0  Initalize using previous .pth and train for fu...   \n",
       "42635             -2  How to get probabilities of each predicted val...   \n",
       "\n",
       "                                            QuestionBody         QuestionDate  \\\n",
       "0      <p>Currently we are doing a project on diagram...  2015-01-01 08:03:13   \n",
       "1      <p>I am beginner in SVM. Could someone please ...  2015-01-01 08:10:29   \n",
       "2      <p>I was reading Programming Collective Intell...  2015-01-01 12:22:49   \n",
       "3      <p>Let <img src=\"https://i.stack.imgur.com/Z1G...  2015-01-01 12:37:59   \n",
       "4      <p>My problem is</p>\\n\\n<blockquote>\\n  <p>I w...  2015-01-01 16:26:06   \n",
       "...                                                  ...                  ...   \n",
       "42631  <p>I am trying to implement LSTMs on drug data...  2021-05-07 21:38:47   \n",
       "42632  <p>I am doing a shap tutorial, and attempting ...  2021-05-08 01:56:51   \n",
       "42633  <p>I saw the following in <a href=\"https://www...  2021-05-08 03:14:14   \n",
       "42634  <p>How do I initialize a UNet model from its p...  2021-05-08 15:36:01   \n",
       "42635  <p>I am currently working on disease predictio...  2021-05-08 15:40:50   \n",
       "\n",
       "       AcceptedAnswer  AnswerUserId  AnswerUserReputation  \\\n",
       "0          27733517.0       1056563                 45925   \n",
       "1          27808712.0        173355                  3162   \n",
       "2          27730829.0        367273                436785   \n",
       "3                 NaN       1060350                 70610   \n",
       "4                 NaN       1060350                 70610   \n",
       "...               ...           ...                   ...   \n",
       "42631             NaN       5927701                  2972   \n",
       "42632      67444552.0       3954379                  5202   \n",
       "42633             NaN      15166370                    45   \n",
       "42634             NaN      14551464                    61   \n",
       "42635      67449543.0       1458722                   884   \n",
       "\n",
       "                 AnswerUserDN  AnswerScore  AnswerId  \\\n",
       "0               StephenBoesch            0  27733517   \n",
       "1                  JeffHeaton            1  27808712   \n",
       "2                         NPE            1  27730829   \n",
       "3      Has QUIT--Anony-Mousse            0  27742921   \n",
       "4      Has QUIT--Anony-Mousse            5  27739848   \n",
       "...                       ...          ...       ...   \n",
       "42631             data_person            1  67442769   \n",
       "42632                   Lucas            2  67444552   \n",
       "42633            Vibhav Surve            0  67443785   \n",
       "42634          Onkar Chougule            0  67451326   \n",
       "42635              Hrishikesh            0  67449543   \n",
       "\n",
       "                                              AnswerBody           AnswerDate  \n",
       "0      <p>In regard solely to the difference in scale...  2015-01-01 18:39:02  \n",
       "1      <p>In Encog SVM is just a classification or re...  2015-01-06 22:58:03  \n",
       "2      <blockquote>\\n  <p>NameError: global name 'lin...  2015-01-01 12:32:19  \n",
       "3      <p>K2(x,z) can be 0.</p>\\n\\n<p>Then this value...  2015-01-02 13:22:27  \n",
       "4      <p>Your data is not formatted appropriately fo...  2015-01-02 09:20:50  \n",
       "...                                                  ...                  ...  \n",
       "42631  <p>Try adding an <code>Embedding Layer</code> ...  2021-05-07 23:36:34  \n",
       "42632  <p>The features are indeed in the same order, ...  2021-05-08 06:02:39  \n",
       "42633  <p>See input layer is nothing but how many neu...  2021-05-08 03:22:03  \n",
       "42634  <pre><code>state= torch.load(&quot;/content/mo...  2021-05-08 19:21:01  \n",
       "42635  <p>If you're using scikit-learn, you can use <...  2021-05-08 16:01:52  \n",
       "\n",
       "[42636 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade06b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning functions\n",
    "\n",
    "# clean all angle brackets from string\n",
    "def clean_tags(tags):    \n",
    "    tag_list = []\n",
    "    # clean tags from '>' and '<' occurences\n",
    "    tags = re.sub('><', ' ', tags) \n",
    "    tags = re.sub('<|>', '', tags)\n",
    "    # add single tag of tags and add it to lists and sets\n",
    "    for tag in tags.split():\n",
    "        if tag != 'machine-learning':\n",
    "            tag_list.append(tag)\n",
    "    return tag_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc55302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all duplicates in posts\n",
    "df_w_dupes = pd.DataFrame(stack_posts[0:n_answer_posts])\n",
    "df_wo_dupes = df_w_dupes.drop_duplicates([\"QuestionId\"])\n",
    "df_sorted_wo_dupes = df_wo_dupes.sort_values(by=[\"QuestionId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c9ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extact user stats (reputation in question/answers, question-/answers counts, amount of accepted answers etc.)\n",
    "users = dict()\n",
    "\n",
    "def create_user_stats(id, display_name):\n",
    "    # add user if userid does not exist\n",
    "    if id not in users:\n",
    "        users[id] = dict()    \n",
    "        users[id][\"display_name\"] = display_name\n",
    "        \n",
    "# customize stats which every user has\n",
    "def customize_user_base_stats(id, score, post_type):    \n",
    "    users[id][post_type + \"_reputation\"] = users[id].get(post_type + \"_reputation\", 0) + score * 10   \n",
    "    users[id][post_type + '_count'] = users[id].get(post_type + '_count', 0) + 1\n",
    "\n",
    "\n",
    "# iterate over dataframe tuples\n",
    "for i, post in enumerate(df_w_dupes.itertuples()):  \n",
    "    # create DataFrame from pandas.core.frame so column names can be used instead of indexes\n",
    "    post = pd.DataFrame(post).transpose().drop(0, axis=1)\n",
    "    post.columns = stack_posts.columns\n",
    "    \n",
    "    # customize question user stats if question is not a duplicate of previous question\n",
    "    if post[\"QuestionId\"][0] != df_w_dupes.iloc[i - 1][\"QuestionId\"]:\n",
    "        question_user_id = post[\"QuestionUserId\"][0]\n",
    "        create_user_stats(question_user_id, post[\"QuestionUserDN\"][0])\n",
    "        \n",
    "        # customize question user stats        \n",
    "        customize_user_base_stats(question_user_id,post[\"QuestionScore\"][0], \"question\")\n",
    "        cleaned_tags = clean_tags(post[\"Tags\"][0])\n",
    "        users[question_user_id][\"question_tags\"] = set(users[question_user_id].get(\"question_tags\", set()).union(cleaned_tags))\n",
    "                    \n",
    "                \n",
    "    # create answer user stats\n",
    "    answer_user_id = post[\"AnswerUserId\"][0]\n",
    "    create_user_stats(answer_user_id, post[\"AnswerUserDN\"][0])\n",
    "        \n",
    "    customize_user_base_stats(answer_user_id,post[\"AnswerScore\"][0], \"answer\")\n",
    "    users[answer_user_id][\"answer_tags\"] = set(users[answer_user_id].get(\"answer_tags\", set()).union(cleaned_tags))\n",
    "    if post[\"AcceptedAnswer\"][0] == post[\"AnswerId\"][0]:\n",
    "        users[answer_user_id][\"accepted_answer_count\"] = users[answer_user_id].get(\"accepted_answer_count\", 0) + 1\n",
    "        users[answer_user_id][\"answer_reputation\"] = users[answer_user_id].get(\"answer_reputation\", 0) + 15        \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756b2a26",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c6cffb09e0b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtechnology_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"import successful\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# read technology list\n",
    "technology_set = set()\n",
    "with open('technology_list_customized.txt', 'r', newline='') as myfile:        \n",
    "    reader = csv.reader(myfile)\n",
    "    for row in reader:        \n",
    "        technology_set.add(row[0].lower())\n",
    "\n",
    "print(\"import successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7bf352",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame(users).transpose()\n",
    "sorted_user_df = user_df.sort_values(by=['answer_reputation'], ascending=False)\n",
    "#sorted_user_df = sorted_user_df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01842e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_name</th>\n",
       "      <th>question_reputation</th>\n",
       "      <th>question_count</th>\n",
       "      <th>question_tags</th>\n",
       "      <th>answer_reputation</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>answer_tags</th>\n",
       "      <th>accepted_answer_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>desertnaut</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{scikit-learn, shap}</td>\n",
       "      <td>31680</td>\n",
       "      <td>579</td>\n",
       "      <td>{unsupervised-learning, tensorflow-datasets, l...</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>lejlot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25015</td>\n",
       "      <td>618</td>\n",
       "      <td>{prediction, object, reinforcement-learning, s...</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>Marcin Możejko</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>{grid-search, nlp, keras, neural-network, cntk...</td>\n",
       "      <td>22335</td>\n",
       "      <td>238</td>\n",
       "      <td>{unsupervised-learning, python-3.x, image, num...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>Maxim</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>{deep-learning, tensorflow, neural-network, py...</td>\n",
       "      <td>20950</td>\n",
       "      <td>378</td>\n",
       "      <td>{unsupervised-learning, machine-translation, r...</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>Shai</td>\n",
       "      <td>1020</td>\n",
       "      <td>9</td>\n",
       "      <td>{normalization, computer-vision, neural-networ...</td>\n",
       "      <td>16625</td>\n",
       "      <td>309</td>\n",
       "      <td>{unsupervised-learning, python-3.x, semantic-s...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>today</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14080</td>\n",
       "      <td>318</td>\n",
       "      <td>{unsupervised-learning, python-3.x, semantic-s...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>Vivek Kumar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9175</td>\n",
       "      <td>182</td>\n",
       "      <td>{python-3.x, unsupervised-learning, numpy, pip...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>dga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8445</td>\n",
       "      <td>14</td>\n",
       "      <td>{computer-vision, python-2.7, image-recognitio...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>Daniel Möller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8265</td>\n",
       "      <td>186</td>\n",
       "      <td>{python-3.x, numpy, image-processing, batch-no...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>Martin Thoma</td>\n",
       "      <td>490</td>\n",
       "      <td>6</td>\n",
       "      <td>{python-3.x, keras, numpy, image-processing, s...</td>\n",
       "      <td>7830</td>\n",
       "      <td>92</td>\n",
       "      <td>{python-3.x, image, reinforcement-learning, pr...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>Prune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7820</td>\n",
       "      <td>266</td>\n",
       "      <td>{proof, unsupervised-learning, loss, predictio...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>stackoverflowuser2010</td>\n",
       "      <td>1860</td>\n",
       "      <td>19</td>\n",
       "      <td>{r, keras, word-embedding, xgboost, bert-langu...</td>\n",
       "      <td>7545</td>\n",
       "      <td>46</td>\n",
       "      <td>{label, python-3.x, weka, j48, numpy, decision...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>mrry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7285</td>\n",
       "      <td>79</td>\n",
       "      <td>{linux, python-3.x, tensorflow-datasets, distr...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>Salvador Dali</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{scikit-learn, python}</td>\n",
       "      <td>6610</td>\n",
       "      <td>35</td>\n",
       "      <td>{convolution, numpy, queue, scikit-learn, soft...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>Has QUIT--Anony-Mousse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6200</td>\n",
       "      <td>356</td>\n",
       "      <td>{unsupervised-learning, conditional, predictio...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>Dr. Snoopy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5290</td>\n",
       "      <td>172</td>\n",
       "      <td>{output, python-3.x, linux, image, prediction,...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>Nicolas Gervais</td>\n",
       "      <td>240</td>\n",
       "      <td>11</td>\n",
       "      <td>{python-3.x, computer-vision, keras, numpy, te...</td>\n",
       "      <td>5165</td>\n",
       "      <td>131</td>\n",
       "      <td>{feature-selection, generative-adversarial-net...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>seralouk</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>{scikit-learn, eli5, python-2.7, roc, classifi...</td>\n",
       "      <td>5140</td>\n",
       "      <td>99</td>\n",
       "      <td>{python-3.x, unsupervised-learning, image, num...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>MaxU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4915</td>\n",
       "      <td>80</td>\n",
       "      <td>{python-3.x, object, numpy, scikit-learn, kagg...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>runhani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4840</td>\n",
       "      <td>1</td>\n",
       "      <td>{signal-processing, deep-learning, convolution...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    display_name question_reputation question_count  \\\n",
       "4685471               desertnaut                  10              1   \n",
       "2658050                   lejlot                 NaN            NaN   \n",
       "5974433           Marcin Możejko                  70              3   \n",
       "712995                     Maxim                  40              1   \n",
       "1714410                     Shai                1020              9   \n",
       "2099607                    today                 NaN            NaN   \n",
       "3374996              Vivek Kumar                 NaN            NaN   \n",
       "5545260                      dga                 NaN            NaN   \n",
       "2097240            Daniel Möller                 NaN            NaN   \n",
       "562769              Martin Thoma                 490              6   \n",
       "4785185                    Prune                 NaN            NaN   \n",
       "4561314    stackoverflowuser2010                1860             19   \n",
       "3574081                     mrry                 NaN            NaN   \n",
       "1090562            Salvador Dali                   0              1   \n",
       "1060350   Has QUIT--Anony-Mousse                 NaN            NaN   \n",
       "349130                Dr. Snoopy                 NaN            NaN   \n",
       "10908375         Nicolas Gervais                 240             11   \n",
       "5025009                 seralouk                 110              3   \n",
       "5741205                     MaxU                 NaN            NaN   \n",
       "6730309                  runhani                 NaN            NaN   \n",
       "\n",
       "                                              question_tags answer_reputation  \\\n",
       "4685471                                {scikit-learn, shap}             31680   \n",
       "2658050                                                 NaN             25015   \n",
       "5974433   {grid-search, nlp, keras, neural-network, cntk...             22335   \n",
       "712995    {deep-learning, tensorflow, neural-network, py...             20950   \n",
       "1714410   {normalization, computer-vision, neural-networ...             16625   \n",
       "2099607                                                 NaN             14080   \n",
       "3374996                                                 NaN              9175   \n",
       "5545260                                                 NaN              8445   \n",
       "2097240                                                 NaN              8265   \n",
       "562769    {python-3.x, keras, numpy, image-processing, s...              7830   \n",
       "4785185                                                 NaN              7820   \n",
       "4561314   {r, keras, word-embedding, xgboost, bert-langu...              7545   \n",
       "3574081                                                 NaN              7285   \n",
       "1090562                              {scikit-learn, python}              6610   \n",
       "1060350                                                 NaN              6200   \n",
       "349130                                                  NaN              5290   \n",
       "10908375  {python-3.x, computer-vision, keras, numpy, te...              5165   \n",
       "5025009   {scikit-learn, eli5, python-2.7, roc, classifi...              5140   \n",
       "5741205                                                 NaN              4915   \n",
       "6730309                                                 NaN              4840   \n",
       "\n",
       "         answer_count                                        answer_tags  \\\n",
       "4685471           579  {unsupervised-learning, tensorflow-datasets, l...   \n",
       "2658050           618  {prediction, object, reinforcement-learning, s...   \n",
       "5974433           238  {unsupervised-learning, python-3.x, image, num...   \n",
       "712995            378  {unsupervised-learning, machine-translation, r...   \n",
       "1714410           309  {unsupervised-learning, python-3.x, semantic-s...   \n",
       "2099607           318  {unsupervised-learning, python-3.x, semantic-s...   \n",
       "3374996           182  {python-3.x, unsupervised-learning, numpy, pip...   \n",
       "5545260            14  {computer-vision, python-2.7, image-recognitio...   \n",
       "2097240           186  {python-3.x, numpy, image-processing, batch-no...   \n",
       "562769             92  {python-3.x, image, reinforcement-learning, pr...   \n",
       "4785185           266  {proof, unsupervised-learning, loss, predictio...   \n",
       "4561314            46  {label, python-3.x, weka, j48, numpy, decision...   \n",
       "3574081            79  {linux, python-3.x, tensorflow-datasets, distr...   \n",
       "1090562            35  {convolution, numpy, queue, scikit-learn, soft...   \n",
       "1060350           356  {unsupervised-learning, conditional, predictio...   \n",
       "349130            172  {output, python-3.x, linux, image, prediction,...   \n",
       "10908375          131  {feature-selection, generative-adversarial-net...   \n",
       "5025009            99  {python-3.x, unsupervised-learning, image, num...   \n",
       "5741205            80  {python-3.x, object, numpy, scikit-learn, kagg...   \n",
       "6730309             1  {signal-processing, deep-learning, convolution...   \n",
       "\n",
       "         accepted_answer_count  \n",
       "4685471                    458  \n",
       "2658050                    363  \n",
       "5974433                    159  \n",
       "712995                     244  \n",
       "1714410                    195  \n",
       "2099607                    250  \n",
       "3374996                    129  \n",
       "5545260                      9  \n",
       "2097240                    105  \n",
       "562769                      32  \n",
       "4785185                    108  \n",
       "4561314                     15  \n",
       "3574081                     51  \n",
       "1090562                     10  \n",
       "1060350                     96  \n",
       "349130                      76  \n",
       "10908375                    75  \n",
       "5025009                     52  \n",
       "5741205                     47  \n",
       "6730309                    NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_user_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab495ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select posts from top users\n",
    "top_answer_users = sorted_user_df[0:20]\n",
    "top_users_posts = stack_posts[stack_posts[\"AnswerUserId\"].isin(top_answer_users.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cd83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean answers\n",
    "regex_pattern = '(<(pre|code|blockquote|a|strike)(.|\\n)*?\\/(pre|code|blockquote|a|strike)>)*?|<(p|b|br|br(.|\\n)*?\\/|sub|sup|em|strong|hr|s|i|ol|ul|li|code)*?>|<\\/(p|b|br|sub|sup|em|strong|s|i|ol|ul|li|div|pre|blockquote|a|code)>|<h(.|\\n)*?>(.|\\n)*?<\\/h(.|\\n)*?>*?|(<(img|div|ol|ul|li)(.|\\n)*?\\/*?>)|\\n'\n",
    "def clean_bodys(text):\n",
    "    text = re.sub(regex_pattern, '', text, flags=re.I)\n",
    "    text = re.sub('\\(|\\)', ' ', text, flags=re.I)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b246eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data is not formatted appropriately for this problem.If you putpairs into a SVM, what you are really putting into the SVM are sparse vectors that consist of a single one, corresponding to your word, i.e.Anything a classifier can do on such data is overfit and memorize. On unknown new words, the result will be useless.If you want your classifier to be able to abstract and generalize, then you need to carefully extract features from your words.Possible features would be n-grams. So the word \"example\" could be represented asNow your classifier/SVM could learn that having the n-gram \"ple\" is typical for nouns.Results will likely be better if you add \"beginning-of-word\" and \"end-of-word\" symbol,and maybe also use more than one n-gram length, e.g.but of course, the more you add the larger your data set and search space grows, which again may lead to overfitting.\n",
      "[(11244915669818549327, 27, 28)]\n"
     ]
    }
   ],
   "source": [
    "# check for technologies\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "technology_pattern = [nlp(text) for text in technology_set]\n",
    "matcher.add(\"TECHNOLOGIES\", technology_pattern)\n",
    "\n",
    "\n",
    "for answer in top_users_posts[\"AnswerBody\"][1:2]:\n",
    "    cleaned_text= clean_bodys(answer)\n",
    "    \n",
    "    doc = nlp(cleaned_text)\n",
    "    print(doc)    \n",
    "    matches = matcher(doc)\n",
    "    print(matches)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6e6dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top users diagram\n",
    "p = figure(plot_width=500, plot_height=500)\n",
    "\n",
    "curdoc().theme = 'light_minimal'\n",
    "p.circle_dot(top_answer_users[\"answer_count\"], top_answer_users[\"answer_reputation\"], size=15, fill_color=\"#348abd\", fill_alpha=0.4, line_color=\"black\")\n",
    "p.xaxis.axis_label = 'Anzahl Posts'\n",
    "p.yaxis.axis_label = 'Reputation'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b39428",
   "metadata": {},
   "source": [
    "# Antworten - Akzeptierte Antworten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e81b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width=500, plot_height=500)\n",
    "\n",
    "curdoc().theme = 'light_minimal'\n",
    "p.circle(top_answer_users[\"answer_count\"], top_answer_users[\"accepted_answer_count\"], size=15, fill_color=\"#348abd\", fill_alpha=0.4, line_color=\"black\")\n",
    "p.xaxis.axis_label = 'Anzahl Antworten'\n",
    "p.yaxis.axis_label = 'Anzahl akzeptierte Anwtorten'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1e058",
   "metadata": {},
   "source": [
    "# Metrik - Antworten/akzeptierte Antworten\n",
    "Rate an akzeptierten Antworten auf Grundlagen von Gesamtanzahl der Antworten unter Experten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db271c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5920076573342905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anzahl akzeptierte Antworten/Antwortanzahl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desertnaut</th>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Kumar</th>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcin Możejko</th>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrry</th>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxim</th>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dga</th>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai</th>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxU</th>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lejlot</th>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicolas Gervais</th>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Möller</th>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seralouk</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Snoopy</th>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Thoma</th>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflowuser2010</th>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvador Dali</th>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has QUIT--Anony-Mousse</th>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runhani</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Anzahl akzeptierte Antworten/Antwortanzahl\n",
       "display_name                                                      \n",
       "desertnaut                                                   0.791\n",
       "today                                                        0.786\n",
       "Vivek Kumar                                                  0.709\n",
       "Marcin Możejko                                               0.668\n",
       "mrry                                                         0.646\n",
       "Maxim                                                        0.646\n",
       "dga                                                          0.643\n",
       "Shai                                                         0.631\n",
       "MaxU                                                         0.588\n",
       "lejlot                                                       0.587\n",
       "Nicolas Gervais                                              0.573\n",
       "Daniel Möller                                                0.565\n",
       "seralouk                                                     0.525\n",
       "Dr. Snoopy                                                   0.442\n",
       "Prune                                                        0.406\n",
       "Martin Thoma                                                 0.348\n",
       "stackoverflowuser2010                                        0.326\n",
       "Salvador Dali                                                0.286\n",
       "Has QUIT--Anony-Mousse                                       0.270\n",
       "runhani                                                      0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_answers = 0\n",
    "\n",
    "for answer_amount in top_answer_users[\"answer_count\"]:\n",
    "    total_answers += answer_amount\n",
    "\n",
    "total_acc_answers = 0\n",
    "for acc_answer_amount in top_answer_users[\"accepted_answer_count\"]:\n",
    "    if math.isnan(acc_answer_amount):\n",
    "        continue\n",
    "    total_acc_answers += acc_answer_amount\n",
    "\n",
    "acc_answer_answer_ratios = []\n",
    "\n",
    "for user in top_answer_users.itertuples():\n",
    "    acc_answer_answer_ratio = user[8]/user[6]\n",
    "    acc_answer_answer_ratios.append(acc_answer_answer_ratio)\n",
    "\n",
    "acc_answer_answer_ratios_df = pd.DataFrame(acc_answer_answer_ratios, index=top_answer_users[\"display_name\"])\n",
    "acc_answer_answer_ratios_df.columns = [\"Anzahl akzeptierte Antworten/Antwortanzahl\"]\n",
    "acc_answer_answer_ratios_df.fillna(0, inplace=True)\n",
    "acc_answer_answer_ratios_df = acc_answer_answer_ratios_df.sort_values(by=[\"Anzahl akzeptierte Antworten/Antwortanzahl\"], ascending=False)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "\n",
    "acc_answer_answer_ratio = total_acc_answers/total_answers\n",
    "print(acc_answer_answer_ratio)\n",
    "display(acc_answer_answer_ratios_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d0077",
   "metadata": {},
   "source": [
    "# Metrik - Reputation pro Antwort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce8d4959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reputation/Antwort</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>runhani</th>\n",
       "      <td>4,840.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dga</th>\n",
       "      <td>603.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvador Dali</th>\n",
       "      <td>188.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflowuser2010</th>\n",
       "      <td>164.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcin Możejko</th>\n",
       "      <td>93.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrry</th>\n",
       "      <td>92.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Thoma</th>\n",
       "      <td>85.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxU</th>\n",
       "      <td>61.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxim</th>\n",
       "      <td>55.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desertnaut</th>\n",
       "      <td>54.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai</th>\n",
       "      <td>53.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seralouk</th>\n",
       "      <td>51.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Kumar</th>\n",
       "      <td>50.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Möller</th>\n",
       "      <td>44.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>44.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lejlot</th>\n",
       "      <td>40.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicolas Gervais</th>\n",
       "      <td>39.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Snoopy</th>\n",
       "      <td>30.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <td>29.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has QUIT--Anony-Mousse</th>\n",
       "      <td>17.416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Reputation/Antwort\n",
       "display_name                              \n",
       "runhani                          4,840.000\n",
       "dga                                603.214\n",
       "Salvador Dali                      188.857\n",
       "stackoverflowuser2010              164.022\n",
       "Marcin Możejko                      93.845\n",
       "mrry                                92.215\n",
       "Martin Thoma                        85.109\n",
       "MaxU                                61.438\n",
       "Maxim                               55.423\n",
       "desertnaut                          54.715\n",
       "Shai                                53.803\n",
       "seralouk                            51.919\n",
       "Vivek Kumar                         50.412\n",
       "Daniel Möller                       44.435\n",
       "today                               44.277\n",
       "lejlot                              40.477\n",
       "Nicolas Gervais                     39.427\n",
       "Dr. Snoopy                          30.756\n",
       "Prune                               29.398\n",
       "Has QUIT--Anony-Mousse              17.416"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "332.05791736784363"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_per_answer_list = []\n",
    "for user in top_answer_users.itertuples():\n",
    "    rep_per_answer = user[5]/user[6]\n",
    "    rep_per_answer_list.append(rep_per_answer)\n",
    "    \n",
    "rep_per_answer_df = pd.DataFrame(rep_per_answer_list, index=top_answer_users[\"display_name\"])\n",
    "rep_per_answer_df.columns = [\"Reputation/Antwort\"]\n",
    "rep_per_answer_df.fillna(0, inplace=True)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "rep_per_answer_df = rep_per_answer_df.sort_values(by=[\"Reputation/Antwort\"], ascending=False)\n",
    "display(rep_per_answer_df)\n",
    "\n",
    "rep_per_answer_df[\"Reputation/Antwort\"].sum()/20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cc911",
   "metadata": {},
   "source": [
    "# Anzahl Tag pro Experte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7eaa695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anzahl Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desertnaut</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lejlot</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcin Możejko</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxim</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Kumar</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dga</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Möller</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Thoma</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflowuser2010</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrry</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvador Dali</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has QUIT--Anony-Mousse</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Snoopy</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicolas Gervais</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seralouk</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxU</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runhani</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Anzahl Tags\n",
       "display_name                       \n",
       "desertnaut                      190\n",
       "lejlot                          256\n",
       "Marcin Możejko                   89\n",
       "Maxim                           174\n",
       "Shai                             83\n",
       "today                           102\n",
       "Vivek Kumar                      99\n",
       "dga                              15\n",
       "Daniel Möller                    67\n",
       "Martin Thoma                     75\n",
       "Prune                           180\n",
       "stackoverflowuser2010            55\n",
       "mrry                             40\n",
       "Salvador Dali                    33\n",
       "Has QUIT--Anony-Mousse          199\n",
       "Dr. Snoopy                       78\n",
       "Nicolas Gervais                  60\n",
       "seralouk                         71\n",
       "MaxU                             74\n",
       "runhani                           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_per_user = []\n",
    "for tags in top_answer_users[\"answer_tags\"]:\n",
    "    tags_per_user.append(len(tags))\n",
    "\n",
    "tags_per_user_df = pd.DataFrame(tags_per_user, index=top_answer_users[\"display_name\"])\n",
    "tags_per_user_df.columns = [\"Anzahl Tags\"]\n",
    "tags_per_user_df.fillna(0, inplace=True)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "display(tags_per_user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42159bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tags = top_answer_users[\"answer_tags\"]\n",
    "for tag in answer_tags:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b20c8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_users = sorted_user_df[0:20]\n",
    "sorted_user_tag_df = pd.DataFrame(top_users, columns=[\"answer_tags\"], index=top_users.index)\n",
    "sorted_user_tag_df[\"user\"] = top_users.index\n",
    "sorted_user_tag_df.fillna(\"0\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da31af",
   "metadata": {},
   "source": [
    "# Metrik Reputation in \"machine-learning\"/Gesamtreputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a661924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_name</th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>calculated_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desertnaut</td>\n",
       "      <td>45566</td>\n",
       "      <td>31680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lejlot</td>\n",
       "      <td>56698</td>\n",
       "      <td>25015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marcin Możejko</td>\n",
       "      <td>34861</td>\n",
       "      <td>22335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maxim</td>\n",
       "      <td>47758</td>\n",
       "      <td>20950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shai</td>\n",
       "      <td>92508</td>\n",
       "      <td>16625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>today</td>\n",
       "      <td>26890</td>\n",
       "      <td>14080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vivek Kumar</td>\n",
       "      <td>28954</td>\n",
       "      <td>9175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dga</td>\n",
       "      <td>20741</td>\n",
       "      <td>8445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Daniel Möller</td>\n",
       "      <td>74002</td>\n",
       "      <td>8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Martin Thoma</td>\n",
       "      <td>90914</td>\n",
       "      <td>7830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Prune</td>\n",
       "      <td>71231</td>\n",
       "      <td>7820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stackoverflowuser2010</td>\n",
       "      <td>28900</td>\n",
       "      <td>7545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mrry</td>\n",
       "      <td>119880</td>\n",
       "      <td>7285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Salvador Dali</td>\n",
       "      <td>181453</td>\n",
       "      <td>6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Has QUIT--Anony-Mousse</td>\n",
       "      <td>70610</td>\n",
       "      <td>6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dr. Snoopy</td>\n",
       "      <td>49881</td>\n",
       "      <td>5290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nicolas Gervais</td>\n",
       "      <td>21433</td>\n",
       "      <td>5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>seralouk</td>\n",
       "      <td>22600</td>\n",
       "      <td>5140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MaxU</td>\n",
       "      <td>172329</td>\n",
       "      <td>4915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>runhani</td>\n",
       "      <td>4879</td>\n",
       "      <td>4840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              display_name  user_reputation  calculated_rep\n",
       "0               desertnaut            45566           31680\n",
       "1                   lejlot            56698           25015\n",
       "2           Marcin Możejko            34861           22335\n",
       "3                    Maxim            47758           20950\n",
       "4                     Shai            92508           16625\n",
       "5                    today            26890           14080\n",
       "6              Vivek Kumar            28954            9175\n",
       "7                      dga            20741            8445\n",
       "8            Daniel Möller            74002            8265\n",
       "9             Martin Thoma            90914            7830\n",
       "10                   Prune            71231            7820\n",
       "11   stackoverflowuser2010            28900            7545\n",
       "12                    mrry           119880            7285\n",
       "13           Salvador Dali           181453            6610\n",
       "14  Has QUIT--Anony-Mousse            70610            6200\n",
       "15              Dr. Snoopy            49881            5290\n",
       "16         Nicolas Gervais            21433            5165\n",
       "17                seralouk            22600            5140\n",
       "18                    MaxU           172329            4915\n",
       "19                 runhani             4879            4840"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_users_total_rep = top_users_posts.drop_duplicates(subset=[\"AnswerUserId\"])\n",
    "top_users_total_rep\n",
    "expert_reputations = []\n",
    "for expert in top_users.itertuples():\n",
    "    \n",
    "    user_reputation = top_users_total_rep.loc[top_users_total_rep['AnswerUserId'] == expert[0]][\"AnswerUserReputation\"].values[0]          \n",
    "    display_name = expert[1]\n",
    "    calculated_rep = expert[5]                    \n",
    "    #expert_reputations.append([display_name, user_reputation, calculated_rep])\n",
    "    expert_reputations.append(calculated_rep/user_reputation)\n",
    "    \n",
    "expert_reputations_df = pd.DataFrame(expert_reputations)\n",
    "expert_reputations_df.columns = [\"display_name\", \"user_reputation\", \"calculated_rep\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f0786fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_reputations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed35f9b",
   "metadata": {},
   "source": [
    "# Tag Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aca35c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tag</th>\n",
       "      <th>.net</th>\n",
       "      <th>accord.net</th>\n",
       "      <th>activation-function</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>adam</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>amazon-sagemaker</th>\n",
       "      <th>anaconda</th>\n",
       "      <th>analysis</th>\n",
       "      <th>analytics</th>\n",
       "      <th>...</th>\n",
       "      <th>word-embedding</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>xgbclassifier</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xls</th>\n",
       "      <th>xor</th>\n",
       "      <th>yellowbrick</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero-padding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tag       .net  accord.net  activation-function  adaboost  adam  algorithm  \\\n",
       "userid                                                                       \n",
       "349130   0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "562769   0.000       0.000                0.000     0.000 0.000      1.000   \n",
       "712995   0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "1060350  0.000       1.000                0.000     0.000 0.000      1.000   \n",
       "1090562  0.000       0.000                0.000     0.000 0.000      1.000   \n",
       "1714410  0.000       0.000                0.000     0.000 0.000      1.000   \n",
       "2097240  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "2099607  0.000       0.000                1.000     0.000 1.000      0.000   \n",
       "2658050  1.000       0.000                0.000     1.000 0.000      1.000   \n",
       "3374996  0.000       0.000                0.000     1.000 0.000      1.000   \n",
       "3574081  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "4561314  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "4685471  0.000       0.000                1.000     1.000 1.000      0.000   \n",
       "4785185  0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "5025009  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "5545260  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "5741205  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "5974433  0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "6730309  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "10908375 0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "\n",
       "tag       amazon-sagemaker  anaconda  analysis  analytics  ...  \\\n",
       "userid                                                     ...   \n",
       "349130               0.000     0.000     0.000      0.000  ...   \n",
       "562769               0.000     0.000     0.000      0.000  ...   \n",
       "712995               0.000     0.000     0.000      0.000  ...   \n",
       "1060350              1.000     0.000     1.000      0.000  ...   \n",
       "1090562              0.000     0.000     0.000      0.000  ...   \n",
       "1714410              0.000     0.000     0.000      0.000  ...   \n",
       "2097240              0.000     0.000     0.000      0.000  ...   \n",
       "2099607              0.000     0.000     0.000      0.000  ...   \n",
       "2658050              0.000     0.000     0.000      0.000  ...   \n",
       "3374996              0.000     1.000     0.000      0.000  ...   \n",
       "3574081              0.000     0.000     0.000      0.000  ...   \n",
       "4561314              0.000     0.000     0.000      0.000  ...   \n",
       "4685471              0.000     0.000     0.000      0.000  ...   \n",
       "4785185              0.000     1.000     0.000      1.000  ...   \n",
       "5025009              0.000     0.000     0.000      0.000  ...   \n",
       "5545260              0.000     0.000     0.000      0.000  ...   \n",
       "5741205              0.000     0.000     0.000      0.000  ...   \n",
       "5974433              0.000     0.000     0.000      0.000  ...   \n",
       "6730309              0.000     0.000     0.000      0.000  ...   \n",
       "10908375             0.000     0.000     0.000      0.000  ...   \n",
       "\n",
       "tag       word-embedding  word2vec  xgbclassifier  xgboost   xls   xor  \\\n",
       "userid                                                                   \n",
       "349130             0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "562769             0.000     1.000          0.000    0.000 0.000 0.000   \n",
       "712995             1.000     1.000          0.000    1.000 0.000 1.000   \n",
       "1060350            1.000     1.000          0.000    0.000 0.000 0.000   \n",
       "1090562            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "1714410            1.000     0.000          0.000    0.000 0.000 0.000   \n",
       "2097240            1.000     0.000          0.000    1.000 0.000 0.000   \n",
       "2099607            1.000     1.000          0.000    0.000 0.000 0.000   \n",
       "2658050            0.000     0.000          0.000    1.000 0.000 0.000   \n",
       "3374996            0.000     0.000          0.000    1.000 0.000 0.000   \n",
       "3574081            1.000     0.000          0.000    0.000 0.000 0.000   \n",
       "4561314            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "4685471            1.000     1.000          1.000    1.000 0.000 0.000   \n",
       "4785185            1.000     1.000          0.000    1.000 0.000 0.000   \n",
       "5025009            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "5545260            0.000     0.000          0.000    0.000 0.000 1.000   \n",
       "5741205            0.000     0.000          0.000    1.000 1.000 0.000   \n",
       "5974433            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "6730309            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "10908375           0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "\n",
       "tag       yellowbrick  yelp  yolo  zero-padding  \n",
       "userid                                           \n",
       "349130          0.000 0.000 0.000         0.000  \n",
       "562769          0.000 0.000 0.000         0.000  \n",
       "712995          0.000 0.000 0.000         0.000  \n",
       "1060350         0.000 1.000 0.000         0.000  \n",
       "1090562         0.000 0.000 0.000         0.000  \n",
       "1714410         0.000 0.000 0.000         0.000  \n",
       "2097240         0.000 0.000 0.000         1.000  \n",
       "2099607         0.000 0.000 0.000         0.000  \n",
       "2658050         0.000 0.000 0.000         0.000  \n",
       "3374996         0.000 0.000 0.000         0.000  \n",
       "3574081         0.000 0.000 0.000         0.000  \n",
       "4561314         0.000 0.000 0.000         0.000  \n",
       "4685471         1.000 0.000 1.000         0.000  \n",
       "4785185         0.000 0.000 1.000         0.000  \n",
       "5025009         0.000 0.000 0.000         0.000  \n",
       "5545260         0.000 0.000 0.000         0.000  \n",
       "5741205         0.000 0.000 0.000         0.000  \n",
       "5974433         0.000 0.000 0.000         0.000  \n",
       "6730309         0.000 0.000 0.000         0.000  \n",
       "10908375        0.000 0.000 0.000         0.000  \n",
       "\n",
       "[20 rows x 689 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userid</th>\n",
       "      <th>349130</th>\n",
       "      <th>562769</th>\n",
       "      <th>712995</th>\n",
       "      <th>1060350</th>\n",
       "      <th>1090562</th>\n",
       "      <th>1714410</th>\n",
       "      <th>2097240</th>\n",
       "      <th>2099607</th>\n",
       "      <th>2658050</th>\n",
       "      <th>3374996</th>\n",
       "      <th>3574081</th>\n",
       "      <th>4561314</th>\n",
       "      <th>4685471</th>\n",
       "      <th>4785185</th>\n",
       "      <th>5025009</th>\n",
       "      <th>5545260</th>\n",
       "      <th>5741205</th>\n",
       "      <th>5974433</th>\n",
       "      <th>6730309</th>\n",
       "      <th>10908375</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>0.431</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.296</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>0.398</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.363</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>0.443</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.469</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.508</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>0.326</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.322</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>0.397</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>0.312</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.342</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>0.282</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>0.292</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>0.303</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.159</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>0.424</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "userid    349130    562769    712995    1060350   1090562   1714410   \\\n",
       "userid                                                                 \n",
       "349130       1.000     0.431     0.361     0.233     0.296     0.398   \n",
       "562769       0.431     1.000     0.376     0.336     0.322     0.368   \n",
       "712995       0.361     0.376     1.000     0.296     0.330     0.349   \n",
       "1060350      0.233     0.336     0.296     1.000     0.173     0.202   \n",
       "1090562      0.296     0.322     0.330     0.173     1.000     0.363   \n",
       "1714410      0.398     0.368     0.349     0.202     0.363     1.000   \n",
       "2097240      0.443     0.324     0.370     0.191     0.319     0.469   \n",
       "2099607      0.404     0.377     0.435     0.204     0.310     0.402   \n",
       "2658050      0.326     0.390     0.403     0.416     0.294     0.322   \n",
       "3374996      0.296     0.406     0.358     0.392     0.297     0.243   \n",
       "3574081      0.376     0.347     0.324     0.179     0.385     0.330   \n",
       "4561314      0.397     0.405     0.317     0.296     0.329     0.311   \n",
       "4685471      0.312     0.377     0.352     0.375     0.290     0.295   \n",
       "4785185      0.380     0.422     0.418     0.433     0.285     0.385   \n",
       "5025009      0.282     0.370     0.279     0.362     0.289     0.261   \n",
       "5545260      0.292     0.268     0.215     0.165     0.405     0.312   \n",
       "5741205      0.303     0.376     0.300     0.338     0.304     0.230   \n",
       "5974433      0.444     0.392     0.410     0.263     0.351     0.384   \n",
       "6730309      0.113     0.115     0.114     0.071     0.261     0.165   \n",
       "10908375     0.424     0.388     0.323     0.210     0.315     0.397   \n",
       "\n",
       "userid    2097240   2099607   2658050   3374996   3574081   4561314   \\\n",
       "userid                                                                 \n",
       "349130       0.443     0.404     0.326     0.296     0.376     0.397   \n",
       "562769       0.324     0.377     0.390     0.406     0.347     0.405   \n",
       "712995       0.370     0.435     0.403     0.358     0.324     0.317   \n",
       "1060350      0.191     0.204     0.416     0.392     0.179     0.296   \n",
       "1090562      0.319     0.310     0.294     0.297     0.385     0.329   \n",
       "1714410      0.469     0.402     0.322     0.243     0.330     0.311   \n",
       "2097240      1.000     0.508     0.305     0.307     0.386     0.346   \n",
       "2099607      0.508     1.000     0.322     0.308     0.329     0.347   \n",
       "2658050      0.305     0.322     1.000     0.408     0.227     0.346   \n",
       "3374996      0.307     0.308     0.408     1.000     0.270     0.366   \n",
       "3574081      0.386     0.329     0.227     0.270     1.000     0.384   \n",
       "4561314      0.346     0.347     0.346     0.366     0.384     1.000   \n",
       "4685471      0.355     0.417     0.440     0.489     0.241     0.342   \n",
       "4785185      0.319     0.369     0.508     0.442     0.271     0.412   \n",
       "5025009      0.203     0.270     0.349     0.525     0.244     0.384   \n",
       "5545260      0.347     0.230     0.210     0.234     0.367     0.174   \n",
       "5741205      0.256     0.299     0.356     0.479     0.257     0.408   \n",
       "5974433      0.505     0.462     0.431     0.362     0.352     0.357   \n",
       "6730309      0.183     0.198     0.094     0.101     0.237     0.067   \n",
       "10908375     0.410     0.422     0.282     0.324     0.347     0.383   \n",
       "\n",
       "userid    4685471   4785185   5025009   5545260   5741205   5974433   \\\n",
       "userid                                                                 \n",
       "349130       0.312     0.380     0.282     0.292     0.303     0.444   \n",
       "562769       0.377     0.422     0.370     0.268     0.376     0.392   \n",
       "712995       0.352     0.418     0.279     0.215     0.300     0.410   \n",
       "1060350      0.375     0.433     0.362     0.165     0.338     0.263   \n",
       "1090562      0.290     0.285     0.289     0.405     0.304     0.351   \n",
       "1714410      0.295     0.385     0.261     0.312     0.230     0.384   \n",
       "2097240      0.355     0.319     0.203     0.347     0.256     0.505   \n",
       "2099607      0.417     0.369     0.270     0.230     0.299     0.462   \n",
       "2658050      0.440     0.508     0.349     0.210     0.356     0.431   \n",
       "3374996      0.489     0.442     0.525     0.234     0.479     0.362   \n",
       "3574081      0.241     0.271     0.244     0.367     0.257     0.352   \n",
       "4561314      0.342     0.412     0.384     0.174     0.408     0.357   \n",
       "4685471      1.000     0.422     0.422     0.169     0.405     0.369   \n",
       "4785185      0.422     1.000     0.372     0.212     0.399     0.387   \n",
       "5025009      0.422     0.372     1.000     0.184     0.455     0.302   \n",
       "5545260      0.169     0.212     0.184     1.000     0.210     0.301   \n",
       "5741205      0.405     0.399     0.455     0.210     1.000     0.333   \n",
       "5974433      0.369     0.387     0.302     0.301     0.333     1.000   \n",
       "6730309      0.109     0.112     0.059     0.258     0.058     0.159   \n",
       "10908375     0.337     0.346     0.368     0.300     0.300     0.342   \n",
       "\n",
       "userid    6730309   10908375  \n",
       "userid                        \n",
       "349130       0.113     0.424  \n",
       "562769       0.115     0.388  \n",
       "712995       0.114     0.323  \n",
       "1060350      0.071     0.210  \n",
       "1090562      0.261     0.315  \n",
       "1714410      0.165     0.397  \n",
       "2097240      0.183     0.410  \n",
       "2099607      0.198     0.422  \n",
       "2658050      0.094     0.282  \n",
       "3374996      0.101     0.324  \n",
       "3574081      0.237     0.347  \n",
       "4561314      0.067     0.383  \n",
       "4685471      0.109     0.337  \n",
       "4785185      0.112     0.346  \n",
       "5025009      0.059     0.368  \n",
       "5545260      0.258     0.300  \n",
       "5741205      0.058     0.300  \n",
       "5974433      0.159     0.342  \n",
       "6730309      1.000     0.129  \n",
       "10908375     0.129     1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_tag_list = []\n",
    "for i,tags in enumerate(sorted_user_tag_df[\"answer_tags\"]):\n",
    "        \n",
    "    if tags != \"0\":    \n",
    "        for tag in tags:        \n",
    "            user_tag = [sorted_user_tag_df.iloc[i][\"user\"], tag]\n",
    "            user_tag_list.append(user_tag)\n",
    "        \n",
    "\n",
    "\n",
    "user_tag_list_df = pd.DataFrame(user_tag_list, columns=[\"userid\", \"tag\"])\n",
    "user_tag_list_df[\"count\"] = 1\n",
    "\n",
    "user_tags_matrix = user_tag_list_df.pivot(index=\"userid\", columns=\"tag\", values=\"count\")\n",
    "user_tags_matrix.fillna(0, inplace=True)\n",
    "user_tag_similarity = cosine_similarity(user_tags_matrix)\n",
    "\n",
    "sim_df = pd.DataFrame(user_tag_similarity, index=user_tags_matrix.index, columns=user_tags_matrix.index)\n",
    "display(user_tags_matrix)\n",
    "display(sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f504d6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userid</th>\n",
       "      <th>349130</th>\n",
       "      <th>562769</th>\n",
       "      <th>712995</th>\n",
       "      <th>1060350</th>\n",
       "      <th>1090562</th>\n",
       "      <th>1714410</th>\n",
       "      <th>2097240</th>\n",
       "      <th>2099607</th>\n",
       "      <th>2658050</th>\n",
       "      <th>3374996</th>\n",
       "      <th>3574081</th>\n",
       "      <th>4561314</th>\n",
       "      <th>4685471</th>\n",
       "      <th>4785185</th>\n",
       "      <th>5025009</th>\n",
       "      <th>5545260</th>\n",
       "      <th>5741205</th>\n",
       "      <th>5974433</th>\n",
       "      <th>6730309</th>\n",
       "      <th>10908375</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>0.431</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>0.398</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>0.443</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.469</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.508</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>0.326</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.322</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>0.397</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>0.312</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>0.303</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>0.424</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "userid    349130    562769    712995    1060350   1090562   1714410   \\\n",
       "userid                                                                 \n",
       "349130       1.000     0.431     0.361     0.000     0.000     0.398   \n",
       "562769       0.431     1.000     0.376     0.336     0.322     0.368   \n",
       "712995       0.361     0.376     1.000     0.000     0.330     0.349   \n",
       "1060350      0.000     0.336     0.000     1.000     0.000     0.000   \n",
       "1090562      0.000     0.322     0.330     0.000     1.000     0.363   \n",
       "1714410      0.398     0.368     0.349     0.000     0.363     1.000   \n",
       "2097240      0.443     0.324     0.370     0.000     0.319     0.469   \n",
       "2099607      0.404     0.377     0.435     0.000     0.310     0.402   \n",
       "2658050      0.326     0.390     0.403     0.416     0.000     0.322   \n",
       "3374996      0.000     0.406     0.358     0.392     0.000     0.000   \n",
       "3574081      0.376     0.347     0.324     0.000     0.385     0.330   \n",
       "4561314      0.397     0.405     0.317     0.000     0.329     0.311   \n",
       "4685471      0.312     0.377     0.352     0.375     0.000     0.000   \n",
       "4785185      0.380     0.422     0.418     0.433     0.000     0.385   \n",
       "5025009      0.000     0.370     0.000     0.362     0.000     0.000   \n",
       "5545260      0.000     0.000     0.000     0.000     0.405     0.312   \n",
       "5741205      0.303     0.376     0.000     0.338     0.304     0.000   \n",
       "5974433      0.444     0.392     0.410     0.000     0.351     0.384   \n",
       "6730309      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "10908375     0.424     0.388     0.323     0.000     0.315     0.397   \n",
       "\n",
       "userid    2097240   2099607   2658050   3374996   3574081   4561314   \\\n",
       "userid                                                                 \n",
       "349130       0.443     0.404     0.326     0.000     0.376     0.397   \n",
       "562769       0.324     0.377     0.390     0.406     0.347     0.405   \n",
       "712995       0.370     0.435     0.403     0.358     0.324     0.317   \n",
       "1060350      0.000     0.000     0.416     0.392     0.000     0.000   \n",
       "1090562      0.319     0.310     0.000     0.000     0.385     0.329   \n",
       "1714410      0.469     0.402     0.322     0.000     0.330     0.311   \n",
       "2097240      1.000     0.508     0.305     0.307     0.386     0.346   \n",
       "2099607      0.508     1.000     0.322     0.308     0.329     0.347   \n",
       "2658050      0.305     0.322     1.000     0.408     0.000     0.346   \n",
       "3374996      0.307     0.308     0.408     1.000     0.000     0.366   \n",
       "3574081      0.386     0.329     0.000     0.000     1.000     0.384   \n",
       "4561314      0.346     0.347     0.346     0.366     0.384     1.000   \n",
       "4685471      0.355     0.417     0.440     0.489     0.000     0.342   \n",
       "4785185      0.319     0.369     0.508     0.442     0.000     0.412   \n",
       "5025009      0.000     0.000     0.349     0.525     0.000     0.384   \n",
       "5545260      0.347     0.000     0.000     0.000     0.367     0.000   \n",
       "5741205      0.000     0.000     0.356     0.479     0.000     0.408   \n",
       "5974433      0.505     0.462     0.431     0.362     0.352     0.357   \n",
       "6730309      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "10908375     0.410     0.422     0.000     0.324     0.347     0.383   \n",
       "\n",
       "userid    4685471   4785185   5025009   5545260   5741205   5974433   \\\n",
       "userid                                                                 \n",
       "349130       0.312     0.380     0.000     0.000     0.303     0.444   \n",
       "562769       0.377     0.422     0.370     0.000     0.376     0.392   \n",
       "712995       0.352     0.418     0.000     0.000     0.000     0.410   \n",
       "1060350      0.375     0.433     0.362     0.000     0.338     0.000   \n",
       "1090562      0.000     0.000     0.000     0.405     0.304     0.351   \n",
       "1714410      0.000     0.385     0.000     0.312     0.000     0.384   \n",
       "2097240      0.355     0.319     0.000     0.347     0.000     0.505   \n",
       "2099607      0.417     0.369     0.000     0.000     0.000     0.462   \n",
       "2658050      0.440     0.508     0.349     0.000     0.356     0.431   \n",
       "3374996      0.489     0.442     0.525     0.000     0.479     0.362   \n",
       "3574081      0.000     0.000     0.000     0.367     0.000     0.352   \n",
       "4561314      0.342     0.412     0.384     0.000     0.408     0.357   \n",
       "4685471      1.000     0.422     0.422     0.000     0.405     0.369   \n",
       "4785185      0.422     1.000     0.372     0.000     0.399     0.387   \n",
       "5025009      0.422     0.372     1.000     0.000     0.455     0.302   \n",
       "5545260      0.000     0.000     0.000     1.000     0.000     0.301   \n",
       "5741205      0.405     0.399     0.455     0.000     1.000     0.333   \n",
       "5974433      0.369     0.387     0.302     0.301     0.333     1.000   \n",
       "6730309      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "10908375     0.337     0.346     0.368     0.000     0.300     0.342   \n",
       "\n",
       "userid    6730309   10908375  \n",
       "userid                        \n",
       "349130       0.000     0.424  \n",
       "562769       0.000     0.388  \n",
       "712995       0.000     0.323  \n",
       "1060350      0.000     0.000  \n",
       "1090562      0.000     0.315  \n",
       "1714410      0.000     0.397  \n",
       "2097240      0.000     0.410  \n",
       "2099607      0.000     0.422  \n",
       "2658050      0.000     0.000  \n",
       "3374996      0.000     0.324  \n",
       "3574081      0.000     0.347  \n",
       "4561314      0.000     0.383  \n",
       "4685471      0.000     0.337  \n",
       "4785185      0.000     0.346  \n",
       "5025009      0.000     0.368  \n",
       "5545260      0.000     0.000  \n",
       "5741205      0.000     0.300  \n",
       "5974433      0.000     0.342  \n",
       "6730309      1.000     0.000  \n",
       "10908375     0.000     1.000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "\n",
    "tag_similarity_filtered = sim_df\n",
    "tag_similarity_filtered.values[tag_similarity_filtered <= threshold] = 0\n",
    "tag_similarity_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144fab1d",
   "metadata": {},
   "source": [
    "# Same tags in all taglists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a60b6c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deep-learning'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_set = sorted_user_tag_df.iloc[0][\"answer_tags\"]\n",
    "#print(intersect_set)\n",
    "for i,tags in enumerate(sorted_user_tag_df[\"answer_tags\"][0:20]):\n",
    "    intersect_set = intersect_set.intersection(tags)\n",
    "intersect_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3507b",
   "metadata": {},
   "source": [
    "# Count tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2c1192bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'deep-learning': 20,\n",
       "         'neural-network': 19,\n",
       "         'python': 19,\n",
       "         'numpy': 18,\n",
       "         'tensorflow': 18,\n",
       "         'computer-vision': 17,\n",
       "         'python-3.x': 17,\n",
       "         'keras': 17,\n",
       "         'scikit-learn': 16,\n",
       "         'nlp': 16,\n",
       "         'conv-neural-network': 16,\n",
       "         'classification': 15,\n",
       "         'artificial-intelligence': 15,\n",
       "         'data-science': 14,\n",
       "         'regression': 14,\n",
       "         'recurrent-neural-network': 14,\n",
       "         'pandas': 14,\n",
       "         'lstm': 14,\n",
       "         'image-processing': 13,\n",
       "         'one-hot-encoding': 13,\n",
       "         'mnist': 12,\n",
       "         'svm': 12,\n",
       "         'feature-extraction': 12,\n",
       "         'text-classification': 12,\n",
       "         'linear-regression': 12,\n",
       "         'logistic-regression': 12,\n",
       "         'cross-validation': 12,\n",
       "         'optimization': 12,\n",
       "         'training-data': 11,\n",
       "         'unsupervised-learning': 10,\n",
       "         'backpropagation': 10,\n",
       "         'arrays': 10,\n",
       "         'cluster-analysis': 10,\n",
       "         'naivebayes': 10,\n",
       "         'time-series': 10,\n",
       "         'feature-selection': 10,\n",
       "         'dataset': 10,\n",
       "         'loss-function': 10,\n",
       "         'statistics': 10,\n",
       "         'r': 10,\n",
       "         'normalization': 10,\n",
       "         'convolution': 10,\n",
       "         'algorithm': 10,\n",
       "         'k-means': 9,\n",
       "         'cross-entropy': 9,\n",
       "         'validation': 9,\n",
       "         'multilabel-classification': 9,\n",
       "         'decision-tree': 9,\n",
       "         'python-2.7': 9,\n",
       "         'keras-layer': 9,\n",
       "         'image': 9,\n",
       "         'prediction': 8,\n",
       "         'pca': 8,\n",
       "         'multiclass-classification': 8,\n",
       "         'tf-idf': 8,\n",
       "         'softmax': 8,\n",
       "         'gradient-descent': 8,\n",
       "         'opencv': 8,\n",
       "         'knn': 8,\n",
       "         'probability': 8,\n",
       "         'autoencoder': 8,\n",
       "         'word-embedding': 8,\n",
       "         'math': 8,\n",
       "         'tensorboard': 8,\n",
       "         'object-detection': 8,\n",
       "         'xgboost': 7,\n",
       "         'scipy': 7,\n",
       "         'matplotlib': 7,\n",
       "         'hyperparameters': 7,\n",
       "         'random-forest': 7,\n",
       "         'pytorch': 7,\n",
       "         'grid-search': 7,\n",
       "         'reinforcement-learning': 7,\n",
       "         'theano': 7,\n",
       "         'caffe': 7,\n",
       "         'dataframe': 7,\n",
       "         'tensor': 7,\n",
       "         'precision-recall': 6,\n",
       "         'nearest-neighbor': 6,\n",
       "         'regularized': 6,\n",
       "         'roc': 6,\n",
       "         'word2vec': 6,\n",
       "         'ensemble-learning': 6,\n",
       "         'activation-function': 6,\n",
       "         'java': 6,\n",
       "         'supervised-learning': 6,\n",
       "         'nltk': 6,\n",
       "         'gaussian': 6,\n",
       "         'valueerror': 6,\n",
       "         'metrics': 6,\n",
       "         'tf.keras': 6,\n",
       "         'non-linear-regression': 6,\n",
       "         'perceptron': 6,\n",
       "         'dimensionality-reduction': 6,\n",
       "         'matlab': 6,\n",
       "         'performance': 6,\n",
       "         'sentiment-analysis': 6,\n",
       "         'image-recognition': 6,\n",
       "         'bigdata': 6,\n",
       "         'data-analysis': 6,\n",
       "         'train-test-split': 5,\n",
       "         'tensorflow2.0': 5,\n",
       "         'libsvm': 5,\n",
       "         'sigmoid': 5,\n",
       "         'dbscan': 5,\n",
       "         'bayesian': 5,\n",
       "         'confusion-matrix': 5,\n",
       "         'evaluation': 5,\n",
       "         'vgg-net': 5,\n",
       "         'random': 5,\n",
       "         'batch-normalization': 5,\n",
       "         'data-mining': 5,\n",
       "         'c++': 5,\n",
       "         'image-segmentation': 5,\n",
       "         'cosine-similarity': 5,\n",
       "         'linear-algebra': 5,\n",
       "         'rnn': 5,\n",
       "         'max-pooling': 5,\n",
       "         'sklearn-pandas': 5,\n",
       "         'generative-adversarial-network': 5,\n",
       "         'tensorflow-datasets': 4,\n",
       "         'loss': 4,\n",
       "         'audio': 4,\n",
       "         'boosting': 4,\n",
       "         'categorical-data': 4,\n",
       "         'signal-processing': 4,\n",
       "         'apache-spark': 4,\n",
       "         'plot': 4,\n",
       "         'gbm': 4,\n",
       "         'apache-spark-mllib': 4,\n",
       "         'auc': 4,\n",
       "         'parallel-processing': 4,\n",
       "         'rapidminer': 4,\n",
       "         'torch': 4,\n",
       "         'uncertainty': 4,\n",
       "         'weka': 4,\n",
       "         'computer-science': 4,\n",
       "         'embedding': 4,\n",
       "         'imagenet': 4,\n",
       "         'generator': 4,\n",
       "         'vector': 4,\n",
       "         'csv': 4,\n",
       "         'ocr': 4,\n",
       "         'convolutional-neural-network': 4,\n",
       "         'vectorization': 4,\n",
       "         'android': 4,\n",
       "         'resnet': 4,\n",
       "         'recommendation-engine': 4,\n",
       "         'predict': 4,\n",
       "         'face-recognition': 4,\n",
       "         'jupyter-notebook': 4,\n",
       "         'imblearn': 3,\n",
       "         'azure-machine-learning-studio': 3,\n",
       "         'scaling': 3,\n",
       "         'imputation': 3,\n",
       "         'gradient': 3,\n",
       "         'gmm': 3,\n",
       "         'dropout': 3,\n",
       "         'text-processing': 3,\n",
       "         'r-caret': 3,\n",
       "         'pyspark': 3,\n",
       "         'outliers': 3,\n",
       "         'standardized': 3,\n",
       "         'rfe': 3,\n",
       "         'lda': 3,\n",
       "         'adaboost': 3,\n",
       "         'shuffle': 3,\n",
       "         'mean-square-error': 3,\n",
       "         'handwriting-recognition': 3,\n",
       "         'terminology': 3,\n",
       "         'matrix': 3,\n",
       "         'missing-data': 3,\n",
       "         'feature-detection': 3,\n",
       "         'hierarchical-clustering': 3,\n",
       "         'kernel-density': 3,\n",
       "         'euclidean-distance': 3,\n",
       "         'q-learning': 3,\n",
       "         'jupyter': 3,\n",
       "         'scikits': 3,\n",
       "         'text-mining': 3,\n",
       "         'mathematical-optimization': 3,\n",
       "         'cluster-computing': 3,\n",
       "         'pattern-recognition': 3,\n",
       "         'arff': 3,\n",
       "         'svd': 3,\n",
       "         'pattern-matching': 3,\n",
       "         'data-visualization': 3,\n",
       "         'gpu': 3,\n",
       "         'visualization': 3,\n",
       "         'document-classification': 3,\n",
       "         'tensorflow-serving': 3,\n",
       "         'distributed-computing': 3,\n",
       "         'seq2seq': 3,\n",
       "         'pre-trained-model': 3,\n",
       "         'recommender-systems': 3,\n",
       "         'preprocessor': 3,\n",
       "         'skflow': 3,\n",
       "         'similarity': 3,\n",
       "         'feature-engineering': 3,\n",
       "         'spark-dataframe': 2,\n",
       "         'image-preprocessing': 2,\n",
       "         'ml.net': 2,\n",
       "         'statsmodels': 2,\n",
       "         'sgd': 2,\n",
       "         'google-cloud-ml': 2,\n",
       "         'gridsearchcv': 2,\n",
       "         'yolo': 2,\n",
       "         'hyperas': 2,\n",
       "         'eli5': 2,\n",
       "         'mse': 2,\n",
       "         'glmnet': 2,\n",
       "         'h2o': 2,\n",
       "         'coreml': 2,\n",
       "         'tfidfvectorizer': 2,\n",
       "         'pipeline': 2,\n",
       "         'precision': 2,\n",
       "         'kaggle': 2,\n",
       "         'apache-spark-ml': 2,\n",
       "         'encoding': 2,\n",
       "         'azure': 2,\n",
       "         'catboost': 2,\n",
       "         'countvectorizer': 2,\n",
       "         'pearson-correlation': 2,\n",
       "         'chatbot': 2,\n",
       "         'adam': 2,\n",
       "         'resampling': 2,\n",
       "         'object': 2,\n",
       "         'probability-density': 2,\n",
       "         'twitter': 2,\n",
       "         'hidden-markov-models': 2,\n",
       "         'self-organizing-maps': 2,\n",
       "         'linear-discriminant': 2,\n",
       "         'import': 2,\n",
       "         'c#': 2,\n",
       "         'autodiff': 2,\n",
       "         'ruby': 2,\n",
       "         'data-modeling': 2,\n",
       "         'bayesian-networks': 2,\n",
       "         'hash': 2,\n",
       "         'threshold': 2,\n",
       "         'machine-translation': 2,\n",
       "         'minhash': 2,\n",
       "         'parameters': 2,\n",
       "         'derivative': 2,\n",
       "         'javascript': 2,\n",
       "         'ranking': 2,\n",
       "         'tree': 2,\n",
       "         'octave': 2,\n",
       "         'kernel': 2,\n",
       "         'tflearn': 2,\n",
       "         'mle': 2,\n",
       "         'nonlinear-optimization': 2,\n",
       "         'correlation': 2,\n",
       "         'keras-2': 2,\n",
       "         'stateful': 2,\n",
       "         'google-cloud-platform': 2,\n",
       "         'minima': 2,\n",
       "         'tokenize': 2,\n",
       "         'logging': 2,\n",
       "         'bias-neuron': 2,\n",
       "         'input': 2,\n",
       "         'machine-learning-model': 2,\n",
       "         'gated-recurrent-unit': 2,\n",
       "         'restore': 2,\n",
       "         'binary-search-tree': 2,\n",
       "         'multithreading': 2,\n",
       "         'dictionary': 2,\n",
       "         'concatenation': 2,\n",
       "         'reshape': 2,\n",
       "         'memory': 2,\n",
       "         'json': 2,\n",
       "         'queue': 2,\n",
       "         'multi-gpu': 2,\n",
       "         'deep-residual-networks': 2,\n",
       "         'kdtree': 2,\n",
       "         'attention-model': 2,\n",
       "         'gensim': 2,\n",
       "         'openai-gym': 2,\n",
       "         'xor': 2,\n",
       "         'graph': 2,\n",
       "         'list': 2,\n",
       "         'semantic-segmentation': 2,\n",
       "         'inference': 2,\n",
       "         'pycaffe': 2,\n",
       "         'torchvision': 2,\n",
       "         'windows': 2,\n",
       "         'lmdb': 2,\n",
       "         'data-augmentation': 2,\n",
       "         'cnn': 2,\n",
       "         'forecasting': 2,\n",
       "         'epoch': 2,\n",
       "         'transfer-learning': 2,\n",
       "         'noise': 2,\n",
       "         'huggingface-transformers': 2,\n",
       "         'anaconda': 2,\n",
       "         'polynomials': 2,\n",
       "         'pycharm': 2,\n",
       "         'testing': 2,\n",
       "         'text-analysis': 2,\n",
       "         'sequential': 2,\n",
       "         'entropy': 2,\n",
       "         'eigenvalue': 2,\n",
       "         'bioinformatics': 2,\n",
       "         'distance': 2,\n",
       "         'scala': 2,\n",
       "         'object-detection-api': 2,\n",
       "         'j48': 2,\n",
       "         'numpy-ndarray': 2,\n",
       "         'linux': 2,\n",
       "         'spyder': 2,\n",
       "         'spacy': 2,\n",
       "         'python-3.7': 2,\n",
       "         'k-fold': 2,\n",
       "         'automl': 1,\n",
       "         'mlp': 1,\n",
       "         'apache-spark-sql': 1,\n",
       "         'rasa': 1,\n",
       "         'auto-keras': 1,\n",
       "         'lasso-regression': 1,\n",
       "         'graphviz': 1,\n",
       "         'node.js': 1,\n",
       "         'azure-databricks': 1,\n",
       "         'log-likelihood': 1,\n",
       "         'imbalanced-data': 1,\n",
       "         'sparse-matrix': 1,\n",
       "         'sparkr': 1,\n",
       "         'naming-conventions': 1,\n",
       "         'test-data': 1,\n",
       "         'densenet': 1,\n",
       "         'lightgbm': 1,\n",
       "         'tensorflow.js': 1,\n",
       "         'tpot': 1,\n",
       "         'glm': 1,\n",
       "         'ml-studio': 1,\n",
       "         'pojo': 1,\n",
       "         'relu': 1,\n",
       "         'mlr': 1,\n",
       "         'smote': 1,\n",
       "         'xgbclassifier': 1,\n",
       "         'multinomial': 1,\n",
       "         'ios': 1,\n",
       "         'iris-dataset': 1,\n",
       "         'yellowbrick': 1,\n",
       "         'tfjs-node': 1,\n",
       "         'stochastic-gradient': 1,\n",
       "         'rpart': 1,\n",
       "         'mlxtend': 1,\n",
       "         'shap': 1,\n",
       "         'random-seed': 1,\n",
       "         'databricks': 1,\n",
       "         'spectral': 1,\n",
       "         'data-partitioning': 1,\n",
       "         'scoring': 1,\n",
       "         'online-machine-learning': 1,\n",
       "         'gaussian-process': 1,\n",
       "         'keras-tuner': 1,\n",
       "         'face-detection': 1,\n",
       "         'early-stopping': 1,\n",
       "         'sampling': 1,\n",
       "         'markov': 1,\n",
       "         'normalize': 1,\n",
       "         'post-processing': 1,\n",
       "         'multiple-regression': 1,\n",
       "         'smo': 1,\n",
       "         'sample': 1,\n",
       "         'binary': 1,\n",
       "         'voting': 1,\n",
       "         'hmmlearn': 1,\n",
       "         'principal-components': 1,\n",
       "         'contour': 1,\n",
       "         'convex-optimization': 1,\n",
       "         'constructor': 1,\n",
       "         'packet': 1,\n",
       "         'variance': 1,\n",
       "         'curves': 1,\n",
       "         'patsy': 1,\n",
       "         'tensorflow-gpu': 1,\n",
       "         'corpus': 1,\n",
       "         'data-representation': 1,\n",
       "         'curve-fitting': 1,\n",
       "         'transformation': 1,\n",
       "         'difference': 1,\n",
       "         'fitness': 1,\n",
       "         'categorization': 1,\n",
       "         'pybrain': 1,\n",
       "         'centroid': 1,\n",
       "         'representation': 1,\n",
       "         'grid': 1,\n",
       "         'markov-models': 1,\n",
       "         'linearmodels': 1,\n",
       "         'perception': 1,\n",
       "         'synthetic': 1,\n",
       "         'documentation': 1,\n",
       "         'mixture-model': 1,\n",
       "         'covariance': 1,\n",
       "         'trigonometry': 1,\n",
       "         'stream': 1,\n",
       "         'function': 1,\n",
       "         'lua': 1,\n",
       "         'python-imaging-library': 1,\n",
       "         'least-squares': 1,\n",
       "         'textblob': 1,\n",
       "         'expectation-maximization': 1,\n",
       "         'em': 1,\n",
       "         'discrete-mathematics': 1,\n",
       "         '.net': 1,\n",
       "         'n-gram': 1,\n",
       "         'smoothing': 1,\n",
       "         'financial': 1,\n",
       "         'google-developer-tools': 1,\n",
       "         'evolutionary-algorithm': 1,\n",
       "         'modeling': 1,\n",
       "         'c': 1,\n",
       "         'false-positive': 1,\n",
       "         'tcp': 1,\n",
       "         'obfuscation': 1,\n",
       "         'markov-chains': 1,\n",
       "         'minimization': 1,\n",
       "         'pygame': 1,\n",
       "         'api': 1,\n",
       "         'deeplearning4j': 1,\n",
       "         'genetic-algorithm': 1,\n",
       "         'tradeoff': 1,\n",
       "         'bernoulli-probability': 1,\n",
       "         'heuristics': 1,\n",
       "         'numerical-methods': 1,\n",
       "         'function-fitting': 1,\n",
       "         'large-data': 1,\n",
       "         'quantify': 1,\n",
       "         'biological-neural-network': 1,\n",
       "         'word-count': 1,\n",
       "         'theano-cuda': 1,\n",
       "         'poisson': 1,\n",
       "         'oop': 1,\n",
       "         'scientific-computing': 1,\n",
       "         'normal-distribution': 1,\n",
       "         'string': 1,\n",
       "         'quadratic': 1,\n",
       "         'merge': 1,\n",
       "         'evaluate': 1,\n",
       "         'flatten': 1,\n",
       "         'lasagne': 1,\n",
       "         'dimension': 1,\n",
       "         'runtime-error': 1,\n",
       "         'weighted': 1,\n",
       "         'stride': 1,\n",
       "         'cntk': 1,\n",
       "         'projection': 1,\n",
       "         'doc2vec': 1,\n",
       "         'beta-distribution': 1,\n",
       "         'multidimensional-array': 1,\n",
       "         'sequence': 1,\n",
       "         'scope': 1,\n",
       "         'save': 1,\n",
       "         'tensorflow-estimator': 1,\n",
       "         'variables': 1,\n",
       "         'array-broadcasting': 1,\n",
       "         'weighted-average': 1,\n",
       "         'differential-equations': 1,\n",
       "         'tensorflow-slim': 1,\n",
       "         'robotics': 1,\n",
       "         'initializer': 1,\n",
       "         'data-manipulation': 1,\n",
       "         'boolean-expression': 1,\n",
       "         'mapping': 1,\n",
       "         'if-statement': 1,\n",
       "         'lambda': 1,\n",
       "         'markov-decision-process': 1,\n",
       "         'deconvolution': 1,\n",
       "         'estimation': 1,\n",
       "         'variable-assignment': 1,\n",
       "         'divide-by-zero': 1,\n",
       "         'avx': 1,\n",
       "         'control-flow': 1,\n",
       "         'initialization': 1,\n",
       "         'memory-leaks': 1,\n",
       "         'feed': 1,\n",
       "         'builder': 1,\n",
       "         'dependencies': 1,\n",
       "         'mxnet': 1,\n",
       "         'error-handling': 1,\n",
       "         'feed-forward': 1,\n",
       "         'conditional-operator': 1,\n",
       "         'snpe': 1,\n",
       "         'sequence-to-sequence': 1,\n",
       "         'transfer-function': 1,\n",
       "         'google-compute-engine': 1,\n",
       "         'tensorflow-gradient': 1,\n",
       "         'transfer': 1,\n",
       "         'matrix-multiplication': 1,\n",
       "         'segmentation-fault': 1,\n",
       "         'protocol-buffers': 1,\n",
       "         'nvidia': 1,\n",
       "         'glog': 1,\n",
       "         'matrix-factorization': 1,\n",
       "         'argparse': 1,\n",
       "         'filter': 1,\n",
       "         'autograd': 1,\n",
       "         'nvidia-digits': 1,\n",
       "         'image-enhancement': 1,\n",
       "         'iterator': 1,\n",
       "         'hdf5': 1,\n",
       "         'multiplication': 1,\n",
       "         'matcaffe': 1,\n",
       "         'inner-product': 1,\n",
       "         'ubuntu-14.04': 1,\n",
       "         'fast-ai': 1,\n",
       "         'reduction': 1,\n",
       "         'quantization': 1,\n",
       "         'keras-rl': 1,\n",
       "         'tpu': 1,\n",
       "         'autoregressive-models': 1,\n",
       "         'siamese-network': 1,\n",
       "         'gradienttape': 1,\n",
       "         'checkpointing': 1,\n",
       "         'unity3d-unet': 1,\n",
       "         'heatmap': 1,\n",
       "         'progress-bar': 1,\n",
       "         'pickle': 1,\n",
       "         'oversampling': 1,\n",
       "         'data-transform': 1,\n",
       "         'lreshape': 1,\n",
       "         'ordinal': 1,\n",
       "         'labels': 1,\n",
       "         'hyperopt': 1,\n",
       "         'edx': 1,\n",
       "         'joblib': 1,\n",
       "         'polynomial-math': 1,\n",
       "         'transformer': 1,\n",
       "         'zero-padding': 1,\n",
       "         'metric': 1,\n",
       "         'video-processing': 1,\n",
       "         'unet': 1,\n",
       "         'mismatch': 1,\n",
       "         'ddos': 1,\n",
       "         'sentence': 1,\n",
       "         'reproducible-research': 1,\n",
       "         'rotation': 1,\n",
       "         'set': 1,\n",
       "         'manual': 1,\n",
       "         'captcha': 1,\n",
       "         'fuzzy-logic': 1,\n",
       "         'proof': 1,\n",
       "         'binary-tree': 1,\n",
       "         'text-extraction': 1,\n",
       "         'language-agnostic': 1,\n",
       "         'temperature': 1,\n",
       "         'text': 1,\n",
       "         'numerical-stability': 1,\n",
       "         'bounding-box': 1,\n",
       "         'geojson': 1,\n",
       "         'theory': 1,\n",
       "         'sensor-fusion': 1,\n",
       "         'question-answering': 1,\n",
       "         'convergence': 1,\n",
       "         'information-theory': 1,\n",
       "         'ordinals': 1,\n",
       "         'analytics': 1,\n",
       "         'calculus': 1,\n",
       "         'google-prediction': 1,\n",
       "         'benchmarking': 1,\n",
       "         'model': 1,\n",
       "         'imperative-programming': 1,\n",
       "         'content-based-retrieval': 1,\n",
       "         'particle-swarm': 1,\n",
       "         'monkeylearn': 1,\n",
       "         'null': 1,\n",
       "         'speech-recognition': 1,\n",
       "         'stanford-nlp': 1,\n",
       "         'graphics': 1,\n",
       "         'time': 1,\n",
       "         'nan': 1,\n",
       "         'search': 1,\n",
       "         'gesture-recognition': 1,\n",
       "         'dataformat': 1,\n",
       "         'logic': 1,\n",
       "         'text-database': 1,\n",
       "         'predictionio': 1,\n",
       "         'security': 1,\n",
       "         'label': 1,\n",
       "         'sparse-file': 1,\n",
       "         'bert-language-model': 1,\n",
       "         'confidence-interval': 1,\n",
       "         'spacy-pytorch-transformers': 1,\n",
       "         'distributed': 1,\n",
       "         'system-requirements': 1,\n",
       "         'grpc': 1,\n",
       "         'build': 1,\n",
       "         'mean': 1,\n",
       "         'synchronization': 1,\n",
       "         'conditional': 1,\n",
       "         'for-loop': 1,\n",
       "         'cuda': 1,\n",
       "         'geometry': 1,\n",
       "         'scikit-image': 1,\n",
       "         'spherical-kmeans': 1,\n",
       "         'orange': 1,\n",
       "         'mean-shift': 1,\n",
       "         'time-complexity': 1,\n",
       "         'binning': 1,\n",
       "         'audio-processing': 1,\n",
       "         'anova': 1,\n",
       "         'levenshtein-distance': 1,\n",
       "         'word': 1,\n",
       "         'apriori': 1,\n",
       "         'arules': 1,\n",
       "         'moa': 1,\n",
       "         'information-retrieval': 1,\n",
       "         'accord.net': 1,\n",
       "         'scatter-plot': 1,\n",
       "         'debugging': 1,\n",
       "         'topic-modeling': 1,\n",
       "         'discretization': 1,\n",
       "         'id3': 1,\n",
       "         'pattern-mining': 1,\n",
       "         'file-format': 1,\n",
       "         'stability': 1,\n",
       "         'scalar': 1,\n",
       "         'trend': 1,\n",
       "         'coordinates': 1,\n",
       "         'edit-distance': 1,\n",
       "         'anomaly-detection': 1,\n",
       "         'yelp': 1,\n",
       "         'unit-testing': 1,\n",
       "         'data-generation': 1,\n",
       "         'intrusion-detection': 1,\n",
       "         'mean-stack': 1,\n",
       "         'google-cloud-automl': 1,\n",
       "         'geolocation': 1,\n",
       "         'sequences': 1,\n",
       "         'google-visualization': 1,\n",
       "         'probability-theory': 1,\n",
       "         'graph-theory': 1,\n",
       "         'linear-programming': 1,\n",
       "         'fpgrowth': 1,\n",
       "         'amazon-sagemaker': 1,\n",
       "         'sift': 1,\n",
       "         'mahout': 1,\n",
       "         'computational-geometry': 1,\n",
       "         'fasttext': 1,\n",
       "         'associations': 1,\n",
       "         'statistical-sampling': 1,\n",
       "         'definition': 1,\n",
       "         'r-daisy': 1,\n",
       "         'term': 1,\n",
       "         'location': 1,\n",
       "         'optics-algorithm': 1,\n",
       "         'continuous-fourier': 1,\n",
       "         'eigenvector': 1,\n",
       "         'elki': 1,\n",
       "         'fuzzy-c-means': 1,\n",
       "         'silhouette': 1,\n",
       "         'subsequence': 1,\n",
       "         'noise-reduction': 1,\n",
       "         'analysis': 1,\n",
       "         'tagging': 1,\n",
       "         'dft': 1,\n",
       "         'output': 1,\n",
       "         'argmax': 1,\n",
       "         'multi-layer': 1,\n",
       "         'python-3.6': 1,\n",
       "         'keras-metrics': 1,\n",
       "         'updatebatchsize': 1,\n",
       "         'plaidml': 1,\n",
       "         'detection': 1,\n",
       "         'huffman-code': 1,\n",
       "         'frameworks': 1,\n",
       "         'mobile': 1,\n",
       "         'django': 1,\n",
       "         'imagedata': 1,\n",
       "         'string-matching': 1,\n",
       "         'low-memory': 1,\n",
       "         'histogram': 1,\n",
       "         'prefetch': 1,\n",
       "         'tensorflow2.x': 1,\n",
       "         'quandl': 1,\n",
       "         'tuples': 1,\n",
       "         'floating-point': 1,\n",
       "         'liblinear': 1,\n",
       "         'multivariate-testing': 1,\n",
       "         'attributes': 1,\n",
       "         'syntax': 1,\n",
       "         'xls': 1,\n",
       "         'mysql': 1,\n",
       "         'type-conversion': 1,\n",
       "         'dummy-variable': 1,\n",
       "         'class': 1,\n",
       "         'dictvectorizer': 1,\n",
       "         'networkx': 1})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counter = Counter()\n",
    "for i,tags in enumerate(sorted_user_tag_df[\"answer_tags\"][0:20]):\n",
    "    for tag in tags:\n",
    "        tag_counter[tag] += 1\n",
    "\n",
    "tag_counter = Counter({k: c for k,c in sorted(tag_counter.items(), key=lambda item: item[1], reverse=True)})\n",
    "\n",
    "tag_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49096c14",
   "metadata": {},
   "source": [
    "# Gesamtanzahl der Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "569b2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedbee5a",
   "metadata": {},
   "source": [
    "# Textähnlichkeiten der Experten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = {}\n",
    "\n",
    "for i in range(0, len(top_users_posts)):        \n",
    "    doc_dict[top_users_posts.iloc[i][\"AnswerUserId\"]] = doc_dict.get(top_users_posts.iloc[i][\"AnswerUserId\"], '') + ' ' + clean_bodys(top_users_posts.iloc[i][\"AnswerBody\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ce888f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>K2 x,z  can be 0.Then this value is not well-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>In short yes, you should include each class. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>Here are the original input variables:A is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>If you got  from git you should find in  fold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>Value iteration is used when you have transit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>In  documentation, it is mentioned: What you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>I see 3 possible ways to solve this:1  try to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>To understand how backpropagation is even pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>You have already split on weather and gender....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>Majority of machine learning algorithms work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>As of TensorFlow 0.8, there is now a  that ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>As with standard matrix multiplication, if  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>As discussed in , a deconvolution is just a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>It's easy for tf.keras!This optimizer will cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>I think there is a bit of a confusion here.An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>currently it's not implemented, but you can u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>Call a  in Keras to see all the layers. An in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>You should not pass  into the RandomizedSearc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>I want to explain with picture from .In a nut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>Actually, setting  for the Embedding layer do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Doc\n",
       "1060350    K2 x,z  can be 0.Then this value is not well-...\n",
       "2658050    In short yes, you should include each class. ...\n",
       "4561314    Here are the original input variables:A is a ...\n",
       "1714410    If you got  from git you should find in  fold...\n",
       "562769     Value iteration is used when you have transit...\n",
       "4685471    In  documentation, it is mentioned: What you ...\n",
       "5025009    I see 3 possible ways to solve this:1  try to...\n",
       "5974433    To understand how backpropagation is even pos...\n",
       "4785185    You have already split on weather and gender....\n",
       "1090562    Majority of machine learning algorithms work ...\n",
       "5545260    As of TensorFlow 0.8, there is now a  that ca...\n",
       "3574081    As with standard matrix multiplication, if  h...\n",
       "712995     As discussed in , a deconvolution is just a c...\n",
       "10908375   It's easy for tf.keras!This optimizer will cl...\n",
       "349130     I think there is a bit of a confusion here.An...\n",
       "5741205    currently it's not implemented, but you can u...\n",
       "2097240    Call a  in Keras to see all the layers. An in...\n",
       "3374996    You should not pass  into the RandomizedSearc...\n",
       "6730309    I want to explain with picture from .In a nut...\n",
       "2099607    Actually, setting  for the Embedding layer do..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_df = pd.DataFrame.from_dict(doc_dict, orient=\"index\", columns=[\"Doc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "805417cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146651\n",
      "457832\n",
      "42612\n",
      "145811\n",
      "54218\n",
      "478490\n",
      "27474\n",
      "144713\n",
      "220743\n",
      "17415\n",
      "9961\n",
      "40127\n",
      "242731\n",
      "37994\n",
      "58081\n",
      "15306\n",
      "114026\n",
      "100284\n",
      "2030\n",
      "196788\n"
     ]
    }
   ],
   "source": [
    "for post in doc_df.itertuples():\n",
    "    print(len(post[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "col = 0\n",
    "\n",
    "doc_sim_matrix = []\n",
    "\n",
    "while i < len(doc_df) - 1:\n",
    "    print(i)\n",
    "    doc1 = nlp(doc_df.iloc[i][\"Doc\"])\n",
    "    doc_sim_vec = []\n",
    "    \n",
    "    j = col + 1\n",
    "    while j < len(doc_df):\n",
    "        print(j)\n",
    "        doc2 = nlp(doc_df.iloc[j][\"Doc\"])\n",
    "        sim = doc1.similarity(doc2)\n",
    "        doc_sim_vec.append(sim)                \n",
    "        j += 1\n",
    "    doc_sim_matrix.append(doc_sim_vec)\n",
    "    col += 1\n",
    "    i += 1\n",
    "    print('---')\n",
    "doc_sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "153caf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ab35295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.992634</td>\n",
       "      <td>0.993036</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>0.994728</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.993858</td>\n",
       "      <td>0.996933</td>\n",
       "      <td>0.995932</td>\n",
       "      <td>0.994589</td>\n",
       "      <td>0.989918</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.994795</td>\n",
       "      <td>0.995843</td>\n",
       "      <td>0.985585</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.993855</td>\n",
       "      <td>0.766346</td>\n",
       "      <td>0.991891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994438</td>\n",
       "      <td>0.993793</td>\n",
       "      <td>0.996806</td>\n",
       "      <td>0.996435</td>\n",
       "      <td>0.989719</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.995539</td>\n",
       "      <td>0.994862</td>\n",
       "      <td>0.991263</td>\n",
       "      <td>0.997294</td>\n",
       "      <td>0.994282</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>0.986199</td>\n",
       "      <td>0.996003</td>\n",
       "      <td>0.993757</td>\n",
       "      <td>0.769810</td>\n",
       "      <td>0.993845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997096</td>\n",
       "      <td>0.994884</td>\n",
       "      <td>0.993524</td>\n",
       "      <td>0.994794</td>\n",
       "      <td>0.994390</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.991792</td>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.996216</td>\n",
       "      <td>0.996506</td>\n",
       "      <td>0.993954</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.988790</td>\n",
       "      <td>0.994016</td>\n",
       "      <td>0.994840</td>\n",
       "      <td>0.779966</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995506</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>0.995550</td>\n",
       "      <td>0.995713</td>\n",
       "      <td>0.993450</td>\n",
       "      <td>0.993611</td>\n",
       "      <td>0.996629</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.996234</td>\n",
       "      <td>0.997647</td>\n",
       "      <td>0.991585</td>\n",
       "      <td>0.996316</td>\n",
       "      <td>0.996049</td>\n",
       "      <td>0.776746</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995417</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>0.998064</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.991776</td>\n",
       "      <td>0.997432</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.996675</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.998123</td>\n",
       "      <td>0.996326</td>\n",
       "      <td>0.773945</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.991593</td>\n",
       "      <td>0.993703</td>\n",
       "      <td>0.997437</td>\n",
       "      <td>0.993970</td>\n",
       "      <td>0.995750</td>\n",
       "      <td>0.991873</td>\n",
       "      <td>0.997488</td>\n",
       "      <td>0.995015</td>\n",
       "      <td>0.995732</td>\n",
       "      <td>0.985639</td>\n",
       "      <td>0.995633</td>\n",
       "      <td>0.995586</td>\n",
       "      <td>0.757010</td>\n",
       "      <td>0.994193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.993106</td>\n",
       "      <td>0.993233</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>0.990921</td>\n",
       "      <td>0.993404</td>\n",
       "      <td>0.992842</td>\n",
       "      <td>0.995177</td>\n",
       "      <td>0.993195</td>\n",
       "      <td>0.995065</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.779525</td>\n",
       "      <td>0.994580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.995090</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.993664</td>\n",
       "      <td>0.995988</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.995447</td>\n",
       "      <td>0.988966</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.995113</td>\n",
       "      <td>0.753082</td>\n",
       "      <td>0.995524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995245</td>\n",
       "      <td>0.996245</td>\n",
       "      <td>0.993385</td>\n",
       "      <td>0.998221</td>\n",
       "      <td>0.996658</td>\n",
       "      <td>0.997135</td>\n",
       "      <td>0.987684</td>\n",
       "      <td>0.997485</td>\n",
       "      <td>0.996049</td>\n",
       "      <td>0.768711</td>\n",
       "      <td>0.995350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995769</td>\n",
       "      <td>0.991023</td>\n",
       "      <td>0.996259</td>\n",
       "      <td>0.997098</td>\n",
       "      <td>0.995174</td>\n",
       "      <td>0.988153</td>\n",
       "      <td>0.996704</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.760570</td>\n",
       "      <td>0.992043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.993115</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.995850</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>0.985704</td>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.994508</td>\n",
       "      <td>0.764659</td>\n",
       "      <td>0.993539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.993273</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.988754</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.759497</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.998143</td>\n",
       "      <td>0.987333</td>\n",
       "      <td>0.997510</td>\n",
       "      <td>0.996093</td>\n",
       "      <td>0.764808</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.996992</td>\n",
       "      <td>0.992626</td>\n",
       "      <td>0.998856</td>\n",
       "      <td>0.997631</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.995472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.989282</td>\n",
       "      <td>0.997566</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.772192</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.990712</td>\n",
       "      <td>0.992409</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.990028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.996702</td>\n",
       "      <td>0.772020</td>\n",
       "      <td>0.995880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.762333</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.767102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.998271  0.992634  0.993036  0.996990  0.994728  0.989189  0.993858   \n",
       "1   0.994438  0.993793  0.996806  0.996435  0.989719  0.995312  0.997449   \n",
       "2   0.997096  0.994884  0.993524  0.994794  0.994390  0.996388  0.991792   \n",
       "3   0.995506  0.992427  0.994934  0.995550  0.995713  0.993450  0.993611   \n",
       "4   0.995417  0.994614  0.996582  0.998064  0.997190  0.995996  0.991776   \n",
       "5   0.991593  0.993703  0.997437  0.993970  0.995750  0.991873  0.997488   \n",
       "6   0.993106  0.993233  0.992416  0.990921  0.993404  0.992842  0.995177   \n",
       "7   0.995966  0.995090  0.994158  0.993664  0.995988  0.994750  0.995447   \n",
       "8   0.995245  0.996245  0.993385  0.998221  0.996658  0.997135  0.987684   \n",
       "9   0.995769  0.991023  0.996259  0.997098  0.995174  0.988153  0.996704   \n",
       "10  0.993115  0.997776  0.995850  0.995965  0.985704  0.996223  0.994508   \n",
       "11  0.994956  0.993273  0.996064  0.988754  0.992618  0.995117  0.759497   \n",
       "12  0.997004  0.998143  0.987333  0.997510  0.996093  0.764808  0.996493   \n",
       "13  0.996992  0.992626  0.998856  0.997631  0.770925  0.995472       NaN   \n",
       "14  0.989282  0.997566  0.996226  0.772192  0.997689       NaN       NaN   \n",
       "15  0.990712  0.992409  0.794451  0.990028       NaN       NaN       NaN   \n",
       "16  0.996702  0.772020  0.995880       NaN       NaN       NaN       NaN   \n",
       "17  0.762333  0.995849       NaN       NaN       NaN       NaN       NaN   \n",
       "18  0.767102       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0   0.996933  0.995932  0.994589  0.989918  0.996549  0.994795  0.995843   \n",
       "1   0.995539  0.994862  0.991263  0.997294  0.994282  0.996877  0.986199   \n",
       "2   0.992760  0.996216  0.996506  0.993954  0.997076  0.988790  0.994016   \n",
       "3   0.996629  0.995825  0.996234  0.997647  0.991585  0.996316  0.996049   \n",
       "4   0.997432  0.997465  0.996675  0.990040  0.998123  0.996326  0.773945   \n",
       "5   0.995015  0.995732  0.985639  0.995633  0.995586  0.757010  0.994193   \n",
       "6   0.993195  0.995065  0.993865  0.996795  0.779525  0.994580       NaN   \n",
       "7   0.988966  0.995094  0.995113  0.753082  0.995524       NaN       NaN   \n",
       "8   0.997485  0.996049  0.768711  0.995350       NaN       NaN       NaN   \n",
       "9   0.995996  0.760570  0.992043       NaN       NaN       NaN       NaN   \n",
       "10  0.764659  0.993539       NaN       NaN       NaN       NaN       NaN   \n",
       "11  0.997013       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "12       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "13       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "14       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "15       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "16       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "17       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "18       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          14        15        16        17        18  \n",
       "0   0.985585  0.995958  0.993855  0.766346  0.991891  \n",
       "1   0.996003  0.993757  0.769810  0.993845       NaN  \n",
       "2   0.994840  0.779966  0.997224       NaN       NaN  \n",
       "3   0.776746  0.997984       NaN       NaN       NaN  \n",
       "4   0.994609       NaN       NaN       NaN       NaN  \n",
       "5        NaN       NaN       NaN       NaN       NaN  \n",
       "6        NaN       NaN       NaN       NaN       NaN  \n",
       "7        NaN       NaN       NaN       NaN       NaN  \n",
       "8        NaN       NaN       NaN       NaN       NaN  \n",
       "9        NaN       NaN       NaN       NaN       NaN  \n",
       "10       NaN       NaN       NaN       NaN       NaN  \n",
       "11       NaN       NaN       NaN       NaN       NaN  \n",
       "12       NaN       NaN       NaN       NaN       NaN  \n",
       "13       NaN       NaN       NaN       NaN       NaN  \n",
       "14       NaN       NaN       NaN       NaN       NaN  \n",
       "15       NaN       NaN       NaN       NaN       NaN  \n",
       "16       NaN       NaN       NaN       NaN       NaN  \n",
       "17       NaN       NaN       NaN       NaN       NaN  \n",
       "18       NaN       NaN       NaN       NaN       NaN  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(doc_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df.iloc[1][\"Doc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d6ce6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
