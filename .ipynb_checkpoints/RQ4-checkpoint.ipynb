{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424d7791",
   "metadata": {},
   "source": [
    "# Forschungsfrage 4\n",
    "Im Folgendem wird die Forschungsfrage 4 behandelt.\n",
    "\n",
    "\tWelche sind die führenden User bzw. Experten und wie tragen diese zu den diskutierten Themen bei? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f1024",
   "metadata": {},
   "source": [
    "# Importieren der Module\n",
    "In der folgenden Zelle werden die benötigten Module, wie zum Beispiel Spacy und scikit-learn importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c54850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy \n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "from bokeh.transform import jitter\n",
    "from bokeh.io import curdoc\n",
    "from bokeh.models import LabelSet\n",
    "import csv\n",
    "import math\n",
    "import networkx as nx\n",
    "import nx_altair as nxa\n",
    "import altair as alt\n",
    "from networkx.drawing.nx_agraph import graphviz_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3874dc",
   "metadata": {},
   "source": [
    "Die Konfiguration der unteren Zelle dient der Auswahl der Datensätze. Um alle Datensätze zu erfassen ist start_post = 0 und end_post = 42637 zu setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "n_tag_posts = 500\n",
    "n_answer_posts = 42637"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0402116",
   "metadata": {},
   "source": [
    "# Datensätze laden\n",
    "Als nächstes müssen die Datensätze aus der exportierten CSV-Datei geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1593004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded csv data\n"
     ]
    }
   ],
   "source": [
    "# Load csv data\n",
    "filepath = os.path.join(os.getcwd(), 'QueryResults_sample_42636_14_05_21.csv')\n",
    "stack_posts = pd.read_csv(filepath, sep = \",\")\n",
    "\n",
    "print(\"loaded csv data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c185024",
   "metadata": {},
   "source": [
    "Im folgendem werden die geladenen Datensätze ausgegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd5c952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionUserId</th>\n",
       "      <th>QuestionUserReputation</th>\n",
       "      <th>QuestionUserDN</th>\n",
       "      <th>Tags</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionScore</th>\n",
       "      <th>title</th>\n",
       "      <th>QuestionBody</th>\n",
       "      <th>QuestionDate</th>\n",
       "      <th>AcceptedAnswer</th>\n",
       "      <th>AnswerUserId</th>\n",
       "      <th>AnswerUserReputation</th>\n",
       "      <th>AnswerUserDN</th>\n",
       "      <th>AnswerScore</th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>AnswerBody</th>\n",
       "      <th>AnswerDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3625340</td>\n",
       "      <td>33</td>\n",
       "      <td>user3625340</td>\n",
       "      <td>&lt;image-processing&gt;&lt;machine-learning&gt;&lt;svm&gt;&lt;feat...</td>\n",
       "      <td>27729199</td>\n",
       "      <td>0</td>\n",
       "      <td>How to find Relevent Features for Comparing Di...</td>\n",
       "      <td>&lt;p&gt;Currently we are doing a project on diagram...</td>\n",
       "      <td>2015-01-01 08:03:13</td>\n",
       "      <td>27733517.0</td>\n",
       "      <td>1056563</td>\n",
       "      <td>45925</td>\n",
       "      <td>StephenBoesch</td>\n",
       "      <td>0</td>\n",
       "      <td>27733517</td>\n",
       "      <td>&lt;p&gt;In regard solely to the difference in scale...</td>\n",
       "      <td>2015-01-01 18:39:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4409773</td>\n",
       "      <td>788</td>\n",
       "      <td>Avis</td>\n",
       "      <td>&lt;java&gt;&lt;machine-learning&gt;&lt;svm&gt;&lt;encog&gt;</td>\n",
       "      <td>27729238</td>\n",
       "      <td>1</td>\n",
       "      <td>SVM using Encog in Java for beginners</td>\n",
       "      <td>&lt;p&gt;I am beginner in SVM. Could someone please ...</td>\n",
       "      <td>2015-01-01 08:10:29</td>\n",
       "      <td>27808712.0</td>\n",
       "      <td>173355</td>\n",
       "      <td>3162</td>\n",
       "      <td>JeffHeaton</td>\n",
       "      <td>1</td>\n",
       "      <td>27808712</td>\n",
       "      <td>&lt;p&gt;In Encog SVM is just a classification or re...</td>\n",
       "      <td>2015-01-06 22:58:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4408281</td>\n",
       "      <td>715</td>\n",
       "      <td>datavinci</td>\n",
       "      <td>&lt;python-2.7&gt;&lt;machine-learning&gt;</td>\n",
       "      <td>27730775</td>\n",
       "      <td>1</td>\n",
       "      <td>Why does not the following code snippet run su...</td>\n",
       "      <td>&lt;p&gt;I was reading Programming Collective Intell...</td>\n",
       "      <td>2015-01-01 12:22:49</td>\n",
       "      <td>27730829.0</td>\n",
       "      <td>367273</td>\n",
       "      <td>436785</td>\n",
       "      <td>NPE</td>\n",
       "      <td>1</td>\n",
       "      <td>27730829</td>\n",
       "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;NameError: global name 'lin...</td>\n",
       "      <td>2015-01-01 12:32:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3512217</td>\n",
       "      <td>119</td>\n",
       "      <td>Shlomi</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;svm&gt;</td>\n",
       "      <td>27730870</td>\n",
       "      <td>-1</td>\n",
       "      <td>division of two proper kernels</td>\n",
       "      <td>&lt;p&gt;Let &lt;img src=\"https://i.stack.imgur.com/Z1G...</td>\n",
       "      <td>2015-01-01 12:37:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060350</td>\n",
       "      <td>70610</td>\n",
       "      <td>Has QUIT--Anony-Mousse</td>\n",
       "      <td>0</td>\n",
       "      <td>27742921</td>\n",
       "      <td>&lt;p&gt;K2(x,z) can be 0.&lt;/p&gt;\\n\\n&lt;p&gt;Then this value...</td>\n",
       "      <td>2015-01-02 13:22:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4405757</td>\n",
       "      <td>14440</td>\n",
       "      <td>user7</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;classification&gt;&lt;weka&gt;&lt;libsv...</td>\n",
       "      <td>27732503</td>\n",
       "      <td>0</td>\n",
       "      <td>One class SVM to detect outliers</td>\n",
       "      <td>&lt;p&gt;My problem is&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n  &lt;p&gt;I w...</td>\n",
       "      <td>2015-01-01 16:26:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060350</td>\n",
       "      <td>70610</td>\n",
       "      <td>Has QUIT--Anony-Mousse</td>\n",
       "      <td>5</td>\n",
       "      <td>27739848</td>\n",
       "      <td>&lt;p&gt;Your data is not formatted appropriately fo...</td>\n",
       "      <td>2015-01-02 09:20:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42631</th>\n",
       "      <td>14926602</td>\n",
       "      <td>21</td>\n",
       "      <td>Waqar Kaleem Khan</td>\n",
       "      <td>&lt;tensorflow&gt;&lt;machine-learning&gt;&lt;keras&gt;&lt;deep-lea...</td>\n",
       "      <td>67441958</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM input layer shape in Keras using function...</td>\n",
       "      <td>&lt;p&gt;I am trying to implement LSTMs on drug data...</td>\n",
       "      <td>2021-05-07 21:38:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5927701</td>\n",
       "      <td>2972</td>\n",
       "      <td>data_person</td>\n",
       "      <td>1</td>\n",
       "      <td>67442769</td>\n",
       "      <td>&lt;p&gt;Try adding an &lt;code&gt;Embedding Layer&lt;/code&gt; ...</td>\n",
       "      <td>2021-05-07 23:36:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42632</th>\n",
       "      <td>3973175</td>\n",
       "      <td>4261</td>\n",
       "      <td>con</td>\n",
       "      <td>&lt;python&gt;&lt;python-3.x&gt;&lt;machine-learning&gt;&lt;shap&gt;</td>\n",
       "      <td>67443411</td>\n",
       "      <td>2</td>\n",
       "      <td>How to get feature names of shap_values from T...</td>\n",
       "      <td>&lt;p&gt;I am doing a shap tutorial, and attempting ...</td>\n",
       "      <td>2021-05-08 01:56:51</td>\n",
       "      <td>67444552.0</td>\n",
       "      <td>3954379</td>\n",
       "      <td>5202</td>\n",
       "      <td>Lucas</td>\n",
       "      <td>2</td>\n",
       "      <td>67444552</td>\n",
       "      <td>&lt;p&gt;The features are indeed in the same order, ...</td>\n",
       "      <td>2021-05-08 06:02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42633</th>\n",
       "      <td>15847767</td>\n",
       "      <td>1</td>\n",
       "      <td>Pearl</td>\n",
       "      <td>&lt;python&gt;&lt;machine-learning&gt;&lt;keras&gt;&lt;neural-network&gt;</td>\n",
       "      <td>67443744</td>\n",
       "      <td>-1</td>\n",
       "      <td>What does hidden_layer = layers.Dense(100, act...</td>\n",
       "      <td>&lt;p&gt;I saw the following in &lt;a href=\"https://www...</td>\n",
       "      <td>2021-05-08 03:14:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15166370</td>\n",
       "      <td>45</td>\n",
       "      <td>Vibhav Surve</td>\n",
       "      <td>0</td>\n",
       "      <td>67443785</td>\n",
       "      <td>&lt;p&gt;See input layer is nothing but how many neu...</td>\n",
       "      <td>2021-05-08 03:22:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42634</th>\n",
       "      <td>14551464</td>\n",
       "      <td>61</td>\n",
       "      <td>Onkar Chougule</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;pytorch&gt;&lt;con...</td>\n",
       "      <td>67449276</td>\n",
       "      <td>0</td>\n",
       "      <td>Initalize using previous .pth and train for fu...</td>\n",
       "      <td>&lt;p&gt;How do I initialize a UNet model from its p...</td>\n",
       "      <td>2021-05-08 15:36:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14551464</td>\n",
       "      <td>61</td>\n",
       "      <td>Onkar Chougule</td>\n",
       "      <td>0</td>\n",
       "      <td>67451326</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;state= torch.load(&amp;quot;/content/mo...</td>\n",
       "      <td>2021-05-08 19:21:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42635</th>\n",
       "      <td>15409153</td>\n",
       "      <td>7</td>\n",
       "      <td>maritsae</td>\n",
       "      <td>&lt;python&gt;&lt;machine-learning&gt;&lt;prediction&gt;</td>\n",
       "      <td>67449334</td>\n",
       "      <td>-2</td>\n",
       "      <td>How to get probabilities of each predicted val...</td>\n",
       "      <td>&lt;p&gt;I am currently working on disease predictio...</td>\n",
       "      <td>2021-05-08 15:40:50</td>\n",
       "      <td>67449543.0</td>\n",
       "      <td>1458722</td>\n",
       "      <td>884</td>\n",
       "      <td>Hrishikesh</td>\n",
       "      <td>0</td>\n",
       "      <td>67449543</td>\n",
       "      <td>&lt;p&gt;If you're using scikit-learn, you can use &lt;...</td>\n",
       "      <td>2021-05-08 16:01:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42636 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QuestionUserId  QuestionUserReputation     QuestionUserDN  \\\n",
       "0             3625340                      33        user3625340   \n",
       "1             4409773                     788               Avis   \n",
       "2             4408281                     715          datavinci   \n",
       "3             3512217                     119             Shlomi   \n",
       "4             4405757                   14440              user7   \n",
       "...               ...                     ...                ...   \n",
       "42631        14926602                      21  Waqar Kaleem Khan   \n",
       "42632         3973175                    4261                con   \n",
       "42633        15847767                       1              Pearl   \n",
       "42634        14551464                      61     Onkar Chougule   \n",
       "42635        15409153                       7           maritsae   \n",
       "\n",
       "                                                    Tags  QuestionId  \\\n",
       "0      <image-processing><machine-learning><svm><feat...    27729199   \n",
       "1                   <java><machine-learning><svm><encog>    27729238   \n",
       "2                         <python-2.7><machine-learning>    27730775   \n",
       "3                                <machine-learning><svm>    27730870   \n",
       "4      <machine-learning><classification><weka><libsv...    27732503   \n",
       "...                                                  ...         ...   \n",
       "42631  <tensorflow><machine-learning><keras><deep-lea...    67441958   \n",
       "42632       <python><python-3.x><machine-learning><shap>    67443411   \n",
       "42633  <python><machine-learning><keras><neural-network>    67443744   \n",
       "42634  <machine-learning><deep-learning><pytorch><con...    67449276   \n",
       "42635             <python><machine-learning><prediction>    67449334   \n",
       "\n",
       "       QuestionScore                                              title  \\\n",
       "0                  0  How to find Relevent Features for Comparing Di...   \n",
       "1                  1              SVM using Encog in Java for beginners   \n",
       "2                  1  Why does not the following code snippet run su...   \n",
       "3                 -1                     division of two proper kernels   \n",
       "4                  0                   One class SVM to detect outliers   \n",
       "...              ...                                                ...   \n",
       "42631              0  LSTM input layer shape in Keras using function...   \n",
       "42632              2  How to get feature names of shap_values from T...   \n",
       "42633             -1  What does hidden_layer = layers.Dense(100, act...   \n",
       "42634              0  Initalize using previous .pth and train for fu...   \n",
       "42635             -2  How to get probabilities of each predicted val...   \n",
       "\n",
       "                                            QuestionBody         QuestionDate  \\\n",
       "0      <p>Currently we are doing a project on diagram...  2015-01-01 08:03:13   \n",
       "1      <p>I am beginner in SVM. Could someone please ...  2015-01-01 08:10:29   \n",
       "2      <p>I was reading Programming Collective Intell...  2015-01-01 12:22:49   \n",
       "3      <p>Let <img src=\"https://i.stack.imgur.com/Z1G...  2015-01-01 12:37:59   \n",
       "4      <p>My problem is</p>\\n\\n<blockquote>\\n  <p>I w...  2015-01-01 16:26:06   \n",
       "...                                                  ...                  ...   \n",
       "42631  <p>I am trying to implement LSTMs on drug data...  2021-05-07 21:38:47   \n",
       "42632  <p>I am doing a shap tutorial, and attempting ...  2021-05-08 01:56:51   \n",
       "42633  <p>I saw the following in <a href=\"https://www...  2021-05-08 03:14:14   \n",
       "42634  <p>How do I initialize a UNet model from its p...  2021-05-08 15:36:01   \n",
       "42635  <p>I am currently working on disease predictio...  2021-05-08 15:40:50   \n",
       "\n",
       "       AcceptedAnswer  AnswerUserId  AnswerUserReputation  \\\n",
       "0          27733517.0       1056563                 45925   \n",
       "1          27808712.0        173355                  3162   \n",
       "2          27730829.0        367273                436785   \n",
       "3                 NaN       1060350                 70610   \n",
       "4                 NaN       1060350                 70610   \n",
       "...               ...           ...                   ...   \n",
       "42631             NaN       5927701                  2972   \n",
       "42632      67444552.0       3954379                  5202   \n",
       "42633             NaN      15166370                    45   \n",
       "42634             NaN      14551464                    61   \n",
       "42635      67449543.0       1458722                   884   \n",
       "\n",
       "                 AnswerUserDN  AnswerScore  AnswerId  \\\n",
       "0               StephenBoesch            0  27733517   \n",
       "1                  JeffHeaton            1  27808712   \n",
       "2                         NPE            1  27730829   \n",
       "3      Has QUIT--Anony-Mousse            0  27742921   \n",
       "4      Has QUIT--Anony-Mousse            5  27739848   \n",
       "...                       ...          ...       ...   \n",
       "42631             data_person            1  67442769   \n",
       "42632                   Lucas            2  67444552   \n",
       "42633            Vibhav Surve            0  67443785   \n",
       "42634          Onkar Chougule            0  67451326   \n",
       "42635              Hrishikesh            0  67449543   \n",
       "\n",
       "                                              AnswerBody           AnswerDate  \n",
       "0      <p>In regard solely to the difference in scale...  2015-01-01 18:39:02  \n",
       "1      <p>In Encog SVM is just a classification or re...  2015-01-06 22:58:03  \n",
       "2      <blockquote>\\n  <p>NameError: global name 'lin...  2015-01-01 12:32:19  \n",
       "3      <p>K2(x,z) can be 0.</p>\\n\\n<p>Then this value...  2015-01-02 13:22:27  \n",
       "4      <p>Your data is not formatted appropriately fo...  2015-01-02 09:20:50  \n",
       "...                                                  ...                  ...  \n",
       "42631  <p>Try adding an <code>Embedding Layer</code> ...  2021-05-07 23:36:34  \n",
       "42632  <p>The features are indeed in the same order, ...  2021-05-08 06:02:39  \n",
       "42633  <p>See input layer is nothing but how many neu...  2021-05-08 03:22:03  \n",
       "42634  <pre><code>state= torch.load(&quot;/content/mo...  2021-05-08 19:21:01  \n",
       "42635  <p>If you're using scikit-learn, you can use <...  2021-05-08 16:01:52  \n",
       "\n",
       "[42636 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6a3ecc",
   "metadata": {},
   "source": [
    "# Datenbereinigung\n",
    "Die nächste Zelle definiert eine Funktion zum Bereinigen der Tags, um spitze Klammern zu entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c260a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning functions\n",
    "\n",
    "# clean all angle brackets from string\n",
    "def clean_tags(tags):    \n",
    "    tag_list = []\n",
    "    # clean tags from '>' and '<' occurences\n",
    "    tags = re.sub('><', ' ', tags) \n",
    "    tags = re.sub('<|>', '', tags)\n",
    "    # add single tag of tags and add it to lists and sets\n",
    "    for tag in tags.split():\n",
    "        if tag != 'machine-learning':\n",
    "            tag_list.append(tag)\n",
    "    return tag_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfc07b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all duplicates in posts\n",
    "df_w_dupes = pd.DataFrame(stack_posts[0:n_answer_posts])\n",
    "df_wo_dupes = df_w_dupes.drop_duplicates([\"QuestionId\"])\n",
    "df_sorted_wo_dupes = df_wo_dupes.sort_values(by=[\"QuestionId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8ba62",
   "metadata": {},
   "source": [
    "# Useranalyse\n",
    "Im Folgendem werden die Statistiken der User erstellt. Hierzu gehört unteranderem das Erstellen des User-Objekts, die Berechnung der Reputation und Speicherung der jeweiligen Tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665fe572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extact user stats (reputation in question/answers, question-/answers counts, amount of accepted answers etc.)\n",
    "users = dict()\n",
    "\n",
    "def create_user_stats(id, display_name):\n",
    "    # add user if userid does not exist\n",
    "    if id not in users:\n",
    "        users[id] = dict()    \n",
    "        users[id][\"display_name\"] = display_name\n",
    "        \n",
    "# customize stats which every user has\n",
    "def customize_user_base_stats(id, score, post_type):    \n",
    "    users[id][post_type + \"_reputation\"] = users[id].get(post_type + \"_reputation\", 0) + score * 10   \n",
    "    users[id][post_type + '_count'] = users[id].get(post_type + '_count', 0) + 1\n",
    "\n",
    "\n",
    "# iterate over dataframe tuples\n",
    "for i, post in enumerate(df_w_dupes.itertuples()):  \n",
    "    # create DataFrame from pandas.core.frame so column names can be used instead of indexes\n",
    "    post = pd.DataFrame(post).transpose().drop(0, axis=1)\n",
    "    post.columns = stack_posts.columns\n",
    "    \n",
    "    # customize question user stats if question is not a duplicate of previous question\n",
    "    if post[\"QuestionId\"][0] != df_w_dupes.iloc[i - 1][\"QuestionId\"]:\n",
    "        question_user_id = post[\"QuestionUserId\"][0]\n",
    "        create_user_stats(question_user_id, post[\"QuestionUserDN\"][0])\n",
    "        \n",
    "        # customize question user stats        \n",
    "        customize_user_base_stats(question_user_id,post[\"QuestionScore\"][0], \"question\")\n",
    "        cleaned_tags = clean_tags(post[\"Tags\"][0])\n",
    "        users[question_user_id][\"question_tags\"] = set(users[question_user_id].get(\"question_tags\", set()).union(cleaned_tags))\n",
    "                    \n",
    "                \n",
    "    # create answer user stats\n",
    "    answer_user_id = post[\"AnswerUserId\"][0]\n",
    "    create_user_stats(answer_user_id, post[\"AnswerUserDN\"][0])\n",
    "        \n",
    "    customize_user_base_stats(answer_user_id,post[\"AnswerScore\"][0], \"answer\")\n",
    "    users[answer_user_id][\"answer_tags\"] = set(users[answer_user_id].get(\"answer_tags\", set()).union(cleaned_tags))\n",
    "    if post[\"AcceptedAnswer\"][0] == post[\"AnswerId\"][0]:\n",
    "        users[answer_user_id][\"accepted_answer_count\"] = users[answer_user_id].get(\"accepted_answer_count\", 0) + 1\n",
    "        users[answer_user_id][\"answer_reputation\"] = users[answer_user_id].get(\"answer_reputation\", 0) + 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94753b8",
   "metadata": {},
   "source": [
    "Der entstandene Dataframe wird nun transponiert und nach der Reputation der Antworten sortiert ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c856f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame(users).transpose()\n",
    "sorted_user_df = user_df.sort_values(by=['answer_reputation'], ascending=False)\n",
    "#sorted_user_df = sorted_user_df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb71f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_name</th>\n",
       "      <th>question_reputation</th>\n",
       "      <th>question_count</th>\n",
       "      <th>question_tags</th>\n",
       "      <th>answer_reputation</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>answer_tags</th>\n",
       "      <th>accepted_answer_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>desertnaut</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{shap, scikit-learn}</td>\n",
       "      <td>31680</td>\n",
       "      <td>579</td>\n",
       "      <td>{hyperparameters, random-forest, ios, kaggle, ...</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>lejlot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25015</td>\n",
       "      <td>618</td>\n",
       "      <td>{documentation, twitter, random-forest, time-s...</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>Marcin Możejko</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>{embedding, neural-network, nlp, grid-search, ...</td>\n",
       "      <td>22335</td>\n",
       "      <td>238</td>\n",
       "      <td>{hyperparameters, google-cloud-platform, plot,...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>Maxim</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>{neural-network, python, deep-learning, tensor...</td>\n",
       "      <td>20950</td>\n",
       "      <td>378</td>\n",
       "      <td>{hyperparameters, doc2vec, seq2seq, machine-le...</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>Shai</td>\n",
       "      <td>1020</td>\n",
       "      <td>9</td>\n",
       "      <td>{neural-network, python, gradient-descent, lin...</td>\n",
       "      <td>16625</td>\n",
       "      <td>309</td>\n",
       "      <td>{tensor, matplotlib, reduction, performance, d...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>today</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14080</td>\n",
       "      <td>318</td>\n",
       "      <td>{signal-processing, hyperparameters, predict, ...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>Vivek Kumar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9175</td>\n",
       "      <td>182</td>\n",
       "      <td>{hyperparameters, random-forest, gaussian, dat...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>dga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8445</td>\n",
       "      <td>14</td>\n",
       "      <td>{c++, neural-network, image-processing, python...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>Daniel Möller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8265</td>\n",
       "      <td>186</td>\n",
       "      <td>{tensor, time-series, optimization, recurrent-...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>Martin Thoma</td>\n",
       "      <td>490</td>\n",
       "      <td>6</td>\n",
       "      <td>{c++, image-processing, amazon-sagemaker, tens...</td>\n",
       "      <td>7830</td>\n",
       "      <td>92</td>\n",
       "      <td>{handwriting-recognition, dbscan, data-science...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>Prune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7820</td>\n",
       "      <td>266</td>\n",
       "      <td>{random-forest, svd, proof, google-cloud-platf...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>stackoverflowuser2010</td>\n",
       "      <td>1860</td>\n",
       "      <td>19</td>\n",
       "      <td>{pandas, classification, tensorflow, keras, sc...</td>\n",
       "      <td>7545</td>\n",
       "      <td>46</td>\n",
       "      <td>{pandas, predict, uncertainty, tf.keras, sciki...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>mrry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7285</td>\n",
       "      <td>79</td>\n",
       "      <td>{distributed, build, tensorflow-datasets, data...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>Salvador Dali</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{python, scikit-learn}</td>\n",
       "      <td>6610</td>\n",
       "      <td>35</td>\n",
       "      <td>{nltk, matplotlib, scikit-learn, deep-learning...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>Has QUIT--Anony-Mousse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6200</td>\n",
       "      <td>356</td>\n",
       "      <td>{twitter, self-organizing-maps, random-forest,...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>Dr. Snoopy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5290</td>\n",
       "      <td>172</td>\n",
       "      <td>{predict, tensor, time-series, data-science, a...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>Nicolas Gervais</td>\n",
       "      <td>240</td>\n",
       "      <td>11</td>\n",
       "      <td>{python, keras, tensorflow, scikit-learn, pyto...</td>\n",
       "      <td>5165</td>\n",
       "      <td>131</td>\n",
       "      <td>{pandas, tensorflow-datasets, random-forest, s...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>seralouk</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>{eli5, roc, classification, python-2.7, python...</td>\n",
       "      <td>5140</td>\n",
       "      <td>99</td>\n",
       "      <td>{hyperparameters, predict, random-forest, matp...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>MaxU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4915</td>\n",
       "      <td>80</td>\n",
       "      <td>{svd, vector, kaggle, octave, matplotlib, data...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>runhani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4840</td>\n",
       "      <td>1</td>\n",
       "      <td>{conv-neural-network, signal-processing, deep-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    display_name question_reputation question_count  \\\n",
       "4685471               desertnaut                  10              1   \n",
       "2658050                   lejlot                 NaN            NaN   \n",
       "5974433           Marcin Możejko                  70              3   \n",
       "712995                     Maxim                  40              1   \n",
       "1714410                     Shai                1020              9   \n",
       "2099607                    today                 NaN            NaN   \n",
       "3374996              Vivek Kumar                 NaN            NaN   \n",
       "5545260                      dga                 NaN            NaN   \n",
       "2097240            Daniel Möller                 NaN            NaN   \n",
       "562769              Martin Thoma                 490              6   \n",
       "4785185                    Prune                 NaN            NaN   \n",
       "4561314    stackoverflowuser2010                1860             19   \n",
       "3574081                     mrry                 NaN            NaN   \n",
       "1090562            Salvador Dali                   0              1   \n",
       "1060350   Has QUIT--Anony-Mousse                 NaN            NaN   \n",
       "349130                Dr. Snoopy                 NaN            NaN   \n",
       "10908375         Nicolas Gervais                 240             11   \n",
       "5025009                 seralouk                 110              3   \n",
       "5741205                     MaxU                 NaN            NaN   \n",
       "6730309                  runhani                 NaN            NaN   \n",
       "\n",
       "                                              question_tags answer_reputation  \\\n",
       "4685471                                {shap, scikit-learn}             31680   \n",
       "2658050                                                 NaN             25015   \n",
       "5974433   {embedding, neural-network, nlp, grid-search, ...             22335   \n",
       "712995    {neural-network, python, deep-learning, tensor...             20950   \n",
       "1714410   {neural-network, python, gradient-descent, lin...             16625   \n",
       "2099607                                                 NaN             14080   \n",
       "3374996                                                 NaN              9175   \n",
       "5545260                                                 NaN              8445   \n",
       "2097240                                                 NaN              8265   \n",
       "562769    {c++, image-processing, amazon-sagemaker, tens...              7830   \n",
       "4785185                                                 NaN              7820   \n",
       "4561314   {pandas, classification, tensorflow, keras, sc...              7545   \n",
       "3574081                                                 NaN              7285   \n",
       "1090562                              {python, scikit-learn}              6610   \n",
       "1060350                                                 NaN              6200   \n",
       "349130                                                  NaN              5290   \n",
       "10908375  {python, keras, tensorflow, scikit-learn, pyto...              5165   \n",
       "5025009   {eli5, roc, classification, python-2.7, python...              5140   \n",
       "5741205                                                 NaN              4915   \n",
       "6730309                                                 NaN              4840   \n",
       "\n",
       "         answer_count                                        answer_tags  \\\n",
       "4685471           579  {hyperparameters, random-forest, ios, kaggle, ...   \n",
       "2658050           618  {documentation, twitter, random-forest, time-s...   \n",
       "5974433           238  {hyperparameters, google-cloud-platform, plot,...   \n",
       "712995            378  {hyperparameters, doc2vec, seq2seq, machine-le...   \n",
       "1714410           309  {tensor, matplotlib, reduction, performance, d...   \n",
       "2099607           318  {signal-processing, hyperparameters, predict, ...   \n",
       "3374996           182  {hyperparameters, random-forest, gaussian, dat...   \n",
       "5545260            14  {c++, neural-network, image-processing, python...   \n",
       "2097240           186  {tensor, time-series, optimization, recurrent-...   \n",
       "562769             92  {handwriting-recognition, dbscan, data-science...   \n",
       "4785185           266  {random-forest, svd, proof, google-cloud-platf...   \n",
       "4561314            46  {pandas, predict, uncertainty, tf.keras, sciki...   \n",
       "3574081            79  {distributed, build, tensorflow-datasets, data...   \n",
       "1090562            35  {nltk, matplotlib, scikit-learn, deep-learning...   \n",
       "1060350           356  {twitter, self-organizing-maps, random-forest,...   \n",
       "349130            172  {predict, tensor, time-series, data-science, a...   \n",
       "10908375          131  {pandas, tensorflow-datasets, random-forest, s...   \n",
       "5025009            99  {hyperparameters, predict, random-forest, matp...   \n",
       "5741205            80  {svd, vector, kaggle, octave, matplotlib, data...   \n",
       "6730309             1  {conv-neural-network, signal-processing, deep-...   \n",
       "\n",
       "         accepted_answer_count  \n",
       "4685471                    458  \n",
       "2658050                    363  \n",
       "5974433                    159  \n",
       "712995                     244  \n",
       "1714410                    195  \n",
       "2099607                    250  \n",
       "3374996                    129  \n",
       "5545260                      9  \n",
       "2097240                    105  \n",
       "562769                      32  \n",
       "4785185                    108  \n",
       "4561314                     15  \n",
       "3574081                     51  \n",
       "1090562                     10  \n",
       "1060350                     96  \n",
       "349130                      76  \n",
       "10908375                    75  \n",
       "5025009                     52  \n",
       "5741205                     47  \n",
       "6730309                    NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_user_df[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2934aa2",
   "metadata": {},
   "source": [
    "Anschließend werden nur die Posts der führenden 20 Experten für weitere Analysen ausgewählt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd2218ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select posts from top users\n",
    "top_answer_users = sorted_user_df[0:20]\n",
    "top_users_posts = stack_posts[stack_posts[\"AnswerUserId\"].isin(top_answer_users.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e997bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean answers\n",
    "regex_pattern = '(<(pre|code|blockquote|a|strike)(.|\\n)*?\\/(pre|code|blockquote|a|strike)>)*?|<(p|b|br|br(.|\\n)*?\\/|sub|sup|em|strong|hr|s|i|ol|ul|li|code)*?>|<\\/(p|b|br|sub|sup|em|strong|s|i|ol|ul|li|div|pre|blockquote|a|code)>|<h(.|\\n)*?>(.|\\n)*?<\\/h(.|\\n)*?>*?|(<(img|div|ol|ul|li)(.|\\n)*?\\/*?>)|\\n'\n",
    "def clean_bodys(text):\n",
    "    text = re.sub(regex_pattern, '', text, flags=re.I)\n",
    "    text = re.sub('\\(|\\)', ' ', text, flags=re.I)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf976c",
   "metadata": {},
   "source": [
    "Die nächste Zelle definiert zwei Hilffunktionen, die für die Visualisierung der Daten verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47601acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plot_configs(p):\n",
    "    p.background_fill_color = '#929191'\n",
    "    p.border_fill_color = '#666666'\n",
    "    p.background_fill_alpha = 0.45\n",
    "    p.border_fill_alpha = 0.25\n",
    "    p.xgrid.grid_line_color = '#afafaf'\n",
    "    p.ygrid.grid_line_color = '#afafaf'\n",
    "    p.xgrid.grid_line_alpha = 0.3\n",
    "    p.ygrid.grid_line_alpha = 0.3\n",
    "    p.axis.axis_label_text_font = 'Times New Roman'\n",
    "    p.axis.major_label_text_font = 'Times New Roman'    \n",
    "    return p\n",
    "\n",
    "def set_plot_labels(p,x_values,y_values):\n",
    "    sorted_df = top_answer_users.sort_values(by=y_values, ascending=False)\n",
    "    source = dict(\n",
    "        x=sorted_df[x_values][0:10].values,\n",
    "        y=sorted_df[y_values][0:10].values,\n",
    "        names=sorted_df[\"display_name\"][0:10].values\n",
    "    )    \n",
    "        \n",
    "    \n",
    "    labels = LabelSet(\n",
    "                x='x',\n",
    "                y='y',\n",
    "                text='names',\n",
    "                level='glyph',\n",
    "                x_offset=2, \n",
    "                y_offset=2, \n",
    "                text_font_size=\"7pt\",\n",
    "                source=ColumnDataSource(source), \n",
    "                render_mode='canvas')\n",
    "\n",
    "    p.add_layout(labels)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c873b",
   "metadata": {},
   "source": [
    "# Visualisierung\n",
    "In dieser Zelle werden die Experten in einer Grafik visualisiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b3ee151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': array([579, 618, 238, 378, 309, 318, 182, 14, 186, 92], dtype=object), 'y': array([31680, 25015, 22335, 20950, 16625, 14080, 9175, 8445, 8265, 7830],\n",
      "      dtype=object), 'names': array(['desertnaut', 'lejlot', 'Marcin Możejko', 'Maxim', 'Shai', 'today',\n",
      "       'Vivek Kumar', 'dga', 'Daniel Möller', 'Martin Thoma'],\n",
      "      dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "# top users diagram\n",
    "circle_size = 12.5\n",
    "fill_color = '#F48024'\n",
    "\n",
    "p = figure(title=' ', plot_width=600, plot_height=400)\n",
    "\n",
    "curdoc().theme = 'light_minimal'\n",
    "p.circle(top_answer_users['answer_count'], top_answer_users['answer_reputation'], size=circle_size, fill_color=fill_color, line_color='black', line_width=0.5)\n",
    "p.xaxis.axis_label = 'Anzahl Posts'\n",
    "p.yaxis.axis_label = 'Anzahl Reputationspunkte'\n",
    "\n",
    "p = set_plot_configs(p)\n",
    "p = set_plot_labels(p, 'answer_count', 'answer_reputation')\n",
    "\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cbf058",
   "metadata": {},
   "source": [
    "# Metriken/Analysen\n",
    "Die nächsten Zellen zeigen weitere Analysen und Metriken, die die vorherige Analyse ergänzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c262ef3",
   "metadata": {},
   "source": [
    "# Antworten - Akzeptierte Antworten\n",
    "Die folgende Zelle zeigt das Verhältnis der Anzahl von Antworten zu der Anzahl der Akzeptierten Antworten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4817e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': array([579, 618, 318, 378, 309, 238, 182, 266, 186, 356], dtype=object), 'y': array([458, 363, 250, 244, 195, 159, 129, 108, 105, 96], dtype=object), 'names': array(['desertnaut', 'lejlot', 'today', 'Maxim', 'Shai', 'Marcin Możejko',\n",
      "       'Vivek Kumar', 'Prune', 'Daniel Möller', 'Has QUIT--Anony-Mousse'],\n",
      "      dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "p = figure(title=' ', plot_width=500, plot_height=500)\n",
    "\n",
    "curdoc().theme = 'light_minimal'\n",
    "p.circle(top_answer_users['answer_count'], top_answer_users['accepted_answer_count'], size=circle_size, fill_color=fill_color, line_color='black', line_width=0.5)\n",
    "p.xaxis.axis_label = 'Anzahl Antworten'\n",
    "p.yaxis.axis_label = 'Anzahl akzeptierte Anwtorten'\n",
    "\n",
    "p = set_plot_configs(p)\n",
    "p = set_plot_labels(p, 'answer_count', 'accepted_answer_count')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50502883",
   "metadata": {},
   "source": [
    "# Metrik - Antworten/akzeptierte Antworten\n",
    "Rate an akzeptierten Antworten auf Grundlagen von Gesamtanzahl der Antworten unter Experten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab11efa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5920076573342905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desertnaut</th>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Kumar</th>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcin Możejko</th>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrry</th>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxim</th>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dga</th>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai</th>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxU</th>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lejlot</th>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicolas Gervais</th>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Möller</th>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seralouk</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Snoopy</th>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Thoma</th>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflowuser2010</th>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvador Dali</th>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has QUIT--Anony-Mousse</th>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runhani</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Ratio\n",
       "display_name                 \n",
       "desertnaut              0.791\n",
       "today                   0.786\n",
       "Vivek Kumar             0.709\n",
       "Marcin Możejko          0.668\n",
       "mrry                    0.646\n",
       "Maxim                   0.646\n",
       "dga                     0.643\n",
       "Shai                    0.631\n",
       "MaxU                    0.588\n",
       "lejlot                  0.587\n",
       "Nicolas Gervais         0.573\n",
       "Daniel Möller           0.565\n",
       "seralouk                0.525\n",
       "Dr. Snoopy              0.442\n",
       "Prune                   0.406\n",
       "Martin Thoma            0.348\n",
       "stackoverflowuser2010   0.326\n",
       "Salvador Dali           0.286\n",
       "Has QUIT--Anony-Mousse  0.270\n",
       "runhani                 0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_answers = 0\n",
    "\n",
    "for answer_amount in top_answer_users[\"answer_count\"]:\n",
    "    total_answers += answer_amount\n",
    "\n",
    "total_acc_answers = 0\n",
    "for acc_answer_amount in top_answer_users[\"accepted_answer_count\"]:\n",
    "    if math.isnan(acc_answer_amount):\n",
    "        continue\n",
    "    total_acc_answers += acc_answer_amount\n",
    "\n",
    "acc_answer_answer_ratios = []\n",
    "\n",
    "for user in top_answer_users.itertuples():\n",
    "    acc_answer_answer_ratio = user[8]/user[6]\n",
    "    acc_answer_answer_ratios.append(acc_answer_answer_ratio)\n",
    "\n",
    "acc_answer_answer_ratios_df = pd.DataFrame(acc_answer_answer_ratios, index=top_answer_users[\"display_name\"])\n",
    "acc_answer_answer_ratios_df.columns = [\"Ratio\"]\n",
    "acc_answer_answer_ratios_df.fillna(0, inplace=True)\n",
    "acc_answer_answer_ratios_df = acc_answer_answer_ratios_df.sort_values(by=[\"Ratio\"], ascending=False)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "\n",
    "acc_answer_answer_ratio = total_acc_answers/total_answers\n",
    "print(acc_answer_answer_ratio)\n",
    "display(acc_answer_answer_ratios_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d4e44",
   "metadata": {},
   "source": [
    "# Metrik - Reputation pro Antwort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acd1466e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reputation/Antwort</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>runhani</th>\n",
       "      <td>4,840.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dga</th>\n",
       "      <td>603.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvador Dali</th>\n",
       "      <td>188.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflowuser2010</th>\n",
       "      <td>164.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcin Możejko</th>\n",
       "      <td>93.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrry</th>\n",
       "      <td>92.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Thoma</th>\n",
       "      <td>85.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxU</th>\n",
       "      <td>61.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxim</th>\n",
       "      <td>55.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desertnaut</th>\n",
       "      <td>54.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai</th>\n",
       "      <td>53.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seralouk</th>\n",
       "      <td>51.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Kumar</th>\n",
       "      <td>50.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Möller</th>\n",
       "      <td>44.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>44.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lejlot</th>\n",
       "      <td>40.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicolas Gervais</th>\n",
       "      <td>39.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Snoopy</th>\n",
       "      <td>30.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <td>29.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has QUIT--Anony-Mousse</th>\n",
       "      <td>17.416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Reputation/Antwort\n",
       "display_name                              \n",
       "runhani                          4,840.000\n",
       "dga                                603.214\n",
       "Salvador Dali                      188.857\n",
       "stackoverflowuser2010              164.022\n",
       "Marcin Możejko                      93.845\n",
       "mrry                                92.215\n",
       "Martin Thoma                        85.109\n",
       "MaxU                                61.438\n",
       "Maxim                               55.423\n",
       "desertnaut                          54.715\n",
       "Shai                                53.803\n",
       "seralouk                            51.919\n",
       "Vivek Kumar                         50.412\n",
       "Daniel Möller                       44.435\n",
       "today                               44.277\n",
       "lejlot                              40.477\n",
       "Nicolas Gervais                     39.427\n",
       "Dr. Snoopy                          30.756\n",
       "Prune                               29.398\n",
       "Has QUIT--Anony-Mousse              17.416"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "332.05791736784363"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_per_answer_list = []\n",
    "for user in top_answer_users.itertuples():\n",
    "    rep_per_answer = user[5]/user[6]\n",
    "    rep_per_answer_list.append(rep_per_answer)\n",
    "    \n",
    "rep_per_answer_df = pd.DataFrame(rep_per_answer_list, index=top_answer_users[\"display_name\"])\n",
    "rep_per_answer_df.columns = [\"Reputation/Antwort\"]\n",
    "rep_per_answer_df.fillna(0, inplace=True)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "rep_per_answer_df = rep_per_answer_df.sort_values(by=[\"Reputation/Antwort\"], ascending=False)\n",
    "display(rep_per_answer_df)\n",
    "\n",
    "rep_per_answer_df[\"Reputation/Antwort\"].sum()/20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104f1dd",
   "metadata": {},
   "source": [
    "# Anzahl Tag pro Experte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4735e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anzahl Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desertnaut</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lejlot</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcin Możejko</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxim</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Kumar</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dga</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Möller</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Thoma</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflowuser2010</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrry</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvador Dali</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has QUIT--Anony-Mousse</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Snoopy</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicolas Gervais</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seralouk</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxU</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runhani</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Anzahl Tags\n",
       "display_name                       \n",
       "desertnaut                      190\n",
       "lejlot                          256\n",
       "Marcin Możejko                   89\n",
       "Maxim                           174\n",
       "Shai                             83\n",
       "today                           102\n",
       "Vivek Kumar                      99\n",
       "dga                              15\n",
       "Daniel Möller                    67\n",
       "Martin Thoma                     75\n",
       "Prune                           180\n",
       "stackoverflowuser2010            55\n",
       "mrry                             40\n",
       "Salvador Dali                    33\n",
       "Has QUIT--Anony-Mousse          199\n",
       "Dr. Snoopy                       78\n",
       "Nicolas Gervais                  60\n",
       "seralouk                         71\n",
       "MaxU                             74\n",
       "runhani                           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_per_user = []\n",
    "for tags in top_answer_users[\"answer_tags\"]:\n",
    "    tags_per_user.append(len(tags))\n",
    "\n",
    "tags_per_user_df = pd.DataFrame(tags_per_user, index=top_answer_users[\"display_name\"])\n",
    "tags_per_user_df.columns = [\"Anzahl Tags\"]\n",
    "tags_per_user_df.fillna(0, inplace=True)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "display(tags_per_user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbc6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tags = top_answer_users[\"answer_tags\"]\n",
    "for tag in answer_tags:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c6c3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_users = sorted_user_df[0:20]\n",
    "sorted_user_tag_df = pd.DataFrame(top_users, columns=[\"answer_tags\"], index=top_users.index)\n",
    "sorted_user_tag_df[\"user\"] = top_users.index\n",
    "sorted_user_tag_df.fillna(\"0\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29f1cb",
   "metadata": {},
   "source": [
    "# Metrik Reputation in \"machine-learning\"/Gesamtreputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0d54e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desertnaut</th>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lejlot</th>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcin Możejko</th>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxim</th>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai</th>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Kumar</th>\n",
       "      <td>0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dga</th>\n",
       "      <td>0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Möller</th>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Thoma</th>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune</th>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflowuser2010</th>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrry</th>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvador Dali</th>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has QUIT--Anony-Mousse</th>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Snoopy</th>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicolas Gervais</th>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seralouk</th>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxU</th>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runhani</th>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Ratio\n",
       "display_name                 \n",
       "desertnaut              0.695\n",
       "lejlot                  0.441\n",
       "Marcin Możejko          0.641\n",
       "Maxim                   0.439\n",
       "Shai                    0.180\n",
       "today                   0.524\n",
       "Vivek Kumar             0.317\n",
       "dga                     0.407\n",
       "Daniel Möller           0.112\n",
       "Martin Thoma            0.086\n",
       "Prune                   0.110\n",
       "stackoverflowuser2010   0.261\n",
       "mrry                    0.061\n",
       "Salvador Dali           0.036\n",
       "Has QUIT--Anony-Mousse  0.088\n",
       "Dr. Snoopy              0.106\n",
       "Nicolas Gervais         0.241\n",
       "seralouk                0.227\n",
       "MaxU                    0.029\n",
       "runhani                 0.992"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_users_total_rep = top_users_posts.drop_duplicates(subset=[\"AnswerUserId\"])\n",
    "top_users_total_rep\n",
    "expert_reputations = []\n",
    "for expert in top_users.itertuples():\n",
    "    \n",
    "    user_reputation = top_users_total_rep.loc[top_users_total_rep['AnswerUserId'] == expert[0]][\"AnswerUserReputation\"].values[0]          \n",
    "    display_name = expert[1]\n",
    "    calculated_rep = expert[5]                    \n",
    "    #expert_reputations.append([display_name, user_reputation, calculated_rep])\n",
    "    expert_reputations.append(calculated_rep/user_reputation)\n",
    "    \n",
    "top_users = sorted_user_df[0:20]\n",
    "expert_reputations_df = pd.DataFrame(expert_reputations, index=top_users[\"display_name\"])\n",
    "expert_reputations_df.columns = [\"Ratio\"]\n",
    "expert_reputations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffadf7c",
   "metadata": {},
   "source": [
    "# Tag Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "79bcda56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tag</th>\n",
       "      <th>.net</th>\n",
       "      <th>accord.net</th>\n",
       "      <th>activation-function</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>adam</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>amazon-sagemaker</th>\n",
       "      <th>anaconda</th>\n",
       "      <th>analysis</th>\n",
       "      <th>analytics</th>\n",
       "      <th>...</th>\n",
       "      <th>word-embedding</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>xgbclassifier</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xls</th>\n",
       "      <th>xor</th>\n",
       "      <th>yellowbrick</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero-padding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tag       .net  accord.net  activation-function  adaboost  adam  algorithm  \\\n",
       "userid                                                                       \n",
       "349130   0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "562769   0.000       0.000                0.000     0.000 0.000      1.000   \n",
       "712995   0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "1060350  0.000       1.000                0.000     0.000 0.000      1.000   \n",
       "1090562  0.000       0.000                0.000     0.000 0.000      1.000   \n",
       "1714410  0.000       0.000                0.000     0.000 0.000      1.000   \n",
       "2097240  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "2099607  0.000       0.000                1.000     0.000 1.000      0.000   \n",
       "2658050  1.000       0.000                0.000     1.000 0.000      1.000   \n",
       "3374996  0.000       0.000                0.000     1.000 0.000      1.000   \n",
       "3574081  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "4561314  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "4685471  0.000       0.000                1.000     1.000 1.000      0.000   \n",
       "4785185  0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "5025009  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "5545260  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "5741205  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "5974433  0.000       0.000                1.000     0.000 0.000      1.000   \n",
       "6730309  0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "10908375 0.000       0.000                0.000     0.000 0.000      0.000   \n",
       "\n",
       "tag       amazon-sagemaker  anaconda  analysis  analytics  ...  \\\n",
       "userid                                                     ...   \n",
       "349130               0.000     0.000     0.000      0.000  ...   \n",
       "562769               0.000     0.000     0.000      0.000  ...   \n",
       "712995               0.000     0.000     0.000      0.000  ...   \n",
       "1060350              1.000     0.000     1.000      0.000  ...   \n",
       "1090562              0.000     0.000     0.000      0.000  ...   \n",
       "1714410              0.000     0.000     0.000      0.000  ...   \n",
       "2097240              0.000     0.000     0.000      0.000  ...   \n",
       "2099607              0.000     0.000     0.000      0.000  ...   \n",
       "2658050              0.000     0.000     0.000      0.000  ...   \n",
       "3374996              0.000     1.000     0.000      0.000  ...   \n",
       "3574081              0.000     0.000     0.000      0.000  ...   \n",
       "4561314              0.000     0.000     0.000      0.000  ...   \n",
       "4685471              0.000     0.000     0.000      0.000  ...   \n",
       "4785185              0.000     1.000     0.000      1.000  ...   \n",
       "5025009              0.000     0.000     0.000      0.000  ...   \n",
       "5545260              0.000     0.000     0.000      0.000  ...   \n",
       "5741205              0.000     0.000     0.000      0.000  ...   \n",
       "5974433              0.000     0.000     0.000      0.000  ...   \n",
       "6730309              0.000     0.000     0.000      0.000  ...   \n",
       "10908375             0.000     0.000     0.000      0.000  ...   \n",
       "\n",
       "tag       word-embedding  word2vec  xgbclassifier  xgboost   xls   xor  \\\n",
       "userid                                                                   \n",
       "349130             0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "562769             0.000     1.000          0.000    0.000 0.000 0.000   \n",
       "712995             1.000     1.000          0.000    1.000 0.000 1.000   \n",
       "1060350            1.000     1.000          0.000    0.000 0.000 0.000   \n",
       "1090562            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "1714410            1.000     0.000          0.000    0.000 0.000 0.000   \n",
       "2097240            1.000     0.000          0.000    1.000 0.000 0.000   \n",
       "2099607            1.000     1.000          0.000    0.000 0.000 0.000   \n",
       "2658050            0.000     0.000          0.000    1.000 0.000 0.000   \n",
       "3374996            0.000     0.000          0.000    1.000 0.000 0.000   \n",
       "3574081            1.000     0.000          0.000    0.000 0.000 0.000   \n",
       "4561314            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "4685471            1.000     1.000          1.000    1.000 0.000 0.000   \n",
       "4785185            1.000     1.000          0.000    1.000 0.000 0.000   \n",
       "5025009            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "5545260            0.000     0.000          0.000    0.000 0.000 1.000   \n",
       "5741205            0.000     0.000          0.000    1.000 1.000 0.000   \n",
       "5974433            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "6730309            0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "10908375           0.000     0.000          0.000    0.000 0.000 0.000   \n",
       "\n",
       "tag       yellowbrick  yelp  yolo  zero-padding  \n",
       "userid                                           \n",
       "349130          0.000 0.000 0.000         0.000  \n",
       "562769          0.000 0.000 0.000         0.000  \n",
       "712995          0.000 0.000 0.000         0.000  \n",
       "1060350         0.000 1.000 0.000         0.000  \n",
       "1090562         0.000 0.000 0.000         0.000  \n",
       "1714410         0.000 0.000 0.000         0.000  \n",
       "2097240         0.000 0.000 0.000         1.000  \n",
       "2099607         0.000 0.000 0.000         0.000  \n",
       "2658050         0.000 0.000 0.000         0.000  \n",
       "3374996         0.000 0.000 0.000         0.000  \n",
       "3574081         0.000 0.000 0.000         0.000  \n",
       "4561314         0.000 0.000 0.000         0.000  \n",
       "4685471         1.000 0.000 1.000         0.000  \n",
       "4785185         0.000 0.000 1.000         0.000  \n",
       "5025009         0.000 0.000 0.000         0.000  \n",
       "5545260         0.000 0.000 0.000         0.000  \n",
       "5741205         0.000 0.000 0.000         0.000  \n",
       "5974433         0.000 0.000 0.000         0.000  \n",
       "6730309         0.000 0.000 0.000         0.000  \n",
       "10908375        0.000 0.000 0.000         0.000  \n",
       "\n",
       "[20 rows x 689 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userid</th>\n",
       "      <th>349130</th>\n",
       "      <th>562769</th>\n",
       "      <th>712995</th>\n",
       "      <th>1060350</th>\n",
       "      <th>1090562</th>\n",
       "      <th>1714410</th>\n",
       "      <th>2097240</th>\n",
       "      <th>2099607</th>\n",
       "      <th>2658050</th>\n",
       "      <th>3374996</th>\n",
       "      <th>3574081</th>\n",
       "      <th>4561314</th>\n",
       "      <th>4685471</th>\n",
       "      <th>4785185</th>\n",
       "      <th>5025009</th>\n",
       "      <th>5545260</th>\n",
       "      <th>5741205</th>\n",
       "      <th>5974433</th>\n",
       "      <th>6730309</th>\n",
       "      <th>10908375</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>0.431</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.296</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>0.398</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.363</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>0.443</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.469</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.508</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>0.326</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.322</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>0.397</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>0.312</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.342</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>0.282</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>0.292</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>0.303</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.159</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>0.424</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "userid    349130    562769    712995    1060350   1090562   1714410   \\\n",
       "userid                                                                 \n",
       "349130       1.000     0.431     0.361     0.233     0.296     0.398   \n",
       "562769       0.431     1.000     0.376     0.336     0.322     0.368   \n",
       "712995       0.361     0.376     1.000     0.296     0.330     0.349   \n",
       "1060350      0.233     0.336     0.296     1.000     0.173     0.202   \n",
       "1090562      0.296     0.322     0.330     0.173     1.000     0.363   \n",
       "1714410      0.398     0.368     0.349     0.202     0.363     1.000   \n",
       "2097240      0.443     0.324     0.370     0.191     0.319     0.469   \n",
       "2099607      0.404     0.377     0.435     0.204     0.310     0.402   \n",
       "2658050      0.326     0.390     0.403     0.416     0.294     0.322   \n",
       "3374996      0.296     0.406     0.358     0.392     0.297     0.243   \n",
       "3574081      0.376     0.347     0.324     0.179     0.385     0.330   \n",
       "4561314      0.397     0.405     0.317     0.296     0.329     0.311   \n",
       "4685471      0.312     0.377     0.352     0.375     0.290     0.295   \n",
       "4785185      0.380     0.422     0.418     0.433     0.285     0.385   \n",
       "5025009      0.282     0.370     0.279     0.362     0.289     0.261   \n",
       "5545260      0.292     0.268     0.215     0.165     0.405     0.312   \n",
       "5741205      0.303     0.376     0.300     0.338     0.304     0.230   \n",
       "5974433      0.444     0.392     0.410     0.263     0.351     0.384   \n",
       "6730309      0.113     0.115     0.114     0.071     0.261     0.165   \n",
       "10908375     0.424     0.388     0.323     0.210     0.315     0.397   \n",
       "\n",
       "userid    2097240   2099607   2658050   3374996   3574081   4561314   \\\n",
       "userid                                                                 \n",
       "349130       0.443     0.404     0.326     0.296     0.376     0.397   \n",
       "562769       0.324     0.377     0.390     0.406     0.347     0.405   \n",
       "712995       0.370     0.435     0.403     0.358     0.324     0.317   \n",
       "1060350      0.191     0.204     0.416     0.392     0.179     0.296   \n",
       "1090562      0.319     0.310     0.294     0.297     0.385     0.329   \n",
       "1714410      0.469     0.402     0.322     0.243     0.330     0.311   \n",
       "2097240      1.000     0.508     0.305     0.307     0.386     0.346   \n",
       "2099607      0.508     1.000     0.322     0.308     0.329     0.347   \n",
       "2658050      0.305     0.322     1.000     0.408     0.227     0.346   \n",
       "3374996      0.307     0.308     0.408     1.000     0.270     0.366   \n",
       "3574081      0.386     0.329     0.227     0.270     1.000     0.384   \n",
       "4561314      0.346     0.347     0.346     0.366     0.384     1.000   \n",
       "4685471      0.355     0.417     0.440     0.489     0.241     0.342   \n",
       "4785185      0.319     0.369     0.508     0.442     0.271     0.412   \n",
       "5025009      0.203     0.270     0.349     0.525     0.244     0.384   \n",
       "5545260      0.347     0.230     0.210     0.234     0.367     0.174   \n",
       "5741205      0.256     0.299     0.356     0.479     0.257     0.408   \n",
       "5974433      0.505     0.462     0.431     0.362     0.352     0.357   \n",
       "6730309      0.183     0.198     0.094     0.101     0.237     0.067   \n",
       "10908375     0.410     0.422     0.282     0.324     0.347     0.383   \n",
       "\n",
       "userid    4685471   4785185   5025009   5545260   5741205   5974433   \\\n",
       "userid                                                                 \n",
       "349130       0.312     0.380     0.282     0.292     0.303     0.444   \n",
       "562769       0.377     0.422     0.370     0.268     0.376     0.392   \n",
       "712995       0.352     0.418     0.279     0.215     0.300     0.410   \n",
       "1060350      0.375     0.433     0.362     0.165     0.338     0.263   \n",
       "1090562      0.290     0.285     0.289     0.405     0.304     0.351   \n",
       "1714410      0.295     0.385     0.261     0.312     0.230     0.384   \n",
       "2097240      0.355     0.319     0.203     0.347     0.256     0.505   \n",
       "2099607      0.417     0.369     0.270     0.230     0.299     0.462   \n",
       "2658050      0.440     0.508     0.349     0.210     0.356     0.431   \n",
       "3374996      0.489     0.442     0.525     0.234     0.479     0.362   \n",
       "3574081      0.241     0.271     0.244     0.367     0.257     0.352   \n",
       "4561314      0.342     0.412     0.384     0.174     0.408     0.357   \n",
       "4685471      1.000     0.422     0.422     0.169     0.405     0.369   \n",
       "4785185      0.422     1.000     0.372     0.212     0.399     0.387   \n",
       "5025009      0.422     0.372     1.000     0.184     0.455     0.302   \n",
       "5545260      0.169     0.212     0.184     1.000     0.210     0.301   \n",
       "5741205      0.405     0.399     0.455     0.210     1.000     0.333   \n",
       "5974433      0.369     0.387     0.302     0.301     0.333     1.000   \n",
       "6730309      0.109     0.112     0.059     0.258     0.058     0.159   \n",
       "10908375     0.337     0.346     0.368     0.300     0.300     0.342   \n",
       "\n",
       "userid    6730309   10908375  \n",
       "userid                        \n",
       "349130       0.113     0.424  \n",
       "562769       0.115     0.388  \n",
       "712995       0.114     0.323  \n",
       "1060350      0.071     0.210  \n",
       "1090562      0.261     0.315  \n",
       "1714410      0.165     0.397  \n",
       "2097240      0.183     0.410  \n",
       "2099607      0.198     0.422  \n",
       "2658050      0.094     0.282  \n",
       "3374996      0.101     0.324  \n",
       "3574081      0.237     0.347  \n",
       "4561314      0.067     0.383  \n",
       "4685471      0.109     0.337  \n",
       "4785185      0.112     0.346  \n",
       "5025009      0.059     0.368  \n",
       "5545260      0.258     0.300  \n",
       "5741205      0.058     0.300  \n",
       "5974433      0.159     0.342  \n",
       "6730309      1.000     0.129  \n",
       "10908375     0.129     1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_tag_list = []\n",
    "for i,tags in enumerate(sorted_user_tag_df[\"answer_tags\"]):\n",
    "        \n",
    "    if tags != \"0\":    \n",
    "        for tag in tags:        \n",
    "            user_tag = [sorted_user_tag_df.iloc[i][\"user\"], tag]\n",
    "            user_tag_list.append(user_tag)\n",
    "        \n",
    "\n",
    "\n",
    "user_tag_list_df = pd.DataFrame(user_tag_list, columns=[\"userid\", \"tag\"])\n",
    "user_tag_list_df[\"count\"] = 1\n",
    "\n",
    "user_tags_matrix = user_tag_list_df.pivot(index=\"userid\", columns=\"tag\", values=\"count\")\n",
    "user_tags_matrix.fillna(0, inplace=True)\n",
    "user_tag_similarity = cosine_similarity(user_tags_matrix)\n",
    "\n",
    "sim_df = pd.DataFrame(user_tag_similarity, index=user_tags_matrix.index, columns=user_tags_matrix.index)\n",
    "display(user_tags_matrix)\n",
    "display(sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3861085c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userid</th>\n",
       "      <th>349130</th>\n",
       "      <th>562769</th>\n",
       "      <th>712995</th>\n",
       "      <th>1060350</th>\n",
       "      <th>1090562</th>\n",
       "      <th>1714410</th>\n",
       "      <th>2097240</th>\n",
       "      <th>2099607</th>\n",
       "      <th>2658050</th>\n",
       "      <th>3374996</th>\n",
       "      <th>3574081</th>\n",
       "      <th>4561314</th>\n",
       "      <th>4685471</th>\n",
       "      <th>4785185</th>\n",
       "      <th>5025009</th>\n",
       "      <th>5545260</th>\n",
       "      <th>5741205</th>\n",
       "      <th>5974433</th>\n",
       "      <th>6730309</th>\n",
       "      <th>10908375</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "userid    349130    562769    712995    1060350   1090562   1714410   \\\n",
       "userid                                                                 \n",
       "349130       1.000     0.000     0.000     0.000     0.000     0.000   \n",
       "562769       0.000     1.000     0.000     0.000     0.000     0.000   \n",
       "712995       0.000     0.000     1.000     0.000     0.000     0.000   \n",
       "1060350      0.000     0.000     0.000     1.000     0.000     0.000   \n",
       "1090562      0.000     0.000     0.000     0.000     1.000     0.000   \n",
       "1714410      0.000     0.000     0.000     0.000     0.000     1.000   \n",
       "2097240      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "2099607      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "2658050      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "3374996      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "3574081      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "4561314      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "4685471      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "4785185      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "5025009      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "5545260      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "5741205      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "5974433      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "6730309      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "10908375     0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "\n",
       "userid    2097240   2099607   2658050   3374996   3574081   4561314   \\\n",
       "userid                                                                 \n",
       "349130       0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "562769       0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "712995       0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "1060350      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "1090562      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "1714410      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "2097240      1.000     0.508     0.000     0.000     0.000     0.000   \n",
       "2099607      0.508     1.000     0.000     0.000     0.000     0.000   \n",
       "2658050      0.000     0.000     1.000     0.000     0.000     0.000   \n",
       "3374996      0.000     0.000     0.000     1.000     0.000     0.000   \n",
       "3574081      0.000     0.000     0.000     0.000     1.000     0.000   \n",
       "4561314      0.000     0.000     0.000     0.000     0.000     1.000   \n",
       "4685471      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "4785185      0.000     0.000     0.508     0.000     0.000     0.000   \n",
       "5025009      0.000     0.000     0.000     0.525     0.000     0.000   \n",
       "5545260      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "5741205      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "5974433      0.505     0.000     0.000     0.000     0.000     0.000   \n",
       "6730309      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "10908375     0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "\n",
       "userid    4685471   4785185   5025009   5545260   5741205   5974433   \\\n",
       "userid                                                                 \n",
       "349130       0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "562769       0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "712995       0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "1060350      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "1090562      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "1714410      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "2097240      0.000     0.000     0.000     0.000     0.000     0.505   \n",
       "2099607      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "2658050      0.000     0.508     0.000     0.000     0.000     0.000   \n",
       "3374996      0.000     0.000     0.525     0.000     0.000     0.000   \n",
       "3574081      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "4561314      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "4685471      1.000     0.000     0.000     0.000     0.000     0.000   \n",
       "4785185      0.000     1.000     0.000     0.000     0.000     0.000   \n",
       "5025009      0.000     0.000     1.000     0.000     0.000     0.000   \n",
       "5545260      0.000     0.000     0.000     1.000     0.000     0.000   \n",
       "5741205      0.000     0.000     0.000     0.000     1.000     0.000   \n",
       "5974433      0.000     0.000     0.000     0.000     0.000     1.000   \n",
       "6730309      0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "10908375     0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "\n",
       "userid    6730309   10908375  \n",
       "userid                        \n",
       "349130       0.000     0.000  \n",
       "562769       0.000     0.000  \n",
       "712995       0.000     0.000  \n",
       "1060350      0.000     0.000  \n",
       "1090562      0.000     0.000  \n",
       "1714410      0.000     0.000  \n",
       "2097240      0.000     0.000  \n",
       "2099607      0.000     0.000  \n",
       "2658050      0.000     0.000  \n",
       "3374996      0.000     0.000  \n",
       "3574081      0.000     0.000  \n",
       "4561314      0.000     0.000  \n",
       "4685471      0.000     0.000  \n",
       "4785185      0.000     0.000  \n",
       "5025009      0.000     0.000  \n",
       "5545260      0.000     0.000  \n",
       "5741205      0.000     0.000  \n",
       "5974433      0.000     0.000  \n",
       "6730309      1.000     0.000  \n",
       "10908375     0.000     1.000  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "tag_similarity_filtered = sim_df\n",
    "tag_similarity_filtered.values[tag_similarity_filtered <= threshold] = 0\n",
    "tag_similarity_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4b0618d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-2b28ceccd26d4a249f9ea22fd12940b0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2b28ceccd26d4a249f9ea22fd12940b0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2b28ceccd26d4a249f9ea22fd12940b0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-11fb52f2350f246b37aab1d9142cc803\"}, \"mark\": {\"type\": \"line\", \"color\": \"#BCBBBB\", \"opacity\": 1, \"strokeWidth\": 3}, \"encoding\": {\"detail\": {\"type\": \"quantitative\", \"field\": \"edge\"}, \"x\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"y\"}}, \"selection\": {\"selector022\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}, {\"data\": {\"name\": \"data-2dedb32d3dcbd328e02235fd9e7b3898\"}, \"mark\": {\"type\": \"line\", \"color\": \"black\", \"opacity\": 1, \"strokeWidth\": 2}, \"encoding\": {\"detail\": {\"type\": \"quantitative\", \"field\": \"edge\"}, \"x\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": false}, \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": false}, \"field\": \"y\"}}}, {\"data\": {\"name\": \"data-6bcb7b1c485556309fae6fdcf0e30e98\"}, \"mark\": {\"type\": \"point\", \"fill\": \"#F48024\", \"opacity\": 1, \"size\": 300, \"strokeWidth\": 1.0}, \"encoding\": {\"tooltip\": [{\"type\": \"quantitative\", \"field\": \"user\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": false}, \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"labels\": false, \"ticks\": false}, \"field\": \"y\"}}}], \"height\": 800, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-11fb52f2350f246b37aab1d9142cc803\": [{\"edge\": 0, \"y\": 0.4483632107270091, \"target\": 349130, \"pair\": [349130, 349130], \"weight\": 1.0000000000000004, \"x\": 0.908397795412796, \"source\": 349130}, {\"edge\": 0, \"y\": 0.4483632107270091, \"target\": 349130, \"pair\": [349130, 349130], \"weight\": 1.0000000000000004, \"x\": 0.908397795412796, \"source\": 349130}, {\"edge\": 1, \"y\": -0.7325548412968512, \"target\": 562769, \"pair\": [562769, 562769], \"weight\": 0.9999999999999998, \"x\": -0.7307704115555524, \"source\": 562769}, {\"edge\": 1, \"y\": -0.7325548412968512, \"target\": 562769, \"pair\": [562769, 562769], \"weight\": 0.9999999999999998, \"x\": -0.7307704115555524, \"source\": 562769}, {\"edge\": 2, \"y\": 0.731164122807007, \"target\": 712995, \"pair\": [712995, 712995], \"weight\": 0.9999999999999992, \"x\": 0.657645909340282, \"source\": 712995}, {\"edge\": 2, \"y\": 0.731164122807007, \"target\": 712995, \"pair\": [712995, 712995], \"weight\": 0.9999999999999992, \"x\": 0.657645909340282, \"source\": 712995}, {\"edge\": 3, \"y\": 0.7222768530671806, \"target\": 1060350, \"pair\": [1060350, 1060350], \"weight\": 0.9999999999999998, \"x\": -0.8181656188288805, \"source\": 1060350}, {\"edge\": 3, \"y\": 0.7222768530671806, \"target\": 1060350, \"pair\": [1060350, 1060350], \"weight\": 0.9999999999999998, \"x\": -0.8181656188288805, \"source\": 1060350}, {\"edge\": 4, \"y\": -0.06593221396208611, \"target\": 1090562, \"pair\": [1090562, 1090562], \"weight\": 1.0000000000000002, \"x\": 0.9999999999999999, \"source\": 1090562}, {\"edge\": 4, \"y\": -0.06593221396208611, \"target\": 1090562, \"pair\": [1090562, 1090562], \"weight\": 1.0000000000000002, \"x\": 0.9999999999999999, \"source\": 1090562}, {\"edge\": 5, \"y\": 0.9188378580853699, \"target\": 1714410, \"pair\": [1714410, 1714410], \"weight\": 1.0, \"x\": -0.42258731219979057, \"source\": 1714410}, {\"edge\": 5, \"y\": 0.9188378580853699, \"target\": 1714410, \"pair\": [1714410, 1714410], \"weight\": 1.0, \"x\": -0.42258731219979057, \"source\": 1714410}, {\"edge\": 6, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [2097240, 2097240], \"weight\": 0.9999999999999997, \"x\": 0.7295323721964762, \"source\": 2097240}, {\"edge\": 6, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [2097240, 2097240], \"weight\": 0.9999999999999997, \"x\": 0.7295323721964762, \"source\": 2097240}, {\"edge\": 7, \"y\": -0.33233696604664387, \"target\": 2099607, \"pair\": [2097240, 2099607], \"weight\": 0.5080562556561289, \"x\": 0.7295323721964762, \"source\": 2097240}, {\"edge\": 7, \"y\": -0.23417901145905584, \"target\": 2099607, \"pair\": [2097240, 2099607], \"weight\": 0.5080562556561289, \"x\": 0.7725885047922963, \"source\": 2097240}, {\"edge\": 8, \"y\": -0.33233696604664387, \"target\": 5974433, \"pair\": [2097240, 5974433], \"weight\": 0.5050474728750302, \"x\": 0.7295323721964762, \"source\": 2097240}, {\"edge\": 8, \"y\": -0.43302999067684383, \"target\": 5974433, \"pair\": [2097240, 5974433], \"weight\": 0.5050474728750302, \"x\": 0.8175599946674809, \"source\": 2097240}, {\"edge\": 9, \"y\": -0.23417901145905584, \"target\": 2099607, \"pair\": [2099607, 2099607], \"weight\": 1.0, \"x\": 0.7725885047922963, \"source\": 2099607}, {\"edge\": 9, \"y\": -0.23417901145905584, \"target\": 2099607, \"pair\": [2099607, 2099607], \"weight\": 1.0, \"x\": 0.7725885047922963, \"source\": 2099607}, {\"edge\": 10, \"y\": -0.23417901145905584, \"target\": 2097240, \"pair\": [2099607, 2097240], \"weight\": 0.5080562556561289, \"x\": 0.7725885047922963, \"source\": 2099607}, {\"edge\": 10, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [2099607, 2097240], \"weight\": 0.5080562556561289, \"x\": 0.7295323721964762, \"source\": 2099607}, {\"edge\": 11, \"y\": -0.8123863687824029, \"target\": 2658050, \"pair\": [2658050, 2658050], \"weight\": 1.0, \"x\": 0.014901150715533834, \"source\": 2658050}, {\"edge\": 11, \"y\": -0.8123863687824029, \"target\": 2658050, \"pair\": [2658050, 2658050], \"weight\": 1.0, \"x\": 0.014901150715533834, \"source\": 2658050}, {\"edge\": 12, \"y\": -0.8123863687824029, \"target\": 4785185, \"pair\": [2658050, 4785185], \"weight\": 0.5077737698905773, \"x\": 0.014901150715533834, \"source\": 2658050}, {\"edge\": 12, \"y\": -0.9366879996615837, \"target\": 4785185, \"pair\": [2658050, 4785185], \"weight\": 0.5077737698905773, \"x\": 0.02153194967976523, \"source\": 2658050}, {\"edge\": 13, \"y\": 0.3721612128280379, \"target\": 3374996, \"pair\": [3374996, 3374996], \"weight\": 1.0000000000000002, \"x\": -0.3351831210386077, \"source\": 3374996}, {\"edge\": 13, \"y\": 0.3721612128280379, \"target\": 3374996, \"pair\": [3374996, 3374996], \"weight\": 1.0000000000000002, \"x\": -0.3351831210386077, \"source\": 3374996}, {\"edge\": 14, \"y\": 0.3721612128280379, \"target\": 5025009, \"pair\": [3374996, 5025009], \"weight\": 0.5248145957739763, \"x\": -0.3351831210386077, \"source\": 3374996}, {\"edge\": 14, \"y\": 0.2857671530778826, \"target\": 5025009, \"pair\": [3374996, 5025009], \"weight\": 0.5248145957739763, \"x\": -0.2880254818594837, \"source\": 3374996}, {\"edge\": 15, \"y\": -0.9077739663934314, \"target\": 3574081, \"pair\": [3574081, 3574081], \"weight\": 1.0, \"x\": 0.5552519774324441, \"source\": 3574081}, {\"edge\": 15, \"y\": -0.9077739663934314, \"target\": 3574081, \"pair\": [3574081, 3574081], \"weight\": 1.0, \"x\": 0.5552519774324441, \"source\": 3574081}, {\"edge\": 16, \"y\": 0.9869233298560326, \"target\": 4561314, \"pair\": [4561314, 4561314], \"weight\": 1.0000000000000002, \"x\": -0.03210663714333541, \"source\": 4561314}, {\"edge\": 16, \"y\": 0.9869233298560326, \"target\": 4561314, \"pair\": [4561314, 4561314], \"weight\": 1.0000000000000002, \"x\": -0.03210663714333541, \"source\": 4561314}, {\"edge\": 17, \"y\": 0.9346259859965821, \"target\": 4685471, \"pair\": [4685471, 4685471], \"weight\": 0.9999999999999996, \"x\": 0.3546711288389178, \"source\": 4685471}, {\"edge\": 17, \"y\": 0.9346259859965821, \"target\": 4685471, \"pair\": [4685471, 4685471], \"weight\": 0.9999999999999996, \"x\": 0.3546711288389178, \"source\": 4685471}, {\"edge\": 18, \"y\": -0.9366879996615837, \"target\": 4785185, \"pair\": [4785185, 4785185], \"weight\": 1.0, \"x\": 0.02153194967976523, \"source\": 4785185}, {\"edge\": 18, \"y\": -0.9366879996615837, \"target\": 4785185, \"pair\": [4785185, 4785185], \"weight\": 1.0, \"x\": 0.02153194967976523, \"source\": 4785185}, {\"edge\": 19, \"y\": -0.9366879996615837, \"target\": 2658050, \"pair\": [4785185, 2658050], \"weight\": 0.5077737698905773, \"x\": 0.02153194967976523, \"source\": 4785185}, {\"edge\": 19, \"y\": -0.8123863687824029, \"target\": 2658050, \"pair\": [4785185, 2658050], \"weight\": 0.5077737698905773, \"x\": 0.014901150715533834, \"source\": 4785185}, {\"edge\": 20, \"y\": 0.2857671530778826, \"target\": 5025009, \"pair\": [5025009, 5025009], \"weight\": 1.0, \"x\": -0.2880254818594837, \"source\": 5025009}, {\"edge\": 20, \"y\": 0.2857671530778826, \"target\": 5025009, \"pair\": [5025009, 5025009], \"weight\": 1.0, \"x\": -0.2880254818594837, \"source\": 5025009}, {\"edge\": 21, \"y\": 0.2857671530778826, \"target\": 3374996, \"pair\": [5025009, 3374996], \"weight\": 0.5248145957739763, \"x\": -0.2880254818594837, \"source\": 5025009}, {\"edge\": 21, \"y\": 0.3721612128280379, \"target\": 3374996, \"pair\": [5025009, 3374996], \"weight\": 0.5248145957739763, \"x\": -0.3351831210386077, \"source\": 5025009}, {\"edge\": 22, \"y\": -0.39351627436797193, \"target\": 5545260, \"pair\": [5545260, 5545260], \"weight\": 0.9999999999999998, \"x\": -0.8990854179724397, \"source\": 5545260}, {\"edge\": 22, \"y\": -0.39351627436797193, \"target\": 5545260, \"pair\": [5545260, 5545260], \"weight\": 0.9999999999999998, \"x\": -0.8990854179724397, \"source\": 5545260}, {\"edge\": 23, \"y\": -0.8712196456006466, \"target\": 5741205, \"pair\": [5741205, 5741205], \"weight\": 1.0000000000000004, \"x\": -0.41685599491007935, \"source\": 5741205}, {\"edge\": 23, \"y\": -0.8712196456006466, \"target\": 5741205, \"pair\": [5741205, 5741205], \"weight\": 1.0000000000000004, \"x\": -0.41685599491007935, \"source\": 5741205}, {\"edge\": 24, \"y\": -0.43302999067684383, \"target\": 5974433, \"pair\": [5974433, 5974433], \"weight\": 1.0000000000000004, \"x\": 0.8175599946674809, \"source\": 5974433}, {\"edge\": 24, \"y\": -0.43302999067684383, \"target\": 5974433, \"pair\": [5974433, 5974433], \"weight\": 1.0000000000000004, \"x\": 0.8175599946674809, \"source\": 5974433}, {\"edge\": 25, \"y\": -0.43302999067684383, \"target\": 2097240, \"pair\": [5974433, 2097240], \"weight\": 0.5050474728750302, \"x\": 0.8175599946674809, \"source\": 5974433}, {\"edge\": 25, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [5974433, 2097240], \"weight\": 0.5050474728750302, \"x\": 0.7295323721964762, \"source\": 5974433}, {\"edge\": 26, \"y\": -0.02963780938096926, \"target\": 6730309, \"pair\": [6730309, 6730309], \"weight\": 1.0, \"x\": -0.9872845743563549, \"source\": 6730309}, {\"edge\": 26, \"y\": -0.02963780938096926, \"target\": 6730309, \"pair\": [6730309, 6730309], \"weight\": 1.0, \"x\": -0.9872845743563549, \"source\": 6730309}, {\"edge\": 27, \"y\": 0.3491353611833846, \"target\": 10908375, \"pair\": [10908375, 10908375], \"weight\": 0.9999999999999998, \"x\": -0.9020162132114677, \"source\": 10908375}, {\"edge\": 27, \"y\": 0.3491353611833846, \"target\": 10908375, \"pair\": [10908375, 10908375], \"weight\": 0.9999999999999998, \"x\": -0.9020162132114677, \"source\": 10908375}], \"data-2dedb32d3dcbd328e02235fd9e7b3898\": [{\"edge\": 0, \"y\": 0.4483632107270091, \"target\": 349130, \"pair\": [349130, 349130], \"weight\": 1.0000000000000004, \"x\": 0.908397795412796, \"source\": 349130}, {\"edge\": 0, \"y\": 0.4483632107270091, \"target\": 349130, \"pair\": [349130, 349130], \"weight\": 1.0000000000000004, \"x\": 0.908397795412796, \"source\": 349130}, {\"edge\": 1, \"y\": -0.7325548412968512, \"target\": 562769, \"pair\": [562769, 562769], \"weight\": 0.9999999999999998, \"x\": -0.7307704115555524, \"source\": 562769}, {\"edge\": 1, \"y\": -0.7325548412968512, \"target\": 562769, \"pair\": [562769, 562769], \"weight\": 0.9999999999999998, \"x\": -0.7307704115555524, \"source\": 562769}, {\"edge\": 2, \"y\": 0.731164122807007, \"target\": 712995, \"pair\": [712995, 712995], \"weight\": 0.9999999999999992, \"x\": 0.657645909340282, \"source\": 712995}, {\"edge\": 2, \"y\": 0.731164122807007, \"target\": 712995, \"pair\": [712995, 712995], \"weight\": 0.9999999999999992, \"x\": 0.657645909340282, \"source\": 712995}, {\"edge\": 3, \"y\": 0.7222768530671806, \"target\": 1060350, \"pair\": [1060350, 1060350], \"weight\": 0.9999999999999998, \"x\": -0.8181656188288805, \"source\": 1060350}, {\"edge\": 3, \"y\": 0.7222768530671806, \"target\": 1060350, \"pair\": [1060350, 1060350], \"weight\": 0.9999999999999998, \"x\": -0.8181656188288805, \"source\": 1060350}, {\"edge\": 4, \"y\": -0.06593221396208611, \"target\": 1090562, \"pair\": [1090562, 1090562], \"weight\": 1.0000000000000002, \"x\": 0.9999999999999999, \"source\": 1090562}, {\"edge\": 4, \"y\": -0.06593221396208611, \"target\": 1090562, \"pair\": [1090562, 1090562], \"weight\": 1.0000000000000002, \"x\": 0.9999999999999999, \"source\": 1090562}, {\"edge\": 5, \"y\": 0.9188378580853699, \"target\": 1714410, \"pair\": [1714410, 1714410], \"weight\": 1.0, \"x\": -0.42258731219979057, \"source\": 1714410}, {\"edge\": 5, \"y\": 0.9188378580853699, \"target\": 1714410, \"pair\": [1714410, 1714410], \"weight\": 1.0, \"x\": -0.42258731219979057, \"source\": 1714410}, {\"edge\": 6, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [2097240, 2097240], \"weight\": 0.9999999999999997, \"x\": 0.7295323721964762, \"source\": 2097240}, {\"edge\": 6, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [2097240, 2097240], \"weight\": 0.9999999999999997, \"x\": 0.7295323721964762, \"source\": 2097240}, {\"edge\": 7, \"y\": -0.23417901145905584, \"target\": 2099607, \"pair\": [2097240, 2099607], \"weight\": 0.5080562556561289, \"x\": 0.7725885047922963, \"source\": 2097240}, {\"edge\": 7, \"y\": -0.24399480691781464, \"target\": 2099607, \"pair\": [2097240, 2099607], \"weight\": 0.5080562556561289, \"x\": 0.7682828915327143, \"source\": 2097240}, {\"edge\": 8, \"y\": -0.43302999067684383, \"target\": 5974433, \"pair\": [2097240, 5974433], \"weight\": 0.5050474728750302, \"x\": 0.8175599946674809, \"source\": 2097240}, {\"edge\": 8, \"y\": -0.4229606882138238, \"target\": 5974433, \"pair\": [2097240, 5974433], \"weight\": 0.5050474728750302, \"x\": 0.8087572324203804, \"source\": 2097240}, {\"edge\": 9, \"y\": -0.23417901145905584, \"target\": 2099607, \"pair\": [2099607, 2099607], \"weight\": 1.0, \"x\": 0.7725885047922963, \"source\": 2099607}, {\"edge\": 9, \"y\": -0.23417901145905584, \"target\": 2099607, \"pair\": [2099607, 2099607], \"weight\": 1.0, \"x\": 0.7725885047922963, \"source\": 2099607}, {\"edge\": 10, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [2099607, 2097240], \"weight\": 0.5080562556561289, \"x\": 0.7295323721964762, \"source\": 2099607}, {\"edge\": 10, \"y\": -0.32252117058788504, \"target\": 2097240, \"pair\": [2099607, 2097240], \"weight\": 0.5080562556561289, \"x\": 0.7338379854560582, \"source\": 2099607}, {\"edge\": 11, \"y\": -0.8123863687824029, \"target\": 2658050, \"pair\": [2658050, 2658050], \"weight\": 1.0, \"x\": 0.014901150715533834, \"source\": 2658050}, {\"edge\": 11, \"y\": -0.8123863687824029, \"target\": 2658050, \"pair\": [2658050, 2658050], \"weight\": 1.0, \"x\": 0.014901150715533834, \"source\": 2658050}, {\"edge\": 12, \"y\": -0.9366879996615837, \"target\": 4785185, \"pair\": [2658050, 4785185], \"weight\": 0.5077737698905773, \"x\": 0.02153194967976523, \"source\": 2658050}, {\"edge\": 12, \"y\": -0.9242578365736656, \"target\": 4785185, \"pair\": [2658050, 4785185], \"weight\": 0.5077737698905773, \"x\": 0.020868869783342087, \"source\": 2658050}, {\"edge\": 13, \"y\": 0.3721612128280379, \"target\": 3374996, \"pair\": [3374996, 3374996], \"weight\": 1.0000000000000002, \"x\": -0.3351831210386077, \"source\": 3374996}, {\"edge\": 13, \"y\": 0.3721612128280379, \"target\": 3374996, \"pair\": [3374996, 3374996], \"weight\": 1.0000000000000002, \"x\": -0.3351831210386077, \"source\": 3374996}, {\"edge\": 14, \"y\": 0.2857671530778826, \"target\": 5025009, \"pair\": [3374996, 5025009], \"weight\": 0.5248145957739763, \"x\": -0.2880254818594837, \"source\": 3374996}, {\"edge\": 14, \"y\": 0.29440655905289814, \"target\": 5025009, \"pair\": [3374996, 5025009], \"weight\": 0.5248145957739763, \"x\": -0.2927412457773961, \"source\": 3374996}, {\"edge\": 15, \"y\": -0.9077739663934314, \"target\": 3574081, \"pair\": [3574081, 3574081], \"weight\": 1.0, \"x\": 0.5552519774324441, \"source\": 3574081}, {\"edge\": 15, \"y\": -0.9077739663934314, \"target\": 3574081, \"pair\": [3574081, 3574081], \"weight\": 1.0, \"x\": 0.5552519774324441, \"source\": 3574081}, {\"edge\": 16, \"y\": 0.9869233298560326, \"target\": 4561314, \"pair\": [4561314, 4561314], \"weight\": 1.0000000000000002, \"x\": -0.03210663714333541, \"source\": 4561314}, {\"edge\": 16, \"y\": 0.9869233298560326, \"target\": 4561314, \"pair\": [4561314, 4561314], \"weight\": 1.0000000000000002, \"x\": -0.03210663714333541, \"source\": 4561314}, {\"edge\": 17, \"y\": 0.9346259859965821, \"target\": 4685471, \"pair\": [4685471, 4685471], \"weight\": 0.9999999999999996, \"x\": 0.3546711288389178, \"source\": 4685471}, {\"edge\": 17, \"y\": 0.9346259859965821, \"target\": 4685471, \"pair\": [4685471, 4685471], \"weight\": 0.9999999999999996, \"x\": 0.3546711288389178, \"source\": 4685471}, {\"edge\": 18, \"y\": -0.9366879996615837, \"target\": 4785185, \"pair\": [4785185, 4785185], \"weight\": 1.0, \"x\": 0.02153194967976523, \"source\": 4785185}, {\"edge\": 18, \"y\": -0.9366879996615837, \"target\": 4785185, \"pair\": [4785185, 4785185], \"weight\": 1.0, \"x\": 0.02153194967976523, \"source\": 4785185}, {\"edge\": 19, \"y\": -0.8123863687824029, \"target\": 2658050, \"pair\": [4785185, 2658050], \"weight\": 0.5077737698905773, \"x\": 0.014901150715533834, \"source\": 4785185}, {\"edge\": 19, \"y\": -0.824816531870321, \"target\": 2658050, \"pair\": [4785185, 2658050], \"weight\": 0.5077737698905773, \"x\": 0.015564230611956973, \"source\": 4785185}, {\"edge\": 20, \"y\": 0.2857671530778826, \"target\": 5025009, \"pair\": [5025009, 5025009], \"weight\": 1.0, \"x\": -0.2880254818594837, \"source\": 5025009}, {\"edge\": 20, \"y\": 0.2857671530778826, \"target\": 5025009, \"pair\": [5025009, 5025009], \"weight\": 1.0, \"x\": -0.2880254818594837, \"source\": 5025009}, {\"edge\": 21, \"y\": 0.3721612128280379, \"target\": 3374996, \"pair\": [5025009, 3374996], \"weight\": 0.5248145957739763, \"x\": -0.3351831210386077, \"source\": 5025009}, {\"edge\": 21, \"y\": 0.3635218068530224, \"target\": 3374996, \"pair\": [5025009, 3374996], \"weight\": 0.5248145957739763, \"x\": -0.3304673571206953, \"source\": 5025009}, {\"edge\": 22, \"y\": -0.39351627436797193, \"target\": 5545260, \"pair\": [5545260, 5545260], \"weight\": 0.9999999999999998, \"x\": -0.8990854179724397, \"source\": 5545260}, {\"edge\": 22, \"y\": -0.39351627436797193, \"target\": 5545260, \"pair\": [5545260, 5545260], \"weight\": 0.9999999999999998, \"x\": -0.8990854179724397, \"source\": 5545260}, {\"edge\": 23, \"y\": -0.8712196456006466, \"target\": 5741205, \"pair\": [5741205, 5741205], \"weight\": 1.0000000000000004, \"x\": -0.41685599491007935, \"source\": 5741205}, {\"edge\": 23, \"y\": -0.8712196456006466, \"target\": 5741205, \"pair\": [5741205, 5741205], \"weight\": 1.0000000000000004, \"x\": -0.41685599491007935, \"source\": 5741205}, {\"edge\": 24, \"y\": -0.43302999067684383, \"target\": 5974433, \"pair\": [5974433, 5974433], \"weight\": 1.0000000000000004, \"x\": 0.8175599946674809, \"source\": 5974433}, {\"edge\": 24, \"y\": -0.43302999067684383, \"target\": 5974433, \"pair\": [5974433, 5974433], \"weight\": 1.0000000000000004, \"x\": 0.8175599946674809, \"source\": 5974433}, {\"edge\": 25, \"y\": -0.33233696604664387, \"target\": 2097240, \"pair\": [5974433, 2097240], \"weight\": 0.5050474728750302, \"x\": 0.7295323721964762, \"source\": 5974433}, {\"edge\": 25, \"y\": -0.3424062685096639, \"target\": 2097240, \"pair\": [5974433, 2097240], \"weight\": 0.5050474728750302, \"x\": 0.7383351344435767, \"source\": 5974433}, {\"edge\": 26, \"y\": -0.02963780938096926, \"target\": 6730309, \"pair\": [6730309, 6730309], \"weight\": 1.0, \"x\": -0.9872845743563549, \"source\": 6730309}, {\"edge\": 26, \"y\": -0.02963780938096926, \"target\": 6730309, \"pair\": [6730309, 6730309], \"weight\": 1.0, \"x\": -0.9872845743563549, \"source\": 6730309}, {\"edge\": 27, \"y\": 0.3491353611833846, \"target\": 10908375, \"pair\": [10908375, 10908375], \"weight\": 0.9999999999999998, \"x\": -0.9020162132114677, \"source\": 10908375}, {\"edge\": 27, \"y\": 0.3491353611833846, \"target\": 10908375, \"pair\": [10908375, 10908375], \"weight\": 0.9999999999999998, \"x\": -0.9020162132114677, \"source\": 10908375}], \"data-6bcb7b1c485556309fae6fdcf0e30e98\": [{\"x\": 0.908397795412796, \"y\": 0.4483632107270091, \"user\": 349130.0}, {\"x\": -0.7307704115555524, \"y\": -0.7325548412968512, \"user\": 562769.0}, {\"x\": 0.657645909340282, \"y\": 0.731164122807007, \"user\": 712995.0}, {\"x\": -0.8181656188288805, \"y\": 0.7222768530671806, \"user\": 1060350.0}, {\"x\": 0.9999999999999999, \"y\": -0.06593221396208611, \"user\": 1090562.0}, {\"x\": -0.42258731219979057, \"y\": 0.9188378580853699, \"user\": 1714410.0}, {\"x\": 0.7295323721964762, \"y\": -0.33233696604664387, \"user\": 2097240.0}, {\"x\": 0.7725885047922963, \"y\": -0.23417901145905584, \"user\": 2099607.0}, {\"x\": 0.014901150715533834, \"y\": -0.8123863687824029, \"user\": 2658050.0}, {\"x\": -0.3351831210386077, \"y\": 0.3721612128280379, \"user\": 3374996.0}, {\"x\": 0.5552519774324441, \"y\": -0.9077739663934314, \"user\": 3574081.0}, {\"x\": -0.03210663714333541, \"y\": 0.9869233298560326, \"user\": 4561314.0}, {\"x\": 0.3546711288389178, \"y\": 0.9346259859965821, \"user\": 4685471.0}, {\"x\": 0.02153194967976523, \"y\": -0.9366879996615837, \"user\": 4785185.0}, {\"x\": -0.2880254818594837, \"y\": 0.2857671530778826, \"user\": 5025009.0}, {\"x\": -0.8990854179724397, \"y\": -0.39351627436797193, \"user\": 5545260.0}, {\"x\": -0.41685599491007935, \"y\": -0.8712196456006466, \"user\": 5741205.0}, {\"x\": 0.8175599946674809, \"y\": -0.43302999067684383, \"user\": 5974433.0}, {\"x\": -0.9872845743563549, \"y\": -0.02963780938096926, \"user\": 6730309.0}, {\"x\": -0.9020162132114677, \"y\": 0.3491353611833846, \"user\": 10908375.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_sim_graph = nx.from_pandas_adjacency(tag_similarity_filtered,  create_using=nx.DiGraph)\n",
    "\n",
    "\n",
    "user_dict = sorted_user_tag_df[\"user\"].to_dict()\n",
    "nx.set_node_attributes(tag_sim_graph, user_dict, \"user\")\n",
    "\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "chart = nxa.draw_networkx(\n",
    "    tag_sim_graph,\n",
    "    node_color= '#F48024',\n",
    "    edge_color= '#BCBBBB',\n",
    "    node_tooltip = [\"user\"],\n",
    "    width = 3\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=800\n",
    ").interactive()\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4db515f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_tags</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>{backpropagation, java, random-seed, computer-vision, lda, pearson-correlation, nearest-neighbor, face-detection, metrics, autoencoder, ios, lightgbm, tfidfvectorizer, mean-square-error, densenet,...</td>\n",
       "      <td>4685471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>{multiple-regression, poisson, computer-vision, c#, lua, lda, contour, function, nearest-neighbor, metrics, mle, ruby, word-count, markov, algorithm, resampling, pandas, modeling, grid, pca, glmne...</td>\n",
       "      <td>2658050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>{caffe, backpropagation, keras, image-recognition, computer-science, evaluate, unsupervised-learning, computer-vision, python, one-hot-encoding, conv-neural-network, plot, non-linear-regression, p...</td>\n",
       "      <td>5974433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>{backpropagation, xor, transfer, list, computer-science, linear-discriminant, tensor, computer-vision, snpe, tensorflow-serving, nearest-neighbor, matrix-multiplication, multi-gpu, autoencoder, ml...</td>\n",
       "      <td>712995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>{caffe, segmentation-fault, backpropagation, keras, image-recognition, autograd, generative-adversarial-network, protocol-buffers, matlab, unsupervised-learning, computer-vision, tensor, python, l...</td>\n",
       "      <td>1714410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>{backpropagation, keras, face-recognition, generative-adversarial-network, unsupervised-learning, tensor, computer-vision, python, conv-neural-network, hyperas, ocr, signal-processing, progress-ba...</td>\n",
       "      <td>2099607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>{keras, oversampling, unsupervised-learning, computer-vision, categorical-data, python, one-hot-encoding, conv-neural-network, hyperparameters, data-mining, labels, anaconda, data-transform, neare...</td>\n",
       "      <td>3374996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>{deep-learning, c++, optimization, image-recognition, xor, tensorflow, computer-vision, skflow, python, object-detection, neural-network, numpy, conv-neural-network, image-processing, python-2.7}</td>\n",
       "      <td>5545260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>{backpropagation, keras, zero-padding, generative-adversarial-network, tensor, computer-vision, python, one-hot-encoding, conv-neural-network, unet, training-data, metrics, python-3.x, autoencoder...</td>\n",
       "      <td>2097240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>{caffe, keras, image-recognition, face-recognition, threshold, matlab, computer-vision, python, one-hot-encoding, text-analysis, conv-neural-network, ocr, training-data, non-linear-regression, fea...</td>\n",
       "      <td>562769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>{backpropagation, java, logic, language-agnostic, sequential, face-recognition, google-prediction, benchmarking, tensor, computer-vision, lmdb, data-mining, distance, nearest-neighbor, metrics, py...</td>\n",
       "      <td>4785185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>{keras, java, libsvm, linear-regression, pytorch, tf.keras, math, python, one-hot-encoding, bert-language-model, recurrent-neural-network, statistics, data-mining, dataframe, deep-learning, huggin...</td>\n",
       "      <td>4561314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>{keras, word-embedding, linear-regression, computer-vision, python, one-hot-encoding, recurrent-neural-network, conv-neural-network, tensorflow-serving, deep-learning, r, system-requirements, pyth...</td>\n",
       "      <td>3574081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>{keras, optimization, synchronization, computer-vision, math, python, recurrent-neural-network, conv-neural-network, deep-learning, regularized, import, audio, numpy, cross-entropy, mnist, scikit-...</td>\n",
       "      <td>1090562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>{backpropagation, java, moa, computer-science, gmm, for-loop, yelp, self-organizing-maps, computer-vision, c#, anova, scikit-image, text-analysis, data-generation, data-mining, lda, mean-stack, di...</td>\n",
       "      <td>1060350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>{caffe, backpropagation, keras, java, output, image-recognition, sequential, face-recognition, generative-adversarial-network, matlab, tensor, computer-vision, python, conv-neural-network, tensorf...</td>\n",
       "      <td>349130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>{keras, prefetch, object-detection-api, imagedata, generative-adversarial-network, pytorch, tensor, computer-vision, tf.keras, python, one-hot-encoding, data-augmentation, reinforcement-learning, ...</td>\n",
       "      <td>10908375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>{kernel, keras, attributes, list, unsupervised-learning, computer-vision, python, one-hot-encoding, training-data, liblinear, feature-selection, python-3.x, floating-point, spyder, tfidfvectorizer...</td>\n",
       "      <td>5025009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>{keras, xls, type-conversion, python, one-hot-encoding, pearson-correlation, non-linear-regression, feature-selection, python-3.x, convolutional-neural-network, spacy, dummy-variable, countvectori...</td>\n",
       "      <td>5741205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>{deep-learning, conv-neural-network, convolution, signal-processing}</td>\n",
       "      <td>6730309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      answer_tags  \\\n",
       "4685471   {backpropagation, java, random-seed, computer-vision, lda, pearson-correlation, nearest-neighbor, face-detection, metrics, autoencoder, ios, lightgbm, tfidfvectorizer, mean-square-error, densenet,...   \n",
       "2658050   {multiple-regression, poisson, computer-vision, c#, lua, lda, contour, function, nearest-neighbor, metrics, mle, ruby, word-count, markov, algorithm, resampling, pandas, modeling, grid, pca, glmne...   \n",
       "5974433   {caffe, backpropagation, keras, image-recognition, computer-science, evaluate, unsupervised-learning, computer-vision, python, one-hot-encoding, conv-neural-network, plot, non-linear-regression, p...   \n",
       "712995    {backpropagation, xor, transfer, list, computer-science, linear-discriminant, tensor, computer-vision, snpe, tensorflow-serving, nearest-neighbor, matrix-multiplication, multi-gpu, autoencoder, ml...   \n",
       "1714410   {caffe, segmentation-fault, backpropagation, keras, image-recognition, autograd, generative-adversarial-network, protocol-buffers, matlab, unsupervised-learning, computer-vision, tensor, python, l...   \n",
       "2099607   {backpropagation, keras, face-recognition, generative-adversarial-network, unsupervised-learning, tensor, computer-vision, python, conv-neural-network, hyperas, ocr, signal-processing, progress-ba...   \n",
       "3374996   {keras, oversampling, unsupervised-learning, computer-vision, categorical-data, python, one-hot-encoding, conv-neural-network, hyperparameters, data-mining, labels, anaconda, data-transform, neare...   \n",
       "5545260       {deep-learning, c++, optimization, image-recognition, xor, tensorflow, computer-vision, skflow, python, object-detection, neural-network, numpy, conv-neural-network, image-processing, python-2.7}   \n",
       "2097240   {backpropagation, keras, zero-padding, generative-adversarial-network, tensor, computer-vision, python, one-hot-encoding, conv-neural-network, unet, training-data, metrics, python-3.x, autoencoder...   \n",
       "562769    {caffe, keras, image-recognition, face-recognition, threshold, matlab, computer-vision, python, one-hot-encoding, text-analysis, conv-neural-network, ocr, training-data, non-linear-regression, fea...   \n",
       "4785185   {backpropagation, java, logic, language-agnostic, sequential, face-recognition, google-prediction, benchmarking, tensor, computer-vision, lmdb, data-mining, distance, nearest-neighbor, metrics, py...   \n",
       "4561314   {keras, java, libsvm, linear-regression, pytorch, tf.keras, math, python, one-hot-encoding, bert-language-model, recurrent-neural-network, statistics, data-mining, dataframe, deep-learning, huggin...   \n",
       "3574081   {keras, word-embedding, linear-regression, computer-vision, python, one-hot-encoding, recurrent-neural-network, conv-neural-network, tensorflow-serving, deep-learning, r, system-requirements, pyth...   \n",
       "1090562   {keras, optimization, synchronization, computer-vision, math, python, recurrent-neural-network, conv-neural-network, deep-learning, regularized, import, audio, numpy, cross-entropy, mnist, scikit-...   \n",
       "1060350   {backpropagation, java, moa, computer-science, gmm, for-loop, yelp, self-organizing-maps, computer-vision, c#, anova, scikit-image, text-analysis, data-generation, data-mining, lda, mean-stack, di...   \n",
       "349130    {caffe, backpropagation, keras, java, output, image-recognition, sequential, face-recognition, generative-adversarial-network, matlab, tensor, computer-vision, python, conv-neural-network, tensorf...   \n",
       "10908375  {keras, prefetch, object-detection-api, imagedata, generative-adversarial-network, pytorch, tensor, computer-vision, tf.keras, python, one-hot-encoding, data-augmentation, reinforcement-learning, ...   \n",
       "5025009   {kernel, keras, attributes, list, unsupervised-learning, computer-vision, python, one-hot-encoding, training-data, liblinear, feature-selection, python-3.x, floating-point, spyder, tfidfvectorizer...   \n",
       "5741205   {keras, xls, type-conversion, python, one-hot-encoding, pearson-correlation, non-linear-regression, feature-selection, python-3.x, convolutional-neural-network, spacy, dummy-variable, countvectori...   \n",
       "6730309                                                                                                                                      {deep-learning, conv-neural-network, convolution, signal-processing}   \n",
       "\n",
       "              user  \n",
       "4685471    4685471  \n",
       "2658050    2658050  \n",
       "5974433    5974433  \n",
       "712995      712995  \n",
       "1714410    1714410  \n",
       "2099607    2099607  \n",
       "3374996    3374996  \n",
       "5545260    5545260  \n",
       "2097240    2097240  \n",
       "562769      562769  \n",
       "4785185    4785185  \n",
       "4561314    4561314  \n",
       "3574081    3574081  \n",
       "1090562    1090562  \n",
       "1060350    1060350  \n",
       "349130      349130  \n",
       "10908375  10908375  \n",
       "5025009    5025009  \n",
       "5741205    5741205  \n",
       "6730309    6730309  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_user_tag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0c6c1",
   "metadata": {},
   "source": [
    "# Same tags in all taglists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7eff90d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deep-learning', 'neural-network', 'python'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_set = sorted_user_tag_df.iloc[0][\"answer_tags\"]\n",
    "#print(intersect_set)\n",
    "for i,tags in enumerate(sorted_user_tag_df[\"answer_tags\"][0:19]):\n",
    "    intersect_set = intersect_set.intersection(tags)\n",
    "intersect_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce396408",
   "metadata": {},
   "source": [
    "# Count tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d43895",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counter = Counter()\n",
    "for i,tags in enumerate(sorted_user_tag_df[\"answer_tags\"][0:20]):\n",
    "    for tag in tags:\n",
    "        tag_counter[tag] += 1\n",
    "\n",
    "tag_counter = Counter({k: c for k,c in sorted(tag_counter.items(), key=lambda item: item[1], reverse=True)})\n",
    "\n",
    "tag_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30446935",
   "metadata": {},
   "source": [
    "# Gesamtanzahl der Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75a42487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e8378",
   "metadata": {},
   "source": [
    "# Textähnlichkeiten der Experten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdfc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = {}\n",
    "\n",
    "for i in range(0, len(top_users_posts)):        \n",
    "    doc_dict[top_users_posts.iloc[i][\"AnswerUserId\"]] = doc_dict.get(top_users_posts.iloc[i][\"AnswerUserId\"], '') + ' ' + clean_bodys(top_users_posts.iloc[i][\"AnswerBody\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24e07d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1060350</th>\n",
       "      <td>K2 x,z  can be 0.Then this value is not well-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658050</th>\n",
       "      <td>In short yes, you should include each class. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561314</th>\n",
       "      <td>Here are the original input variables:A is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714410</th>\n",
       "      <td>If you got  from git you should find in  fold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562769</th>\n",
       "      <td>Value iteration is used when you have transit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685471</th>\n",
       "      <td>In  documentation, it is mentioned: What you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025009</th>\n",
       "      <td>I see 3 possible ways to solve this:1  try to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974433</th>\n",
       "      <td>To understand how backpropagation is even pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785185</th>\n",
       "      <td>You have already split on weather and gender....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090562</th>\n",
       "      <td>Majority of machine learning algorithms work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545260</th>\n",
       "      <td>As of TensorFlow 0.8, there is now a  that ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574081</th>\n",
       "      <td>As with standard matrix multiplication, if  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712995</th>\n",
       "      <td>As discussed in , a deconvolution is just a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908375</th>\n",
       "      <td>It's easy for tf.keras!This optimizer will cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349130</th>\n",
       "      <td>I think there is a bit of a confusion here.An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741205</th>\n",
       "      <td>currently it's not implemented, but you can u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097240</th>\n",
       "      <td>Call a  in Keras to see all the layers. An in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374996</th>\n",
       "      <td>You should not pass  into the RandomizedSearc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730309</th>\n",
       "      <td>I want to explain with picture from .In a nut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099607</th>\n",
       "      <td>Actually, setting  for the Embedding layer do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Doc\n",
       "1060350    K2 x,z  can be 0.Then this value is not well-...\n",
       "2658050    In short yes, you should include each class. ...\n",
       "4561314    Here are the original input variables:A is a ...\n",
       "1714410    If you got  from git you should find in  fold...\n",
       "562769     Value iteration is used when you have transit...\n",
       "4685471    In  documentation, it is mentioned: What you ...\n",
       "5025009    I see 3 possible ways to solve this:1  try to...\n",
       "5974433    To understand how backpropagation is even pos...\n",
       "4785185    You have already split on weather and gender....\n",
       "1090562    Majority of machine learning algorithms work ...\n",
       "5545260    As of TensorFlow 0.8, there is now a  that ca...\n",
       "3574081    As with standard matrix multiplication, if  h...\n",
       "712995     As discussed in , a deconvolution is just a c...\n",
       "10908375   It's easy for tf.keras!This optimizer will cl...\n",
       "349130     I think there is a bit of a confusion here.An...\n",
       "5741205    currently it's not implemented, but you can u...\n",
       "2097240    Call a  in Keras to see all the layers. An in...\n",
       "3374996    You should not pass  into the RandomizedSearc...\n",
       "6730309    I want to explain with picture from .In a nut...\n",
       "2099607    Actually, setting  for the Embedding layer do..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_df = pd.DataFrame.from_dict(doc_dict, orient=\"index\", columns=[\"Doc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "col = 0\n",
    "\n",
    "doc_sim_matrix = []\n",
    "\n",
    "while i < len(doc_df) - 1:\n",
    "    print(i)\n",
    "    doc1 = nlp(doc_df.iloc[i][\"Doc\"])\n",
    "    doc_sim_vec = []\n",
    "    \n",
    "    j = col + 1\n",
    "    while j < len(doc_df):\n",
    "        print(j)\n",
    "        doc2 = nlp(doc_df.iloc[j][\"Doc\"])\n",
    "        sim = doc1.similarity(doc2)\n",
    "        doc_sim_vec.append(sim)                \n",
    "        j += 1\n",
    "    doc_sim_matrix.append(doc_sim_vec)\n",
    "    col += 1\n",
    "    i += 1\n",
    "    print('---')\n",
    "doc_sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44852e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.992634</td>\n",
       "      <td>0.993036</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>0.994728</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.993858</td>\n",
       "      <td>0.996933</td>\n",
       "      <td>0.995932</td>\n",
       "      <td>0.994589</td>\n",
       "      <td>0.989918</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.994795</td>\n",
       "      <td>0.995843</td>\n",
       "      <td>0.985585</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.993855</td>\n",
       "      <td>0.766346</td>\n",
       "      <td>0.991891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994438</td>\n",
       "      <td>0.993793</td>\n",
       "      <td>0.996806</td>\n",
       "      <td>0.996435</td>\n",
       "      <td>0.989719</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.995539</td>\n",
       "      <td>0.994862</td>\n",
       "      <td>0.991263</td>\n",
       "      <td>0.997294</td>\n",
       "      <td>0.994282</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>0.986199</td>\n",
       "      <td>0.996003</td>\n",
       "      <td>0.993757</td>\n",
       "      <td>0.769810</td>\n",
       "      <td>0.993845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997096</td>\n",
       "      <td>0.994884</td>\n",
       "      <td>0.993524</td>\n",
       "      <td>0.994794</td>\n",
       "      <td>0.994390</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.991792</td>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.996216</td>\n",
       "      <td>0.996506</td>\n",
       "      <td>0.993954</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.988790</td>\n",
       "      <td>0.994016</td>\n",
       "      <td>0.994840</td>\n",
       "      <td>0.779966</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995506</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>0.995550</td>\n",
       "      <td>0.995713</td>\n",
       "      <td>0.993450</td>\n",
       "      <td>0.993611</td>\n",
       "      <td>0.996629</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.996234</td>\n",
       "      <td>0.997647</td>\n",
       "      <td>0.991585</td>\n",
       "      <td>0.996316</td>\n",
       "      <td>0.996049</td>\n",
       "      <td>0.776746</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995417</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>0.998064</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.991776</td>\n",
       "      <td>0.997432</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.996675</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.998123</td>\n",
       "      <td>0.996326</td>\n",
       "      <td>0.773945</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.991593</td>\n",
       "      <td>0.993703</td>\n",
       "      <td>0.997437</td>\n",
       "      <td>0.993970</td>\n",
       "      <td>0.995750</td>\n",
       "      <td>0.991873</td>\n",
       "      <td>0.997488</td>\n",
       "      <td>0.995015</td>\n",
       "      <td>0.995732</td>\n",
       "      <td>0.985639</td>\n",
       "      <td>0.995633</td>\n",
       "      <td>0.995586</td>\n",
       "      <td>0.757010</td>\n",
       "      <td>0.994193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.993106</td>\n",
       "      <td>0.993233</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>0.990921</td>\n",
       "      <td>0.993404</td>\n",
       "      <td>0.992842</td>\n",
       "      <td>0.995177</td>\n",
       "      <td>0.993195</td>\n",
       "      <td>0.995065</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.779525</td>\n",
       "      <td>0.994580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.995090</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.993664</td>\n",
       "      <td>0.995988</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.995447</td>\n",
       "      <td>0.988966</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.995113</td>\n",
       "      <td>0.753082</td>\n",
       "      <td>0.995524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995245</td>\n",
       "      <td>0.996245</td>\n",
       "      <td>0.993385</td>\n",
       "      <td>0.998221</td>\n",
       "      <td>0.996658</td>\n",
       "      <td>0.997135</td>\n",
       "      <td>0.987684</td>\n",
       "      <td>0.997485</td>\n",
       "      <td>0.996049</td>\n",
       "      <td>0.768711</td>\n",
       "      <td>0.995350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995769</td>\n",
       "      <td>0.991023</td>\n",
       "      <td>0.996259</td>\n",
       "      <td>0.997098</td>\n",
       "      <td>0.995174</td>\n",
       "      <td>0.988153</td>\n",
       "      <td>0.996704</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.760570</td>\n",
       "      <td>0.992043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.993115</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.995850</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>0.985704</td>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.994508</td>\n",
       "      <td>0.764659</td>\n",
       "      <td>0.993539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.993273</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.988754</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.759497</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.998143</td>\n",
       "      <td>0.987333</td>\n",
       "      <td>0.997510</td>\n",
       "      <td>0.996093</td>\n",
       "      <td>0.764808</td>\n",
       "      <td>0.996493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.996992</td>\n",
       "      <td>0.992626</td>\n",
       "      <td>0.998856</td>\n",
       "      <td>0.997631</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.995472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.989282</td>\n",
       "      <td>0.997566</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.772192</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.990712</td>\n",
       "      <td>0.992409</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.990028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.996702</td>\n",
       "      <td>0.772020</td>\n",
       "      <td>0.995880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.762333</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.767102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.998271  0.992634  0.993036  0.996990  0.994728  0.989189  0.993858   \n",
       "1   0.994438  0.993793  0.996806  0.996435  0.989719  0.995312  0.997449   \n",
       "2   0.997096  0.994884  0.993524  0.994794  0.994390  0.996388  0.991792   \n",
       "3   0.995506  0.992427  0.994934  0.995550  0.995713  0.993450  0.993611   \n",
       "4   0.995417  0.994614  0.996582  0.998064  0.997190  0.995996  0.991776   \n",
       "5   0.991593  0.993703  0.997437  0.993970  0.995750  0.991873  0.997488   \n",
       "6   0.993106  0.993233  0.992416  0.990921  0.993404  0.992842  0.995177   \n",
       "7   0.995966  0.995090  0.994158  0.993664  0.995988  0.994750  0.995447   \n",
       "8   0.995245  0.996245  0.993385  0.998221  0.996658  0.997135  0.987684   \n",
       "9   0.995769  0.991023  0.996259  0.997098  0.995174  0.988153  0.996704   \n",
       "10  0.993115  0.997776  0.995850  0.995965  0.985704  0.996223  0.994508   \n",
       "11  0.994956  0.993273  0.996064  0.988754  0.992618  0.995117  0.759497   \n",
       "12  0.997004  0.998143  0.987333  0.997510  0.996093  0.764808  0.996493   \n",
       "13  0.996992  0.992626  0.998856  0.997631  0.770925  0.995472       NaN   \n",
       "14  0.989282  0.997566  0.996226  0.772192  0.997689       NaN       NaN   \n",
       "15  0.990712  0.992409  0.794451  0.990028       NaN       NaN       NaN   \n",
       "16  0.996702  0.772020  0.995880       NaN       NaN       NaN       NaN   \n",
       "17  0.762333  0.995849       NaN       NaN       NaN       NaN       NaN   \n",
       "18  0.767102       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0   0.996933  0.995932  0.994589  0.989918  0.996549  0.994795  0.995843   \n",
       "1   0.995539  0.994862  0.991263  0.997294  0.994282  0.996877  0.986199   \n",
       "2   0.992760  0.996216  0.996506  0.993954  0.997076  0.988790  0.994016   \n",
       "3   0.996629  0.995825  0.996234  0.997647  0.991585  0.996316  0.996049   \n",
       "4   0.997432  0.997465  0.996675  0.990040  0.998123  0.996326  0.773945   \n",
       "5   0.995015  0.995732  0.985639  0.995633  0.995586  0.757010  0.994193   \n",
       "6   0.993195  0.995065  0.993865  0.996795  0.779525  0.994580       NaN   \n",
       "7   0.988966  0.995094  0.995113  0.753082  0.995524       NaN       NaN   \n",
       "8   0.997485  0.996049  0.768711  0.995350       NaN       NaN       NaN   \n",
       "9   0.995996  0.760570  0.992043       NaN       NaN       NaN       NaN   \n",
       "10  0.764659  0.993539       NaN       NaN       NaN       NaN       NaN   \n",
       "11  0.997013       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "12       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "13       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "14       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "15       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "16       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "17       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "18       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          14        15        16        17        18  \n",
       "0   0.985585  0.995958  0.993855  0.766346  0.991891  \n",
       "1   0.996003  0.993757  0.769810  0.993845       NaN  \n",
       "2   0.994840  0.779966  0.997224       NaN       NaN  \n",
       "3   0.776746  0.997984       NaN       NaN       NaN  \n",
       "4   0.994609       NaN       NaN       NaN       NaN  \n",
       "5        NaN       NaN       NaN       NaN       NaN  \n",
       "6        NaN       NaN       NaN       NaN       NaN  \n",
       "7        NaN       NaN       NaN       NaN       NaN  \n",
       "8        NaN       NaN       NaN       NaN       NaN  \n",
       "9        NaN       NaN       NaN       NaN       NaN  \n",
       "10       NaN       NaN       NaN       NaN       NaN  \n",
       "11       NaN       NaN       NaN       NaN       NaN  \n",
       "12       NaN       NaN       NaN       NaN       NaN  \n",
       "13       NaN       NaN       NaN       NaN       NaN  \n",
       "14       NaN       NaN       NaN       NaN       NaN  \n",
       "15       NaN       NaN       NaN       NaN       NaN  \n",
       "16       NaN       NaN       NaN       NaN       NaN  \n",
       "17       NaN       NaN       NaN       NaN       NaN  \n",
       "18       NaN       NaN       NaN       NaN       NaN  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(doc_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea38cd32",
   "metadata": {},
   "source": [
    "# Schnittmenge der Tags pro Experte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e39d6f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Has QUIT--Anony-Mousse': {'machine-learning'},\n",
       " 'lejlot': {'machine-learning'},\n",
       " 'stackoverflowuser2010': {'machine-learning'},\n",
       " 'Shai': {'machine-learning'},\n",
       " 'Martin Thoma': {'machine-learning'},\n",
       " 'desertnaut': set(),\n",
       " 'seralouk': {'machine-learning'},\n",
       " 'Marcin Możejko': {'machine-learning'},\n",
       " 'Prune': {'machine-learning'},\n",
       " 'Salvador Dali': {'machine-learning'},\n",
       " 'dga': {'machine-learning', 'tensorflow'},\n",
       " 'mrry': {'machine-learning'},\n",
       " 'Maxim': set(),\n",
       " 'Nicolas Gervais': {'machine-learning'},\n",
       " 'Dr. Snoopy': {'machine-learning'},\n",
       " 'MaxU': {'machine-learning'},\n",
       " 'Daniel Möller': {'machine-learning'},\n",
       " 'Vivek Kumar': {'machine-learning'},\n",
       " 'runhani': {'conv-neural-network',\n",
       "  'convolution',\n",
       "  'deep-learning',\n",
       "  'machine-learning',\n",
       "  'signal-processing'},\n",
       " 'today': {'machine-learning'}}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tags_with_ml(tags):    \n",
    "    tag_list = []\n",
    "    # clean tags from '>' and '<' occurences\n",
    "    tags = re.sub('><', ' ', tags) \n",
    "    tags = re.sub('<|>', '', tags)\n",
    "    # add single tag of tags and add it to lists and sets\n",
    "    for tag in tags.split():    \n",
    "        tag_list.append(tag)\n",
    "    return tag_list\n",
    "\n",
    "for post in top_users_posts.drop_duplicates(subset=\"AnswerUserId\").itertuples():\n",
    "    \n",
    "    user_tag_dict[post[13]] = set(clean_tags_with_ml(post[4]))\n",
    "\n",
    "for post in top_users_posts.itertuples():\n",
    "    \n",
    "    cleaned_tags = clean_tags_with_ml(post[4])\n",
    "    if len(cleaned_tags) >= 0:\n",
    "        user_tag_dict[post[13]] = set(user_tag_dict.get(post[13], set()).intersection(cleaned_tags))\n",
    "user_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4ea93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
